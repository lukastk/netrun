{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for MultiprocessPool"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp pool.test_multiprocess"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import pytest\n",
        "import asyncio\n",
        "from netrun.rpc.base import RecvTimeout\n",
        "from netrun.pool.base import (\n",
        "    PoolNotStarted,\n",
        "    PoolAlreadyStarted,\n",
        ")\n",
        "from netrun.pool.multiprocess import MultiprocessPool"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Worker Functions\n",
        "\n",
        "Worker functions are in an importable module for multiprocessing."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from tests.pool.workers import echo_worker, compute_worker, pid_worker, printing_worker"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Pool Creation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_creation():\n",
        "    \"\"\"Test creating a MultiprocessPool.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n",
        "    assert pool.num_workers == 4\n",
        "    assert pool.num_processes == 2\n",
        "    assert pool.threads_per_process == 2\n",
        "    assert not pool.is_running"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_creation();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_default_threads():\n",
        "    \"\"\"Test that threads_per_process defaults to 1.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=3)\n",
        "    assert pool.num_workers == 3\n",
        "    assert pool.threads_per_process == 1"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_default_threads();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_invalid_num_processes():\n",
        "    \"\"\"Test that invalid num_processes raises ValueError.\"\"\"\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=0)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=-1)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_invalid_num_processes();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_invalid_threads_per_process():\n",
        "    \"\"\"Test that invalid threads_per_process raises ValueError.\"\"\"\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=2, threads_per_process=0)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_invalid_threads_per_process();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Pool Lifecycle"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_start_and_close():\n",
        "    \"\"\"Test starting and closing a pool.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    assert not pool.is_running\n",
        "    await pool.start()\n",
        "    assert pool.is_running\n",
        "\n",
        "    await pool.close()\n",
        "    assert not pool.is_running"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_start_and_close();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_double_start_raises():\n",
        "    \"\"\"Test that starting twice raises PoolAlreadyStarted.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1)\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        with pytest.raises(PoolAlreadyStarted):\n",
        "            await pool.start()\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_double_start_raises();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_context_manager():\n",
        "    \"\"\"Test using pool as context manager.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        assert pool.is_running\n",
        "\n",
        "    assert not pool.is_running"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_context_manager();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Send/Recv"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_recv_single():\n",
        "    \"\"\"Test sending and receiving a single message.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1) as pool:\n",
        "        await pool.send(worker_id=0, key=\"test\", data=\"hello\")\n",
        "        msg = await pool.recv(timeout=10.0)\n",
        "\n",
        "        assert msg.worker_id == 0\n",
        "        assert msg.key == \"echo:test\"\n",
        "        assert msg.data == {\"worker_id\": 0, \"data\": \"hello\"}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_recv_single();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_recv_multiple_workers():\n",
        "    \"\"\"Test sending to multiple workers across processes.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        # Send to each worker\n",
        "        for i in range(pool.num_workers):\n",
        "            await pool.send(worker_id=i, key=\"ping\", data=i)\n",
        "\n",
        "        # Receive all responses\n",
        "        responses = []\n",
        "        for _ in range(pool.num_workers):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            responses.append(msg)\n",
        "\n",
        "        assert len(responses) == 4\n",
        "        worker_ids = {msg.worker_id for msg in responses}\n",
        "        assert worker_ids == {0, 1, 2, 3}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_recv_multiple_workers();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Worker ID Mapping"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_worker_id_mapping():\n",
        "    \"\"\"Test that worker IDs map correctly to processes and threads.\"\"\"\n",
        "    # 2 processes x 2 threads = 4 workers\n",
        "    # Worker 0, 1 in process 0\n",
        "    # Worker 2, 3 in process 1\n",
        "    async with MultiprocessPool(pid_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        for i in range(4):\n",
        "            await pool.send(worker_id=i, key=\"get_pid\", data=None)\n",
        "\n",
        "        pids = {}\n",
        "        for _ in range(4):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            pids[msg.data[\"worker_id\"]] = msg.data[\"pid\"]\n",
        "\n",
        "        # Workers 0 and 1 should have same PID (same process)\n",
        "        assert pids[0] == pids[1]\n",
        "        # Workers 2 and 3 should have same PID (same process)\n",
        "        assert pids[2] == pids[3]\n",
        "        # Different processes should have different PIDs\n",
        "        assert pids[0] != pids[2]"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_worker_id_mapping();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test try_recv"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_try_recv_empty():\n",
        "    \"\"\"Test try_recv when no messages pending.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        result = await pool.try_recv()\n",
        "        assert result is None"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_try_recv_empty();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_try_recv_with_message():\n",
        "    \"\"\"Test try_recv with pending message.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        await pool.send(worker_id=0, key=\"test\", data=\"data\")\n",
        "        await asyncio.sleep(0.5)  # Let worker process\n",
        "\n",
        "        result = await pool.try_recv()\n",
        "        assert result is not None\n",
        "        assert result.key == \"echo:test\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_try_recv_with_message();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Broadcast"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_broadcast():\n",
        "    \"\"\"Test broadcasting to all workers.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        await pool.broadcast(\"config\", {\"setting\": \"value\"})\n",
        "\n",
        "        responses = []\n",
        "        for _ in range(pool.num_workers):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            responses.append(msg)\n",
        "\n",
        "        assert len(responses) == 4\n",
        "        worker_ids = {msg.worker_id for msg in responses}\n",
        "        assert worker_ids == {0, 1, 2, 3}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_broadcast();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Timeout"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_recv_timeout():\n",
        "    \"\"\"Test recv timeout.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        with pytest.raises(RecvTimeout):\n",
        "            await pool.recv(timeout=0.5)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_recv_timeout();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Error Handling"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_before_start_raises():\n",
        "    \"\"\"Test that sending before start raises PoolNotStarted.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.send(worker_id=0, key=\"test\", data=\"data\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_before_start_raises();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_recv_before_start_raises():\n",
        "    \"\"\"Test that receiving before start raises PoolNotStarted.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.recv()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_recv_before_start_raises();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_invalid_worker_id():\n",
        "    \"\"\"Test that invalid worker_id raises ValueError.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        with pytest.raises(ValueError):\n",
        "            await pool.send(worker_id=-1, key=\"test\", data=\"data\")\n",
        "\n",
        "        with pytest.raises(ValueError):\n",
        "            await pool.send(worker_id=4, key=\"test\", data=\"data\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_invalid_worker_id();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Computation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_compute_workers():\n",
        "    \"\"\"Test compute workers with actual computation.\"\"\"\n",
        "    async with MultiprocessPool(compute_worker, num_processes=2, threads_per_process=1) as pool:\n",
        "        await pool.send(worker_id=0, key=\"square\", data=7)\n",
        "        await pool.send(worker_id=1, key=\"double\", data=21)\n",
        "\n",
        "        results = []\n",
        "        for _ in range(2):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            results.append((msg.worker_id, msg.data))\n",
        "\n",
        "        results.sort()  # Sort by worker_id\n",
        "        assert results == [(0, 49), (1, 42)]"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_compute_workers();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Consistency\n",
        "\n",
        "These tests verify that all messages are reliably delivered across multiple runs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_single_run():\n",
        "    \"\"\"Test that all messages are received in a single run.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        num_messages = pool.num_workers\n",
        "\n",
        "        # Send to each worker\n",
        "        for i in range(num_messages):\n",
        "            await pool.send(worker_id=i, key=\"ping\", data=i)\n",
        "\n",
        "        # Receive all responses\n",
        "        received = []\n",
        "        for _ in range(num_messages):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            received.append(msg.worker_id)\n",
        "\n",
        "        # All workers should have responded\n",
        "        assert sorted(received) == list(range(num_messages)), f\"Missing responses: expected {list(range(num_messages))}, got {sorted(received)}\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_single_run();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_multiple_runs():\n",
        "    \"\"\"Test consistency across multiple pool create/destroy cycles.\"\"\"\n",
        "    for run in range(5):\n",
        "        async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "            num_messages = pool.num_workers\n",
        "\n",
        "            # Send to each worker\n",
        "            for i in range(num_messages):\n",
        "                await pool.send(worker_id=i, key=\"ping\", data=i)\n",
        "\n",
        "            # Receive all responses\n",
        "            received = []\n",
        "            for _ in range(num_messages):\n",
        "                msg = await pool.recv(timeout=10.0)\n",
        "                received.append(msg.worker_id)\n",
        "\n",
        "            assert sorted(received) == list(range(num_messages)), f\"Run {run}: Missing responses\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_multiple_runs();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_many_messages():\n",
        "    \"\"\"Test consistency with many messages per worker.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        messages_per_worker = 10\n",
        "        total_messages = pool.num_workers * messages_per_worker\n",
        "\n",
        "        # Send multiple messages to each worker\n",
        "        for round_num in range(messages_per_worker):\n",
        "            for worker_id in range(pool.num_workers):\n",
        "                await pool.send(worker_id, key=f\"msg{round_num}\", data=round_num)\n",
        "\n",
        "        # Receive all responses\n",
        "        received_count = 0\n",
        "        for _ in range(total_messages):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            received_count += 1\n",
        "\n",
        "        assert received_count == total_messages, f\"Expected {total_messages} messages, got {received_count}\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_many_messages();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_rapid_cycles():\n",
        "    \"\"\"Test consistency with rapid pool creation and destruction.\"\"\"\n",
        "    for run in range(10):\n",
        "        async with MultiprocessPool(echo_worker, num_processes=1, threads_per_process=2) as pool:\n",
        "            # Quick send/recv cycle\n",
        "            await pool.send(worker_id=0, key=\"quick\", data=run)\n",
        "            await pool.send(worker_id=1, key=\"quick\", data=run)\n",
        "\n",
        "            msg1 = await pool.recv(timeout=10.0)\n",
        "            msg2 = await pool.recv(timeout=10.0)\n",
        "\n",
        "            worker_ids = sorted([msg1.worker_id, msg2.worker_id])\n",
        "            assert worker_ids == [0, 1], f\"Run {run}: Expected workers [0, 1], got {worker_ids}\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_rapid_cycles();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Stdout/Stderr Redirection\n",
        "\n",
        "These tests verify the stdout/stderr capture and buffering feature."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_stdout_redirect_default():\n",
        "    \"\"\"Test that stdout/stderr redirection is enabled by default.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1)\n",
        "    # Default should be redirect_output=True, buffer_output=True\n",
        "    assert pool._redirect_output is True\n",
        "    assert pool._buffer_output is True"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_stdout_redirect_default();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_stdout_redirect_disabled():\n",
        "    \"\"\"Test creating pool with stdout redirection disabled.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, redirect_output=False)\n",
        "    assert pool._redirect_output is False"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_stdout_redirect_disabled();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_flush_stdout_single_process():\n",
        "    \"\"\"Test flushing stdout from a single process.\"\"\"\n",
        "    async with MultiprocessPool(\n",
        "        printing_worker,\n",
        "        num_processes=1,\n",
        "        threads_per_process=1,\n",
        "        redirect_output=True,\n",
        "        buffer_output=True,\n",
        "    ) as pool:\n",
        "        # Wait for startup messages\n",
        "        await asyncio.sleep(0.5)\n",
        "\n",
        "        # Send a message to trigger more prints\n",
        "        await pool.send(0, \"test\", \"hello\")\n",
        "        await pool.recv(timeout=5.0)\n",
        "\n",
        "        # Flush stdout\n",
        "        buffer = await pool.flush_stdout(0)\n",
        "\n",
        "        # Should have captured output\n",
        "        assert len(buffer) > 0\n",
        "\n",
        "        # Check buffer format: list of (datetime, bool, str)\n",
        "        for entry in buffer:\n",
        "            assert len(entry) == 3\n",
        "            timestamp, is_stdout, text = entry\n",
        "            assert isinstance(is_stdout, bool)\n",
        "            assert isinstance(text, str)\n",
        "\n",
        "        # Should have captured both stdout (True) and stderr (False)\n",
        "        has_stdout = any(entry[1] is True for entry in buffer)\n",
        "        has_stderr = any(entry[1] is False for entry in buffer)\n",
        "        assert has_stdout, \"Should have captured stdout\"\n",
        "        assert has_stderr, \"Should have captured stderr\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_flush_stdout_single_process();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_flush_stdout_clears_buffer():\n",
        "    \"\"\"Test that flushing clears the buffer.\"\"\"\n",
        "    async with MultiprocessPool(\n",
        "        printing_worker,\n",
        "        num_processes=1,\n",
        "        redirect_output=True,\n",
        "        buffer_output=True,\n",
        "    ) as pool:\n",
        "        await asyncio.sleep(0.5)\n",
        "\n",
        "        # First flush gets startup messages\n",
        "        buffer1 = await pool.flush_stdout(0)\n",
        "        assert len(buffer1) > 0\n",
        "\n",
        "        # Second flush should be empty (no new output)\n",
        "        buffer2 = await pool.flush_stdout(0)\n",
        "        assert len(buffer2) == 0"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_flush_stdout_clears_buffer();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_flush_all_stdout():\n",
        "    \"\"\"Test flushing stdout from all processes.\"\"\"\n",
        "    async with MultiprocessPool(\n",
        "        printing_worker,\n",
        "        num_processes=2,\n",
        "        threads_per_process=1,\n",
        "        redirect_output=True,\n",
        "        buffer_output=True,\n",
        "    ) as pool:\n",
        "        await asyncio.sleep(0.5)\n",
        "\n",
        "        # Send to both workers\n",
        "        await pool.send(0, \"test\", \"hello\")\n",
        "        await pool.send(1, \"test\", \"world\")\n",
        "\n",
        "        # Receive responses\n",
        "        await pool.recv(timeout=5.0)\n",
        "        await pool.recv(timeout=5.0)\n",
        "\n",
        "        # Flush all\n",
        "        all_buffers = await pool.flush_all_stdout()\n",
        "\n",
        "        assert len(all_buffers) == 2\n",
        "        assert 0 in all_buffers\n",
        "        assert 1 in all_buffers\n",
        "\n",
        "        # Both processes should have output\n",
        "        assert len(all_buffers[0]) > 0\n",
        "        assert len(all_buffers[1]) > 0"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_flush_all_stdout();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_stdout_silent_mode():\n",
        "    \"\"\"Test that buffer_output=False discards output.\"\"\"\n",
        "    async with MultiprocessPool(\n",
        "        printing_worker,\n",
        "        num_processes=1,\n",
        "        redirect_output=True,\n",
        "        buffer_output=False,  # Silent mode\n",
        "    ) as pool:\n",
        "        await asyncio.sleep(0.5)\n",
        "\n",
        "        # Flush should return empty buffer (output discarded)\n",
        "        buffer = await pool.flush_stdout(0)\n",
        "        assert len(buffer) == 0"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_stdout_silent_mode();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_flush_stdout_invalid_process_idx():\n",
        "    \"\"\"Test that flush_stdout raises ValueError for invalid process_idx.\"\"\"\n",
        "    async with MultiprocessPool(\n",
        "        printing_worker,\n",
        "        num_processes=2,\n",
        "        redirect_output=True,\n",
        "        buffer_output=True,\n",
        "    ) as pool:\n",
        "        with pytest.raises(ValueError):\n",
        "            await pool.flush_stdout(-1)\n",
        "\n",
        "        with pytest.raises(ValueError):\n",
        "            await pool.flush_stdout(2)  # Only 0 and 1 are valid"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_flush_stdout_invalid_process_idx();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_flush_stdout_before_start():\n",
        "    \"\"\"Test that flush_stdout raises PoolNotStarted before start().\"\"\"\n",
        "    pool = MultiprocessPool(\n",
        "        printing_worker,\n",
        "        num_processes=1,\n",
        "        redirect_output=True,\n",
        "        buffer_output=True,\n",
        "    )\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.flush_stdout(0)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_flush_stdout_before_start();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_stdout_content():\n",
        "    \"\"\"Test that captured stdout contains expected content.\"\"\"\n",
        "    async with MultiprocessPool(\n",
        "        printing_worker,\n",
        "        num_processes=1,\n",
        "        redirect_output=True,\n",
        "        buffer_output=True,\n",
        "    ) as pool:\n",
        "        await asyncio.sleep(0.5)\n",
        "\n",
        "        await pool.send(0, \"mykey\", \"myvalue\")\n",
        "        await pool.recv(timeout=5.0)\n",
        "\n",
        "        buffer = await pool.flush_stdout(0)\n",
        "\n",
        "        # Combine all stdout text\n",
        "        stdout_text = \"\".join(\n",
        "            text for timestamp, is_stdout, text in buffer if is_stdout\n",
        "        )\n",
        "        stderr_text = \"\".join(\n",
        "            text for timestamp, is_stdout, text in buffer if not is_stdout\n",
        "        )\n",
        "\n",
        "        # Check expected content\n",
        "        assert \"Worker 0 starting\" in stdout_text\n",
        "        assert \"Worker 0 got: mykey=myvalue\" in stdout_text\n",
        "        assert \"Worker 0 stderr\" in stderr_text"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_stdout_content();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
