{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for MultiprocessPool"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp pool.test_multiprocess"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import pytest\n",
        "import asyncio\n",
        "from netrun.rpc.base import RecvTimeout\n",
        "from netrun.pool.base import (\n",
        "    PoolNotStarted,\n",
        "    PoolAlreadyStarted,\n",
        ")\n",
        "from netrun.pool.multiprocess import MultiprocessPool"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Worker Functions\n",
        "\n",
        "Worker functions are in an importable module for multiprocessing."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from .workers import echo_worker, compute_worker, pid_worker"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Pool Creation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_creation():\n",
        "    \"\"\"Test creating a MultiprocessPool.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n",
        "    assert pool.num_workers == 4\n",
        "    assert pool.num_processes == 2\n",
        "    assert pool.threads_per_process == 2\n",
        "    assert not pool.is_running"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_creation();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_default_threads():\n",
        "    \"\"\"Test that threads_per_process defaults to 1.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=3)\n",
        "    assert pool.num_workers == 3\n",
        "    assert pool.threads_per_process == 1"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_default_threads();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_invalid_num_processes():\n",
        "    \"\"\"Test that invalid num_processes raises ValueError.\"\"\"\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=0)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=-1)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_invalid_num_processes();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_pool_invalid_threads_per_process():\n",
        "    \"\"\"Test that invalid threads_per_process raises ValueError.\"\"\"\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=2, threads_per_process=0)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_pool_invalid_threads_per_process();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Pool Lifecycle"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_start_and_close():\n",
        "    \"\"\"Test starting and closing a pool.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    assert not pool.is_running\n",
        "    await pool.start()\n",
        "    assert pool.is_running\n",
        "\n",
        "    await pool.close()\n",
        "    assert not pool.is_running"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_start_and_close();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_double_start_raises():\n",
        "    \"\"\"Test that starting twice raises PoolAlreadyStarted.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1)\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        with pytest.raises(PoolAlreadyStarted):\n",
        "            await pool.start()\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_double_start_raises();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_context_manager():\n",
        "    \"\"\"Test using pool as context manager.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        assert pool.is_running\n",
        "\n",
        "    assert not pool.is_running"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_context_manager();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Send/Recv"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_recv_single():\n",
        "    \"\"\"Test sending and receiving a single message.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1) as pool:\n",
        "        await pool.send(worker_id=0, key=\"test\", data=\"hello\")\n",
        "        msg = await pool.recv(timeout=10.0)\n",
        "\n",
        "        assert msg.worker_id == 0\n",
        "        assert msg.key == \"echo:test\"\n",
        "        assert msg.data == {\"worker_id\": 0, \"data\": \"hello\"}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_recv_single();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_recv_multiple_workers():\n",
        "    \"\"\"Test sending to multiple workers across processes.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        # Send to each worker\n",
        "        for i in range(pool.num_workers):\n",
        "            await pool.send(worker_id=i, key=\"ping\", data=i)\n",
        "\n",
        "        # Receive all responses\n",
        "        responses = []\n",
        "        for _ in range(pool.num_workers):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            responses.append(msg)\n",
        "\n",
        "        assert len(responses) == 4\n",
        "        worker_ids = {msg.worker_id for msg in responses}\n",
        "        assert worker_ids == {0, 1, 2, 3}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_recv_multiple_workers();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Worker ID Mapping"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_worker_id_mapping():\n",
        "    \"\"\"Test that worker IDs map correctly to processes and threads.\"\"\"\n",
        "    # 2 processes x 2 threads = 4 workers\n",
        "    # Worker 0, 1 in process 0\n",
        "    # Worker 2, 3 in process 1\n",
        "    async with MultiprocessPool(pid_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        for i in range(4):\n",
        "            await pool.send(worker_id=i, key=\"get_pid\", data=None)\n",
        "\n",
        "        pids = {}\n",
        "        for _ in range(4):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            pids[msg.data[\"worker_id\"]] = msg.data[\"pid\"]\n",
        "\n",
        "        # Workers 0 and 1 should have same PID (same process)\n",
        "        assert pids[0] == pids[1]\n",
        "        # Workers 2 and 3 should have same PID (same process)\n",
        "        assert pids[2] == pids[3]\n",
        "        # Different processes should have different PIDs\n",
        "        assert pids[0] != pids[2]"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_worker_id_mapping();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test try_recv"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_try_recv_empty():\n",
        "    \"\"\"Test try_recv when no messages pending.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        result = await pool.try_recv()\n",
        "        assert result is None"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_try_recv_empty();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_try_recv_with_message():\n",
        "    \"\"\"Test try_recv with pending message.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        await pool.send(worker_id=0, key=\"test\", data=\"data\")\n",
        "        await asyncio.sleep(0.5)  # Let worker process\n",
        "\n",
        "        result = await pool.try_recv()\n",
        "        assert result is not None\n",
        "        assert result.key == \"echo:test\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_try_recv_with_message();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Broadcast"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_broadcast():\n",
        "    \"\"\"Test broadcasting to all workers.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        await pool.broadcast(\"config\", {\"setting\": \"value\"})\n",
        "\n",
        "        responses = []\n",
        "        for _ in range(pool.num_workers):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            responses.append(msg)\n",
        "\n",
        "        assert len(responses) == 4\n",
        "        worker_ids = {msg.worker_id for msg in responses}\n",
        "        assert worker_ids == {0, 1, 2, 3}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_broadcast();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Timeout"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_recv_timeout():\n",
        "    \"\"\"Test recv timeout.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n",
        "        with pytest.raises(RecvTimeout):\n",
        "            await pool.recv(timeout=0.5)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_recv_timeout();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Error Handling"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_before_start_raises():\n",
        "    \"\"\"Test that sending before start raises PoolNotStarted.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.send(worker_id=0, key=\"test\", data=\"data\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_before_start_raises();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_recv_before_start_raises():\n",
        "    \"\"\"Test that receiving before start raises PoolNotStarted.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.recv()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_recv_before_start_raises();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_invalid_worker_id():\n",
        "    \"\"\"Test that invalid worker_id raises ValueError.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        with pytest.raises(ValueError):\n",
        "            await pool.send(worker_id=-1, key=\"test\", data=\"data\")\n",
        "\n",
        "        with pytest.raises(ValueError):\n",
        "            await pool.send(worker_id=4, key=\"test\", data=\"data\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_invalid_worker_id();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Computation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_compute_workers():\n",
        "    \"\"\"Test compute workers with actual computation.\"\"\"\n",
        "    async with MultiprocessPool(compute_worker, num_processes=2, threads_per_process=1) as pool:\n",
        "        await pool.send(worker_id=0, key=\"square\", data=7)\n",
        "        await pool.send(worker_id=1, key=\"double\", data=21)\n",
        "\n",
        "        results = []\n",
        "        for _ in range(2):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            results.append((msg.worker_id, msg.data))\n",
        "\n",
        "        results.sort()  # Sort by worker_id\n",
        "        assert results == [(0, 49), (1, 42)]"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_compute_workers();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Consistency\n",
        "\n",
        "These tests verify that all messages are reliably delivered across multiple runs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_single_run():\n",
        "    \"\"\"Test that all messages are received in a single run.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        num_messages = pool.num_workers\n",
        "\n",
        "        # Send to each worker\n",
        "        for i in range(num_messages):\n",
        "            await pool.send(worker_id=i, key=\"ping\", data=i)\n",
        "\n",
        "        # Receive all responses\n",
        "        received = []\n",
        "        for _ in range(num_messages):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            received.append(msg.worker_id)\n",
        "\n",
        "        # All workers should have responded\n",
        "        assert sorted(received) == list(range(num_messages)), f\"Missing responses: expected {list(range(num_messages))}, got {sorted(received)}\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_single_run();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_multiple_runs():\n",
        "    \"\"\"Test consistency across multiple pool create/destroy cycles.\"\"\"\n",
        "    for run in range(5):\n",
        "        async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "            num_messages = pool.num_workers\n",
        "\n",
        "            # Send to each worker\n",
        "            for i in range(num_messages):\n",
        "                await pool.send(worker_id=i, key=\"ping\", data=i)\n",
        "\n",
        "            # Receive all responses\n",
        "            received = []\n",
        "            for _ in range(num_messages):\n",
        "                msg = await pool.recv(timeout=10.0)\n",
        "                received.append(msg.worker_id)\n",
        "\n",
        "            assert sorted(received) == list(range(num_messages)), f\"Run {run}: Missing responses\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_multiple_runs();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_many_messages():\n",
        "    \"\"\"Test consistency with many messages per worker.\"\"\"\n",
        "    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n",
        "        messages_per_worker = 10\n",
        "        total_messages = pool.num_workers * messages_per_worker\n",
        "\n",
        "        # Send multiple messages to each worker\n",
        "        for round_num in range(messages_per_worker):\n",
        "            for worker_id in range(pool.num_workers):\n",
        "                await pool.send(worker_id, key=f\"msg{round_num}\", data=round_num)\n",
        "\n",
        "        # Receive all responses\n",
        "        received_count = 0\n",
        "        for _ in range(total_messages):\n",
        "            msg = await pool.recv(timeout=10.0)\n",
        "            received_count += 1\n",
        "\n",
        "        assert received_count == total_messages, f\"Expected {total_messages} messages, got {received_count}\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_many_messages();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_consistency_rapid_cycles():\n",
        "    \"\"\"Test consistency with rapid pool creation and destruction.\"\"\"\n",
        "    for run in range(10):\n",
        "        async with MultiprocessPool(echo_worker, num_processes=1, threads_per_process=2) as pool:\n",
        "            # Quick send/recv cycle\n",
        "            await pool.send(worker_id=0, key=\"quick\", data=run)\n",
        "            await pool.send(worker_id=1, key=\"quick\", data=run)\n",
        "\n",
        "            msg1 = await pool.recv(timeout=10.0)\n",
        "            msg2 = await pool.recv(timeout=10.0)\n",
        "\n",
        "            worker_ids = sorted([msg1.worker_id, msg2.worker_id])\n",
        "            assert worker_ids == [0, 1], f\"Run {run}: Expected workers [0, 1], got {worker_ids}\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_consistency_rapid_cycles();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
