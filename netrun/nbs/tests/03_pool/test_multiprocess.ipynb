{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Tests for MultiprocessPool",
      "metadata": {},
      "id": "cell0"
    },
    {
      "cell_type": "code",
      "source": "#|default_exp pool.test_multiprocess",
      "metadata": {},
      "id": "cell1",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nimport pytest\nimport asyncio\nfrom netrun.rpc.base import RecvTimeout\nfrom netrun.pool.base import (\n    PoolNotStarted,\n    PoolAlreadyStarted,\n)\nfrom netrun.pool.multiprocess import MultiprocessPool",
      "metadata": {},
      "id": "cell2",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Import Worker Functions\n\nWorker functions are in an importable module for multiprocessing.",
      "metadata": {},
      "id": "cell3"
    },
    {
      "cell_type": "code",
      "source": "#|export\nfrom tests.pool.workers import echo_worker, compute_worker, pid_worker, printing_worker",
      "metadata": {},
      "id": "cell4",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Pool Creation",
      "metadata": {},
      "id": "cell5"
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef test_pool_creation():\n    \"\"\"Test creating a MultiprocessPool.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n    assert pool.num_workers == 4\n    assert pool.num_processes == 2\n    assert pool.threads_per_process == 2\n    assert not pool.is_running",
      "metadata": {},
      "id": "cell6",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_pool_creation();",
      "metadata": {},
      "id": "cell7",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef test_pool_default_threads():\n    \"\"\"Test that threads_per_process defaults to 1.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=3)\n    assert pool.num_workers == 3\n    assert pool.threads_per_process == 1",
      "metadata": {},
      "id": "cell8",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_pool_default_threads();",
      "metadata": {},
      "id": "cell9",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef test_pool_invalid_num_processes():\n    \"\"\"Test that invalid num_processes raises ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        MultiprocessPool(echo_worker, num_processes=0)\n\n    with pytest.raises(ValueError):\n        MultiprocessPool(echo_worker, num_processes=-1)",
      "metadata": {},
      "id": "cell10",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_pool_invalid_num_processes();",
      "metadata": {},
      "id": "cell11",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef test_pool_invalid_threads_per_process():\n    \"\"\"Test that invalid threads_per_process raises ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        MultiprocessPool(echo_worker, num_processes=2, threads_per_process=0)",
      "metadata": {},
      "id": "cell12",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_pool_invalid_threads_per_process();",
      "metadata": {},
      "id": "cell13",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Pool Lifecycle",
      "metadata": {},
      "id": "cell14"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_start_and_close():\n    \"\"\"Test starting and closing a pool.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n\n    assert not pool.is_running\n    await pool.start()\n    assert pool.is_running\n\n    await pool.close()\n    assert not pool.is_running",
      "metadata": {},
      "id": "cell15",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_start_and_close();",
      "metadata": {},
      "id": "cell16",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_double_start_raises():\n    \"\"\"Test that starting twice raises PoolAlreadyStarted.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1)\n    await pool.start()\n\n    try:\n        with pytest.raises(PoolAlreadyStarted):\n            await pool.start()\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell17",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_double_start_raises();",
      "metadata": {},
      "id": "cell18",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_context_manager():\n    \"\"\"Test using pool as context manager.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n        assert pool.is_running\n\n    assert not pool.is_running",
      "metadata": {},
      "id": "cell19",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_context_manager();",
      "metadata": {},
      "id": "cell20",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Send/Recv",
      "metadata": {},
      "id": "cell21"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_send_recv_single():\n    \"\"\"Test sending and receiving a single message.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1) as pool:\n        await pool.send(worker_id=0, key=\"test\", data=\"hello\")\n        msg = await pool.recv(timeout=10.0)\n\n        assert msg.worker_id == 0\n        assert msg.key == \"echo:test\"\n        assert msg.data == {\"worker_id\": 0, \"data\": \"hello\"}",
      "metadata": {},
      "id": "cell22",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_send_recv_single();",
      "metadata": {},
      "id": "cell23",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_send_recv_multiple_workers():\n    \"\"\"Test sending to multiple workers across processes.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n        # Send to each worker\n        for i in range(pool.num_workers):\n            await pool.send(worker_id=i, key=\"ping\", data=i)\n\n        # Receive all responses\n        responses = []\n        for _ in range(pool.num_workers):\n            msg = await pool.recv(timeout=10.0)\n            responses.append(msg)\n\n        assert len(responses) == 4\n        worker_ids = {msg.worker_id for msg in responses}\n        assert worker_ids == {0, 1, 2, 3}",
      "metadata": {},
      "id": "cell24",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_send_recv_multiple_workers();",
      "metadata": {},
      "id": "cell25",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Worker ID Mapping",
      "metadata": {},
      "id": "cell26"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_worker_id_mapping():\n    \"\"\"Test that worker IDs map correctly to processes and threads.\"\"\"\n    # 2 processes x 2 threads = 4 workers\n    # Worker 0, 1 in process 0\n    # Worker 2, 3 in process 1\n    async with MultiprocessPool(pid_worker, num_processes=2, threads_per_process=2) as pool:\n        for i in range(4):\n            await pool.send(worker_id=i, key=\"get_pid\", data=None)\n\n        pids = {}\n        for _ in range(4):\n            msg = await pool.recv(timeout=10.0)\n            pids[msg.data[\"worker_id\"]] = msg.data[\"pid\"]\n\n        # Workers 0 and 1 should have same PID (same process)\n        assert pids[0] == pids[1]\n        # Workers 2 and 3 should have same PID (same process)\n        assert pids[2] == pids[3]\n        # Different processes should have different PIDs\n        assert pids[0] != pids[2]",
      "metadata": {},
      "id": "cell27",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_worker_id_mapping();",
      "metadata": {},
      "id": "cell28",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test try_recv",
      "metadata": {},
      "id": "cell29"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_try_recv_empty():\n    \"\"\"Test try_recv when no messages pending.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n        result = await pool.try_recv()\n        assert result is None",
      "metadata": {},
      "id": "cell30",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_try_recv_empty();",
      "metadata": {},
      "id": "cell31",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_try_recv_with_message():\n    \"\"\"Test try_recv with pending message.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n        await pool.send(worker_id=0, key=\"test\", data=\"data\")\n        await asyncio.sleep(0.5)  # Let worker process\n\n        result = await pool.try_recv()\n        assert result is not None\n        assert result.key == \"echo:test\"",
      "metadata": {},
      "id": "cell32",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_try_recv_with_message();",
      "metadata": {},
      "id": "cell33",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Broadcast",
      "metadata": {},
      "id": "cell34"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_broadcast():\n    \"\"\"Test broadcasting to all workers.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n        await pool.broadcast(\"config\", {\"setting\": \"value\"})\n\n        responses = []\n        for _ in range(pool.num_workers):\n            msg = await pool.recv(timeout=10.0)\n            responses.append(msg)\n\n        assert len(responses) == 4\n        worker_ids = {msg.worker_id for msg in responses}\n        assert worker_ids == {0, 1, 2, 3}",
      "metadata": {},
      "id": "cell35",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_broadcast();",
      "metadata": {},
      "id": "cell36",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Timeout",
      "metadata": {},
      "id": "cell37"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_recv_timeout():\n    \"\"\"Test recv timeout.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=1) as pool:\n        with pytest.raises(RecvTimeout):\n            await pool.recv(timeout=0.5)",
      "metadata": {},
      "id": "cell38",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_recv_timeout();",
      "metadata": {},
      "id": "cell39",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Error Handling",
      "metadata": {},
      "id": "cell40"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_send_before_start_raises():\n    \"\"\"Test that sending before start raises PoolNotStarted.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1)\n\n    with pytest.raises(PoolNotStarted):\n        await pool.send(worker_id=0, key=\"test\", data=\"data\")",
      "metadata": {},
      "id": "cell41",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_send_before_start_raises();",
      "metadata": {},
      "id": "cell42",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_recv_before_start_raises():\n    \"\"\"Test that receiving before start raises PoolNotStarted.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1)\n\n    with pytest.raises(PoolNotStarted):\n        await pool.recv()",
      "metadata": {},
      "id": "cell43",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_recv_before_start_raises();",
      "metadata": {},
      "id": "cell44",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_invalid_worker_id():\n    \"\"\"Test that invalid worker_id raises ValueError.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n        with pytest.raises(ValueError):\n            await pool.send(worker_id=-1, key=\"test\", data=\"data\")\n\n        with pytest.raises(ValueError):\n            await pool.send(worker_id=4, key=\"test\", data=\"data\")",
      "metadata": {},
      "id": "cell45",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_invalid_worker_id();",
      "metadata": {},
      "id": "cell46",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Computation",
      "metadata": {},
      "id": "cell47"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_compute_workers():\n    \"\"\"Test compute workers with actual computation.\"\"\"\n    async with MultiprocessPool(compute_worker, num_processes=2, threads_per_process=1) as pool:\n        await pool.send(worker_id=0, key=\"square\", data=7)\n        await pool.send(worker_id=1, key=\"double\", data=21)\n\n        results = []\n        for _ in range(2):\n            msg = await pool.recv(timeout=10.0)\n            results.append((msg.worker_id, msg.data))\n\n        results.sort()  # Sort by worker_id\n        assert results == [(0, 49), (1, 42)]",
      "metadata": {},
      "id": "cell48",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_compute_workers();",
      "metadata": {},
      "id": "cell49",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Consistency\n\nThese tests verify that all messages are reliably delivered across multiple runs.",
      "metadata": {},
      "id": "cell50"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_consistency_single_run():\n    \"\"\"Test that all messages are received in a single run.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n        num_messages = pool.num_workers\n\n        # Send to each worker\n        for i in range(num_messages):\n            await pool.send(worker_id=i, key=\"ping\", data=i)\n\n        # Receive all responses\n        received = []\n        for _ in range(num_messages):\n            msg = await pool.recv(timeout=10.0)\n            received.append(msg.worker_id)\n\n        # All workers should have responded\n        assert sorted(received) == list(range(num_messages)), f\"Missing responses: expected {list(range(num_messages))}, got {sorted(received)}\"",
      "metadata": {},
      "id": "cell51",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_consistency_single_run();",
      "metadata": {},
      "id": "cell52",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_consistency_multiple_runs():\n    \"\"\"Test consistency across multiple pool create/destroy cycles.\"\"\"\n    for run in range(5):\n        async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n            num_messages = pool.num_workers\n\n            # Send to each worker\n            for i in range(num_messages):\n                await pool.send(worker_id=i, key=\"ping\", data=i)\n\n            # Receive all responses\n            received = []\n            for _ in range(num_messages):\n                msg = await pool.recv(timeout=10.0)\n                received.append(msg.worker_id)\n\n            assert sorted(received) == list(range(num_messages)), f\"Run {run}: Missing responses\"",
      "metadata": {},
      "id": "cell53",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_consistency_multiple_runs();",
      "metadata": {},
      "id": "cell54",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_consistency_many_messages():\n    \"\"\"Test consistency with many messages per worker.\"\"\"\n    async with MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2) as pool:\n        messages_per_worker = 10\n        total_messages = pool.num_workers * messages_per_worker\n\n        # Send multiple messages to each worker\n        for round_num in range(messages_per_worker):\n            for worker_id in range(pool.num_workers):\n                await pool.send(worker_id, key=f\"msg{round_num}\", data=round_num)\n\n        # Receive all responses\n        received_count = 0\n        for _ in range(total_messages):\n            msg = await pool.recv(timeout=10.0)\n            received_count += 1\n\n        assert received_count == total_messages, f\"Expected {total_messages} messages, got {received_count}\"",
      "metadata": {},
      "id": "cell55",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_consistency_many_messages();",
      "metadata": {},
      "id": "cell56",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_consistency_rapid_cycles():\n    \"\"\"Test consistency with rapid pool creation and destruction.\"\"\"\n    for run in range(10):\n        async with MultiprocessPool(echo_worker, num_processes=1, threads_per_process=2) as pool:\n            # Quick send/recv cycle\n            await pool.send(worker_id=0, key=\"quick\", data=run)\n            await pool.send(worker_id=1, key=\"quick\", data=run)\n\n            msg1 = await pool.recv(timeout=10.0)\n            msg2 = await pool.recv(timeout=10.0)\n\n            worker_ids = sorted([msg1.worker_id, msg2.worker_id])\n            assert worker_ids == [0, 1], f\"Run {run}: Expected workers [0, 1], got {worker_ids}\"",
      "metadata": {},
      "id": "cell57",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_consistency_rapid_cycles();",
      "metadata": {},
      "id": "cell58",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Test Stdout/Stderr Redirection\n\nThese tests verify the stdout/stderr capture and buffering feature.",
      "metadata": {},
      "id": "cell59"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_stdout_redirect_default():\n    \"\"\"Test that stdout/stderr redirection is enabled by default.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1)\n    # Default should be redirect_output=True, buffer_output=True\n    assert pool._redirect_output is True\n    assert pool._buffer_output is True",
      "metadata": {},
      "id": "cell60",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_stdout_redirect_default();",
      "metadata": {},
      "id": "cell61",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_stdout_redirect_disabled():\n    \"\"\"Test creating pool with stdout redirection disabled.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, redirect_output=False)\n    assert pool._redirect_output is False",
      "metadata": {},
      "id": "cell62",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_stdout_redirect_disabled();",
      "metadata": {},
      "id": "cell63",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_flush_stdout_single_process():\n    \"\"\"Test flushing stdout from a single process.\"\"\"\n    async with MultiprocessPool(\n        printing_worker,\n        num_processes=1,\n        threads_per_process=1,\n        redirect_output=True,\n        buffer_output=True,\n    ) as pool:\n        # Wait for startup messages\n        await asyncio.sleep(0.5)\n\n        # Send a message to trigger more prints\n        await pool.send(0, \"test\", \"hello\")\n        await pool.recv(timeout=5.0)\n\n        # Flush stdout\n        buffer = await pool.flush_stdout(0)\n\n        # Should have captured output\n        assert len(buffer) > 0\n\n        # Check buffer format: list of (datetime, bool, str)\n        for entry in buffer:\n            assert len(entry) == 3\n            timestamp, is_stdout, text = entry\n            assert isinstance(is_stdout, bool)\n            assert isinstance(text, str)\n\n        # Should have captured both stdout (True) and stderr (False)\n        has_stdout = any(entry[1] is True for entry in buffer)\n        has_stderr = any(entry[1] is False for entry in buffer)\n        assert has_stdout, \"Should have captured stdout\"\n        assert has_stderr, \"Should have captured stderr\"",
      "metadata": {},
      "id": "cell64",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_flush_stdout_single_process();",
      "metadata": {},
      "id": "cell65",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_flush_stdout_clears_buffer():\n    \"\"\"Test that flushing clears the buffer.\"\"\"\n    async with MultiprocessPool(\n        printing_worker,\n        num_processes=1,\n        redirect_output=True,\n        buffer_output=True,\n    ) as pool:\n        await asyncio.sleep(0.5)\n\n        # First flush gets startup messages\n        buffer1 = await pool.flush_stdout(0)\n        assert len(buffer1) > 0\n\n        # Second flush should be empty (no new output)\n        buffer2 = await pool.flush_stdout(0)\n        assert len(buffer2) == 0",
      "metadata": {},
      "id": "cell66",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_flush_stdout_clears_buffer();",
      "metadata": {},
      "id": "cell67",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_flush_all_stdout():\n    \"\"\"Test flushing stdout from all processes.\"\"\"\n    async with MultiprocessPool(\n        printing_worker,\n        num_processes=2,\n        threads_per_process=1,\n        redirect_output=True,\n        buffer_output=True,\n    ) as pool:\n        await asyncio.sleep(0.5)\n\n        # Send to both workers\n        await pool.send(0, \"test\", \"hello\")\n        await pool.send(1, \"test\", \"world\")\n\n        # Receive responses\n        await pool.recv(timeout=5.0)\n        await pool.recv(timeout=5.0)\n\n        # Flush all\n        all_buffers = await pool.flush_all_stdout()\n\n        assert len(all_buffers) == 2\n        assert 0 in all_buffers\n        assert 1 in all_buffers\n\n        # Both processes should have output\n        assert len(all_buffers[0]) > 0\n        assert len(all_buffers[1]) > 0",
      "metadata": {},
      "id": "cell68",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_flush_all_stdout();",
      "metadata": {},
      "id": "cell69",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_stdout_silent_mode():\n    \"\"\"Test that buffer_output=False discards output.\"\"\"\n    async with MultiprocessPool(\n        printing_worker,\n        num_processes=1,\n        redirect_output=True,\n        buffer_output=False,  # Silent mode\n    ) as pool:\n        await asyncio.sleep(0.5)\n\n        # Flush should return empty buffer (output discarded)\n        buffer = await pool.flush_stdout(0)\n        assert len(buffer) == 0",
      "metadata": {},
      "id": "cell70",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_stdout_silent_mode();",
      "metadata": {},
      "id": "cell71",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_flush_stdout_invalid_process_idx():\n    \"\"\"Test that flush_stdout raises ValueError for invalid process_idx.\"\"\"\n    async with MultiprocessPool(\n        printing_worker,\n        num_processes=2,\n        redirect_output=True,\n        buffer_output=True,\n    ) as pool:\n        with pytest.raises(ValueError):\n            await pool.flush_stdout(-1)\n\n        with pytest.raises(ValueError):\n            await pool.flush_stdout(2)  # Only 0 and 1 are valid",
      "metadata": {},
      "id": "cell72",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_flush_stdout_invalid_process_idx();",
      "metadata": {},
      "id": "cell73",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_flush_stdout_before_start():\n    \"\"\"Test that flush_stdout raises PoolNotStarted before start().\"\"\"\n    pool = MultiprocessPool(\n        printing_worker,\n        num_processes=1,\n        redirect_output=True,\n        buffer_output=True,\n    )\n\n    with pytest.raises(PoolNotStarted):\n        await pool.flush_stdout(0)",
      "metadata": {},
      "id": "cell74",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_flush_stdout_before_start();",
      "metadata": {},
      "id": "cell75",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_stdout_content():\n    \"\"\"Test that captured stdout contains expected content.\"\"\"\n    async with MultiprocessPool(\n        printing_worker,\n        num_processes=1,\n        redirect_output=True,\n        buffer_output=True,\n    ) as pool:\n        await asyncio.sleep(0.5)\n\n        await pool.send(0, \"mykey\", \"myvalue\")\n        await pool.recv(timeout=5.0)\n\n        buffer = await pool.flush_stdout(0)\n\n        # Combine all stdout text\n        stdout_text = \"\".join(\n            text for timestamp, is_stdout, text in buffer if is_stdout\n        )\n        stderr_text = \"\".join(\n            text for timestamp, is_stdout, text in buffer if not is_stdout\n        )\n\n        # Check expected content\n        assert \"Worker 0 starting\" in stdout_text\n        assert \"Worker 0 got: mykey=myvalue\" in stdout_text\n        assert \"Worker 0 stderr\" in stderr_text",
      "metadata": {},
      "id": "cell76",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_stdout_content();",
      "metadata": {},
      "id": "cell77",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "nblite_source_hash": "9bc6f192cedd94d9d3bcec5cdc2e1b2102bc8d9b12240eb05296b02ab8b3fdd1"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
