{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Multiprocess Pool Exception Tests\n\nThis notebook provides comprehensive tests and examples for all exception types\nthat can occur in the Multiprocess Pool layer. The MultiprocessPool uses\nsubprocesses with threads, and `multiprocessing.Queue` for communication.\n\n## Exception Types\n\nThe MultiprocessPool can raise the following exceptions:\n\n1. **PoolNotStarted**: Trying to use the pool before calling `start()`\n2. **PoolAlreadyStarted**: Calling `start()` on a running pool\n3. **RecvTimeout**: A receive operation timed out waiting for a message\n4. **WorkerException**: The worker function raised an exception\n5. **WorkerCrashed**: The worker process died unexpectedly\n6. **ValueError**: Invalid worker_id or configuration",
      "metadata": {},
      "id": "cell0"
    },
    {
      "cell_type": "code",
      "source": "#|default_exp pool.test_exceptions_multiprocess",
      "metadata": {},
      "id": "cell1",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nimport pytest\nimport time\nfrom netrun.rpc.base import RecvTimeout\nfrom netrun.pool.base import (\n    PoolError,\n    PoolNotStarted,\n    PoolAlreadyStarted,\n    WorkerException,\n    WorkerCrashed,\n)\nfrom netrun.pool.multiprocess import MultiprocessPool",
      "metadata": {},
      "id": "cell2",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Worker Functions\n\nFor multiprocessing with spawn context, workers must be importable\n(defined at module level in an importable module).\nWe use the workers from tests.pool.workers.",
      "metadata": {},
      "id": "cell3"
    },
    {
      "cell_type": "code",
      "source": "#|export\nfrom tests.pool.workers import echo_worker, compute_worker",
      "metadata": {},
      "id": "cell4",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# PoolNotStarted Exception\n\n`PoolNotStarted` is raised when trying to use the pool before calling `start()`.",
      "metadata": {},
      "id": "cell5"
    },
    {
      "cell_type": "markdown",
      "source": "## 1.1 PoolNotStarted on send()",
      "metadata": {},
      "id": "cell6"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_send_before_start():\n    \"\"\"MultiprocessPool.send() raises PoolNotStarted before start().\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n\n    with pytest.raises(PoolNotStarted) as exc_info:\n        await pool.send(0, \"hello\", \"world\")\n\n    assert \"not been started\" in str(exc_info.value).lower()",
      "metadata": {},
      "id": "cell7",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_send_before_start()\nprint(\"Send before start: raises PoolNotStarted as expected\")",
      "metadata": {},
      "id": "cell8",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Send before start: raises PoolNotStarted as expected\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_recv_before_start():\n    \"\"\"MultiprocessPool.recv() raises PoolNotStarted before start().\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n\n    with pytest.raises(PoolNotStarted):\n        await pool.recv(timeout=0.1)",
      "metadata": {},
      "id": "cell9",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_recv_before_start()\nprint(\"Recv before start: raises PoolNotStarted as expected\")",
      "metadata": {},
      "id": "cell10",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recv before start: raises PoolNotStarted as expected\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_try_recv_before_start():\n    \"\"\"MultiprocessPool.try_recv() raises PoolNotStarted before start().\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n\n    with pytest.raises(PoolNotStarted):\n        await pool.try_recv()",
      "metadata": {},
      "id": "cell11",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_try_recv_before_start()\nprint(\"Try_recv before start: raises PoolNotStarted as expected\")",
      "metadata": {},
      "id": "cell12",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Try_recv before start: raises PoolNotStarted as expected\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_broadcast_before_start():\n    \"\"\"MultiprocessPool.broadcast() raises PoolNotStarted before start().\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n\n    with pytest.raises(PoolNotStarted):\n        await pool.broadcast(\"hello\", \"world\")",
      "metadata": {},
      "id": "cell13",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_broadcast_before_start()\nprint(\"Broadcast before start: raises PoolNotStarted as expected\")",
      "metadata": {},
      "id": "cell14",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcast before start: raises PoolNotStarted as expected\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# PoolAlreadyStarted Exception\n\n`PoolAlreadyStarted` is raised when calling `start()` on a pool that's already running.",
      "metadata": {},
      "id": "cell15"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_start_twice():\n    \"\"\"MultiprocessPool.start() raises PoolAlreadyStarted if already running.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n\n    await pool.start()\n    try:\n        assert pool.is_running\n\n        with pytest.raises(PoolAlreadyStarted) as exc_info:\n            await pool.start()\n\n        assert \"already running\" in str(exc_info.value).lower()\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell16",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_start_twice()\nprint(\"Start twice: raises PoolAlreadyStarted as expected\")",
      "metadata": {},
      "id": "cell17",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start twice: raises PoolAlreadyStarted as expected\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_close_allows_restart():\n    \"\"\"After close(), the pool can be started again.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n\n    # First start\n    await pool.start()\n    await pool.close()\n    assert not pool.is_running\n\n    # Second start should work\n    await pool.start()\n    assert pool.is_running\n    await pool.close()",
      "metadata": {},
      "id": "cell18",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_close_allows_restart()\nprint(\"Close allows restart: pool can be restarted after close\")",
      "metadata": {},
      "id": "cell19",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Close allows restart: pool can be restarted after close\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# RecvTimeout Exception\n\n`RecvTimeout` is raised when `recv()` times out waiting for a message.",
      "metadata": {},
      "id": "cell20"
    },
    {
      "cell_type": "markdown",
      "source": "## 3.1 RecvTimeout Basics",
      "metadata": {},
      "id": "cell21"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_recv_timeout():\n    \"\"\"MultiprocessPool.recv() raises RecvTimeout when timeout expires.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n    await pool.start()\n\n    try:\n        start = time.time()\n        with pytest.raises(RecvTimeout) as exc_info:\n            await pool.recv(timeout=0.1)\n        elapsed = time.time() - start\n\n        assert elapsed >= 0.1\n        assert elapsed < 0.5\n        assert \"timed out\" in str(exc_info.value).lower()\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell22",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_recv_timeout()\nprint(\"Recv timeout: raises RecvTimeout after specified duration\")",
      "metadata": {},
      "id": "cell23",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recv timeout: raises RecvTimeout after specified duration\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_recv_timeout_preserves_pool():\n    \"\"\"After RecvTimeout, the pool is still usable.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n    await pool.start()\n\n    try:\n        # First recv times out\n        with pytest.raises(RecvTimeout):\n            await pool.recv(timeout=0.05)\n\n        # Pool should still be running\n        assert pool.is_running\n\n        # Can still send and receive\n        await pool.send(0, \"hello\", \"world\")\n        msg = await pool.recv(timeout=5.0)\n        assert msg.key == \"echo:hello\"\n        assert msg.data[\"data\"] == \"world\"\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell24",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_recv_timeout_preserves_pool()\nprint(\"Recv timeout: pool remains usable after timeout\")",
      "metadata": {},
      "id": "cell25",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recv timeout: pool remains usable after timeout\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 3.2 try_recv Does NOT Raise RecvTimeout",
      "metadata": {},
      "id": "cell26"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_try_recv_returns_none():\n    \"\"\"MultiprocessPool.try_recv() returns None, never raises RecvTimeout.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n    await pool.start()\n\n    try:\n        result = await pool.try_recv()\n        assert result is None\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell27",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_try_recv_returns_none()\nprint(\"Try_recv: returns None (no RecvTimeout)\")",
      "metadata": {},
      "id": "cell28",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Try_recv: returns None (no RecvTimeout)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# WorkerException\n\n`WorkerException` is raised when a worker's code raises an exception.\nThe exception info is serialized and sent back to the parent.",
      "metadata": {},
      "id": "cell29"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_worker_exception_structure():\n    \"\"\"WorkerException has the expected structure.\"\"\"\n    exc = WorkerException(42, ValueError(\"test\"))\n\n    assert exc.worker_id == 42\n    assert isinstance(exc.original_exception, ValueError)\n    assert \"Worker 42\" in str(exc)\n    assert \"ValueError\" in str(exc)",
      "metadata": {},
      "id": "cell30",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_worker_exception_structure()\nprint(\"WorkerException: has expected structure\")",
      "metadata": {},
      "id": "cell31",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WorkerException: has expected structure\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_worker_exception_dict_form():\n    \"\"\"WorkerException can hold error dict (for unpickleable exceptions).\"\"\"\n    error_dict = {\n        \"type\": \"CustomError\",\n        \"message\": \"Something went wrong\",\n    }\n    exc = WorkerException(0, error_dict)\n\n    assert exc.worker_id == 0\n    assert exc.original_exception == error_dict\n    assert \"CustomError\" in str(exc)\n    assert \"Something went wrong\" in str(exc)",
      "metadata": {},
      "id": "cell32",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_worker_exception_dict_form()\nprint(\"WorkerException: handles error dict form\")",
      "metadata": {},
      "id": "cell33",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WorkerException: handles error dict form\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# WorkerCrashed Exception\n\n`WorkerCrashed` is raised when a worker process dies unexpectedly.",
      "metadata": {},
      "id": "cell34"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_worker_crashed_structure():\n    \"\"\"WorkerCrashed has the expected structure.\"\"\"\n    details = {\"exit_code\": -9, \"reason\": \"Process killed\"}\n    exc = WorkerCrashed(3, details)\n\n    assert exc.worker_id == 3\n    assert exc.details == details\n    assert \"Worker 3\" in str(exc)\n    assert \"crashed\" in str(exc).lower()",
      "metadata": {},
      "id": "cell35",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_worker_crashed_structure()\nprint(\"WorkerCrashed: has expected structure\")",
      "metadata": {},
      "id": "cell36",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WorkerCrashed: has expected structure\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# ValueError (Invalid Configuration)\n\n`ValueError` is raised for invalid configuration or worker_id.",
      "metadata": {},
      "id": "cell37"
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef test_invalid_num_processes():\n    \"\"\"MultiprocessPool raises ValueError for invalid num_processes.\"\"\"\n    with pytest.raises(ValueError) as exc_info:\n        MultiprocessPool(echo_worker, num_processes=0)\n\n    assert \"num_processes\" in str(exc_info.value).lower()\n\n    with pytest.raises(ValueError):\n        MultiprocessPool(echo_worker, num_processes=-1)",
      "metadata": {},
      "id": "cell38",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_invalid_num_processes()\nprint(\"Invalid num_processes: raises ValueError\")",
      "metadata": {},
      "id": "cell39",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid num_processes: raises ValueError\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef test_invalid_threads_per_process():\n    \"\"\"MultiprocessPool raises ValueError for invalid threads_per_process.\"\"\"\n    with pytest.raises(ValueError) as exc_info:\n        MultiprocessPool(echo_worker, num_processes=1, threads_per_process=0)\n\n    assert \"threads_per_process\" in str(exc_info.value).lower()\n\n    with pytest.raises(ValueError):\n        MultiprocessPool(echo_worker, num_processes=1, threads_per_process=-1)",
      "metadata": {},
      "id": "cell40",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_invalid_threads_per_process()\nprint(\"Invalid threads_per_process: raises ValueError\")",
      "metadata": {},
      "id": "cell41",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid threads_per_process: raises ValueError\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_send_invalid_worker_id_negative():\n    \"\"\"send() raises ValueError for negative worker_id.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n    await pool.start()\n\n    try:\n        with pytest.raises(ValueError) as exc_info:\n            await pool.send(-1, \"hello\", \"world\")\n\n        assert \"out of range\" in str(exc_info.value)\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell42",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_send_invalid_worker_id_negative()\nprint(\"Invalid worker_id (negative): raises ValueError\")",
      "metadata": {},
      "id": "cell43",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid worker_id (negative): raises ValueError\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_send_invalid_worker_id_too_large():\n    \"\"\"send() raises ValueError for worker_id >= num_workers.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n    # Total workers = 2 * 2 = 4, valid IDs are 0, 1, 2, 3\n    await pool.start()\n\n    try:\n        with pytest.raises(ValueError) as exc_info:\n            await pool.send(4, \"hello\", \"world\")\n\n        assert \"out of range\" in str(exc_info.value)\n\n        with pytest.raises(ValueError):\n            await pool.send(100, \"hello\", \"world\")\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell44",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_send_invalid_worker_id_too_large()\nprint(\"Invalid worker_id (too large): raises ValueError\")",
      "metadata": {},
      "id": "cell45",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid worker_id (too large): raises ValueError\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# Worker ID Mapping\n\nMultiprocessPool uses flat worker IDs across processes and threads.\nworker_id = process_idx * threads_per_process + thread_idx",
      "metadata": {},
      "id": "cell46"
    },
    {
      "cell_type": "code",
      "source": "#|export\n@pytest.mark.asyncio\nasync def test_worker_id_mapping():\n    \"\"\"Worker IDs are correctly mapped across processes.\"\"\"\n    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n    await pool.start()\n\n    try:\n        assert pool.num_workers == 4\n        assert pool.num_processes == 2\n        assert pool.threads_per_process == 2\n\n        # Send to each worker and verify responses\n        for worker_id in range(4):\n            await pool.send(worker_id, \"test\", worker_id)\n\n        responses = []\n        for _ in range(4):\n            msg = await pool.recv(timeout=5.0)\n            responses.append((msg.worker_id, msg.data[\"worker_id\"]))\n\n        # Each worker should report their correct ID\n        for worker_id, reported_id in responses:\n            assert worker_id == reported_id\n    finally:\n        await pool.close()",
      "metadata": {},
      "id": "cell47",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await test_worker_id_mapping()\nprint(\"Worker ID mapping: correct across processes and threads\")",
      "metadata": {},
      "id": "cell48",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker ID mapping: correct across processes and threads\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# Exception Hierarchy\n\nAll pool-specific exceptions inherit from `PoolError`:",
      "metadata": {},
      "id": "cell49"
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef test_exception_hierarchy():\n    \"\"\"Verify exception hierarchy is correct.\"\"\"\n    assert issubclass(PoolNotStarted, PoolError)\n    assert issubclass(PoolAlreadyStarted, PoolError)\n    assert issubclass(WorkerException, PoolError)\n    assert issubclass(WorkerCrashed, PoolError)\n    assert issubclass(PoolError, Exception)\n\n    # RecvTimeout is from RPC layer, not PoolError\n    assert not issubclass(RecvTimeout, PoolError)",
      "metadata": {},
      "id": "cell50",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "test_exception_hierarchy()\nprint(\"Exception hierarchy: verified\")",
      "metadata": {},
      "id": "cell51",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception hierarchy: verified\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n# Practical Examples",
      "metadata": {},
      "id": "cell52"
    },
    {
      "cell_type": "markdown",
      "source": "## Example: Error Handling with Multiple Workers",
      "metadata": {},
      "id": "cell53"
    },
    {
      "cell_type": "code",
      "source": "@pytest.mark.asyncio\nasync def example_error_handling():\n    \"\"\"Example: Error handling with multiprocess pool.\"\"\"\n    print(\"=\" * 50)\n    print(\"Example: Error Handling\")\n    print(\"=\" * 50)\n\n    async with MultiprocessPool(compute_worker, num_processes=2, threads_per_process=1) as pool:\n        print(f\"  Pool has {pool.num_workers} workers\")\n\n        # Send tasks to workers\n        await pool.send(0, \"square\", 5)\n        await pool.send(1, \"double\", 10)\n\n        # Receive results with error handling\n        for _ in range(2):\n            try:\n                msg = await pool.recv(timeout=5.0)\n                print(f\"  Worker {msg.worker_id}: {msg.key} = {msg.data}\")\n            except RecvTimeout:\n                print(\"  Timeout waiting for response\")\n            except WorkerException as e:\n                print(f\"  Worker {e.worker_id} failed: {e}\")\n            except WorkerCrashed as e:\n                print(f\"  Worker {e.worker_id} crashed: {e.details}\")\n\n    print(\"Done!\")",
      "metadata": {},
      "id": "cell54",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await example_error_handling()",
      "metadata": {},
      "id": "cell55",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Example: Error Handling\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Pool has 2 workers\n",
            "  Worker 0: result = 25\n",
            "  Worker 1: result = 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "nblite_source_hash": "51a73fa83c6f781d4a38114581ad69f2c4f5e24a0b7882c53e0123d1e6784930"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
