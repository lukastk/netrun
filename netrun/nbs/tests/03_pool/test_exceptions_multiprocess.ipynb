{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multiprocess Pool Exception Tests\n",
        "\n",
        "This notebook provides comprehensive tests and examples for all exception types\n",
        "that can occur in the Multiprocess Pool layer. The MultiprocessPool uses\n",
        "subprocesses with threads, and `multiprocessing.Queue` for communication.\n",
        "\n",
        "## Exception Types\n",
        "\n",
        "The MultiprocessPool can raise the following exceptions:\n",
        "\n",
        "1. **PoolNotStarted**: Trying to use the pool before calling `start()`\n",
        "2. **PoolAlreadyStarted**: Calling `start()` on a running pool\n",
        "3. **RecvTimeout**: A receive operation timed out waiting for a message\n",
        "4. **WorkerException**: The worker function raised an exception\n",
        "5. **WorkerCrashed**: The worker process died unexpectedly\n",
        "6. **ValueError**: Invalid worker_id or configuration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp pool.test_exceptions_multiprocess"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import pytest\n",
        "import asyncio\n",
        "import time\n",
        "from netrun.rpc.base import ChannelClosed, RecvTimeout\n",
        "from netrun.pool.base import (\n",
        "    PoolError,\n",
        "    PoolNotStarted,\n",
        "    PoolAlreadyStarted,\n",
        "    WorkerException,\n",
        "    WorkerCrashed,\n",
        ")\n",
        "from netrun.pool.multiprocess import MultiprocessPool"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Worker Functions\n",
        "\n",
        "For multiprocessing with spawn context, workers must be importable\n",
        "(defined at module level in an importable module).\n",
        "We use the workers from tests.pool.workers."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from tests.pool.workers import echo_worker, compute_worker, raising_worker, slow_worker"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# PoolNotStarted Exception\n",
        "\n",
        "`PoolNotStarted` is raised when trying to use the pool before calling `start()`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 PoolNotStarted on send()"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_before_start():\n",
        "    \"\"\"MultiprocessPool.send() raises PoolNotStarted before start().\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted) as exc_info:\n",
        "        await pool.send(0, \"hello\", \"world\")\n",
        "\n",
        "    assert \"not been started\" in str(exc_info.value).lower()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_before_start()\n",
        "print(\"Send before start: raises PoolNotStarted as expected\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_recv_before_start():\n",
        "    \"\"\"MultiprocessPool.recv() raises PoolNotStarted before start().\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.recv(timeout=0.1)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_recv_before_start()\n",
        "print(\"Recv before start: raises PoolNotStarted as expected\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_try_recv_before_start():\n",
        "    \"\"\"MultiprocessPool.try_recv() raises PoolNotStarted before start().\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.try_recv()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_try_recv_before_start()\n",
        "print(\"Try_recv before start: raises PoolNotStarted as expected\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_broadcast_before_start():\n",
        "    \"\"\"MultiprocessPool.broadcast() raises PoolNotStarted before start().\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    with pytest.raises(PoolNotStarted):\n",
        "        await pool.broadcast(\"hello\", \"world\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_broadcast_before_start()\n",
        "print(\"Broadcast before start: raises PoolNotStarted as expected\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# PoolAlreadyStarted Exception\n",
        "\n",
        "`PoolAlreadyStarted` is raised when calling `start()` on a pool that's already running."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_start_twice():\n",
        "    \"\"\"MultiprocessPool.start() raises PoolAlreadyStarted if already running.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    await pool.start()\n",
        "    try:\n",
        "        assert pool.is_running\n",
        "\n",
        "        with pytest.raises(PoolAlreadyStarted) as exc_info:\n",
        "            await pool.start()\n",
        "\n",
        "        assert \"already running\" in str(exc_info.value).lower()\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_start_twice()\n",
        "print(\"Start twice: raises PoolAlreadyStarted as expected\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_close_allows_restart():\n",
        "    \"\"\"After close(), the pool can be started again.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "\n",
        "    # First start\n",
        "    await pool.start()\n",
        "    await pool.close()\n",
        "    assert not pool.is_running\n",
        "\n",
        "    # Second start should work\n",
        "    await pool.start()\n",
        "    assert pool.is_running\n",
        "    await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_close_allows_restart()\n",
        "print(\"Close allows restart: pool can be restarted after close\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# RecvTimeout Exception\n",
        "\n",
        "`RecvTimeout` is raised when `recv()` times out waiting for a message."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 RecvTimeout Basics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_recv_timeout():\n",
        "    \"\"\"MultiprocessPool.recv() raises RecvTimeout when timeout expires.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        start = time.time()\n",
        "        with pytest.raises(RecvTimeout) as exc_info:\n",
        "            await pool.recv(timeout=0.1)\n",
        "        elapsed = time.time() - start\n",
        "\n",
        "        assert elapsed >= 0.1\n",
        "        assert elapsed < 0.5\n",
        "        assert \"timed out\" in str(exc_info.value).lower()\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_recv_timeout()\n",
        "print(\"Recv timeout: raises RecvTimeout after specified duration\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_recv_timeout_preserves_pool():\n",
        "    \"\"\"After RecvTimeout, the pool is still usable.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        # First recv times out\n",
        "        with pytest.raises(RecvTimeout):\n",
        "            await pool.recv(timeout=0.05)\n",
        "\n",
        "        # Pool should still be running\n",
        "        assert pool.is_running\n",
        "\n",
        "        # Can still send and receive\n",
        "        await pool.send(0, \"hello\", \"world\")\n",
        "        msg = await pool.recv(timeout=5.0)\n",
        "        assert msg.key == \"echo:hello\"\n",
        "        assert msg.data[\"data\"] == \"world\"\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_recv_timeout_preserves_pool()\n",
        "print(\"Recv timeout: pool remains usable after timeout\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 try_recv Does NOT Raise RecvTimeout"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_try_recv_returns_none():\n",
        "    \"\"\"MultiprocessPool.try_recv() returns None, never raises RecvTimeout.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=1, threads_per_process=1)\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        result = await pool.try_recv()\n",
        "        assert result is None\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_try_recv_returns_none()\n",
        "print(\"Try_recv: returns None (no RecvTimeout)\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# WorkerException\n",
        "\n",
        "`WorkerException` is raised when a worker's code raises an exception.\n",
        "The exception info is serialized and sent back to the parent."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_worker_exception_structure():\n",
        "    \"\"\"WorkerException has the expected structure.\"\"\"\n",
        "    exc = WorkerException(42, ValueError(\"test\"))\n",
        "\n",
        "    assert exc.worker_id == 42\n",
        "    assert isinstance(exc.original_exception, ValueError)\n",
        "    assert \"Worker 42\" in str(exc)\n",
        "    assert \"ValueError\" in str(exc)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_worker_exception_structure()\n",
        "print(\"WorkerException: has expected structure\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_worker_exception_dict_form():\n",
        "    \"\"\"WorkerException can hold error dict (for unpickleable exceptions).\"\"\"\n",
        "    error_dict = {\n",
        "        \"type\": \"CustomError\",\n",
        "        \"message\": \"Something went wrong\",\n",
        "    }\n",
        "    exc = WorkerException(0, error_dict)\n",
        "\n",
        "    assert exc.worker_id == 0\n",
        "    assert exc.original_exception == error_dict\n",
        "    assert \"CustomError\" in str(exc)\n",
        "    assert \"Something went wrong\" in str(exc)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_worker_exception_dict_form()\n",
        "print(\"WorkerException: handles error dict form\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# WorkerCrashed Exception\n",
        "\n",
        "`WorkerCrashed` is raised when a worker process dies unexpectedly."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_worker_crashed_structure():\n",
        "    \"\"\"WorkerCrashed has the expected structure.\"\"\"\n",
        "    details = {\"exit_code\": -9, \"reason\": \"Process killed\"}\n",
        "    exc = WorkerCrashed(3, details)\n",
        "\n",
        "    assert exc.worker_id == 3\n",
        "    assert exc.details == details\n",
        "    assert \"Worker 3\" in str(exc)\n",
        "    assert \"crashed\" in str(exc).lower()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_worker_crashed_structure()\n",
        "print(\"WorkerCrashed: has expected structure\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ValueError (Invalid Configuration)\n",
        "\n",
        "`ValueError` is raised for invalid configuration or worker_id."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_invalid_num_processes():\n",
        "    \"\"\"MultiprocessPool raises ValueError for invalid num_processes.\"\"\"\n",
        "    with pytest.raises(ValueError) as exc_info:\n",
        "        MultiprocessPool(echo_worker, num_processes=0)\n",
        "\n",
        "    assert \"num_processes\" in str(exc_info.value).lower()\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=-1)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_invalid_num_processes()\n",
        "print(\"Invalid num_processes: raises ValueError\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_invalid_threads_per_process():\n",
        "    \"\"\"MultiprocessPool raises ValueError for invalid threads_per_process.\"\"\"\n",
        "    with pytest.raises(ValueError) as exc_info:\n",
        "        MultiprocessPool(echo_worker, num_processes=1, threads_per_process=0)\n",
        "\n",
        "    assert \"threads_per_process\" in str(exc_info.value).lower()\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        MultiprocessPool(echo_worker, num_processes=1, threads_per_process=-1)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_invalid_threads_per_process()\n",
        "print(\"Invalid threads_per_process: raises ValueError\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_invalid_worker_id_negative():\n",
        "    \"\"\"send() raises ValueError for negative worker_id.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        with pytest.raises(ValueError) as exc_info:\n",
        "            await pool.send(-1, \"hello\", \"world\")\n",
        "\n",
        "        assert \"out of range\" in str(exc_info.value)\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_invalid_worker_id_negative()\n",
        "print(\"Invalid worker_id (negative): raises ValueError\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_send_invalid_worker_id_too_large():\n",
        "    \"\"\"send() raises ValueError for worker_id >= num_workers.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n",
        "    # Total workers = 2 * 2 = 4, valid IDs are 0, 1, 2, 3\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        with pytest.raises(ValueError) as exc_info:\n",
        "            await pool.send(4, \"hello\", \"world\")\n",
        "\n",
        "        assert \"out of range\" in str(exc_info.value)\n",
        "\n",
        "        with pytest.raises(ValueError):\n",
        "            await pool.send(100, \"hello\", \"world\")\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_send_invalid_worker_id_too_large()\n",
        "print(\"Invalid worker_id (too large): raises ValueError\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Worker ID Mapping\n",
        "\n",
        "MultiprocessPool uses flat worker IDs across processes and threads.\n",
        "worker_id = process_idx * threads_per_process + thread_idx"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@pytest.mark.asyncio\n",
        "async def test_worker_id_mapping():\n",
        "    \"\"\"Worker IDs are correctly mapped across processes.\"\"\"\n",
        "    pool = MultiprocessPool(echo_worker, num_processes=2, threads_per_process=2)\n",
        "    await pool.start()\n",
        "\n",
        "    try:\n",
        "        assert pool.num_workers == 4\n",
        "        assert pool.num_processes == 2\n",
        "        assert pool.threads_per_process == 2\n",
        "\n",
        "        # Send to each worker and verify responses\n",
        "        for worker_id in range(4):\n",
        "            await pool.send(worker_id, \"test\", worker_id)\n",
        "\n",
        "        responses = []\n",
        "        for _ in range(4):\n",
        "            msg = await pool.recv(timeout=5.0)\n",
        "            responses.append((msg.worker_id, msg.data[\"worker_id\"]))\n",
        "\n",
        "        # Each worker should report their correct ID\n",
        "        for worker_id, reported_id in responses:\n",
        "            assert worker_id == reported_id\n",
        "    finally:\n",
        "        await pool.close()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await test_worker_id_mapping()\n",
        "print(\"Worker ID mapping: correct across processes and threads\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Exception Hierarchy\n",
        "\n",
        "All pool-specific exceptions inherit from `PoolError`:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def test_exception_hierarchy():\n",
        "    \"\"\"Verify exception hierarchy is correct.\"\"\"\n",
        "    assert issubclass(PoolNotStarted, PoolError)\n",
        "    assert issubclass(PoolAlreadyStarted, PoolError)\n",
        "    assert issubclass(WorkerException, PoolError)\n",
        "    assert issubclass(WorkerCrashed, PoolError)\n",
        "    assert issubclass(PoolError, Exception)\n",
        "\n",
        "    # RecvTimeout is from RPC layer, not PoolError\n",
        "    assert not issubclass(RecvTimeout, PoolError)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_exception_hierarchy()\n",
        "print(\"Exception hierarchy: verified\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Practical Examples"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Error Handling with Multiple Workers"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "@pytest.mark.asyncio\n",
        "async def example_error_handling():\n",
        "    \"\"\"Example: Error handling with multiprocess pool.\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Example: Error Handling\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    async with MultiprocessPool(compute_worker, num_processes=2, threads_per_process=1) as pool:\n",
        "        print(f\"  Pool has {pool.num_workers} workers\")\n",
        "\n",
        "        # Send tasks to workers\n",
        "        await pool.send(0, \"square\", 5)\n",
        "        await pool.send(1, \"double\", 10)\n",
        "\n",
        "        # Receive results with error handling\n",
        "        for _ in range(2):\n",
        "            try:\n",
        "                msg = await pool.recv(timeout=5.0)\n",
        "                print(f\"  Worker {msg.worker_id}: {msg.key} = {msg.data}\")\n",
        "            except RecvTimeout:\n",
        "                print(\"  Timeout waiting for response\")\n",
        "            except WorkerException as e:\n",
        "                print(f\"  Worker {e.worker_id} failed: {e}\")\n",
        "            except WorkerCrashed as e:\n",
        "                print(f\"  Worker {e.worker_id} crashed: {e.details}\")\n",
        "\n",
        "    print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "await example_error_handling()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
