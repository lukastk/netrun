{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Example 02: Error Handling and Retries\n\nThis example demonstrates netrun's error handling capabilities:\n\n- Configuring retries for unreliable nodes\n- Using the dead letter queue (DLQ) for failed packets\n- Error callbacks and failure handlers\n- Different `on_error` modes\n\n## Scenario\n\nWe simulate a pipeline where the Processor node has a chance of failing.\nWith retries configured, it will automatically retry on failure.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|default_exp 02_error_handling",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nimport random\nfrom netrun import (\n    # Graph building\n    Graph,\n    Node,\n    Edge,\n    Port,\n    PortType,\n    PortRef,\n    PortState,\n    MaxSalvos,\n    SalvoCondition,\n    SalvoConditionTerm,\n    # Net and configuration\n    Net,\n    NetState,\n    # DLQ\n    DeadLetterEntry,\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 1: Create a Simple Pipeline\n\nSource -> Processor (unreliable) -> Sink",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nsource_node = Node(\n    name=\"Source\",\n    out_ports={\"out\": Port()},\n    out_salvo_conditions={\n        \"send\": SalvoCondition(\n            MaxSalvos.infinite(),\n            \"out\",\n            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n        )\n    }\n)\n\nprocessor_node = Node(\n    name=\"Processor\",\n    in_ports={\"in\": Port()},\n    out_ports={\"out\": Port()},\n    in_salvo_conditions={\n        \"receive\": SalvoCondition(\n            MaxSalvos.finite(1),\n            \"in\",\n            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n        )\n    },\n    out_salvo_conditions={\n        \"send\": SalvoCondition(\n            MaxSalvos.infinite(),\n            \"out\",\n            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n        )\n    }\n)\n\nsink_node = Node(\n    name=\"Sink\",\n    in_ports={\"in\": Port()},\n    in_salvo_conditions={\n        \"receive\": SalvoCondition(\n            MaxSalvos.finite(1),\n            \"in\",\n            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n        )\n    }\n)\n\nedges = [\n    Edge(\n        PortRef(\"Source\", PortType.Output, \"out\"),\n        PortRef(\"Processor\", PortType.Input, \"in\")\n    ),\n    Edge(\n        PortRef(\"Processor\", PortType.Output, \"out\"),\n        PortRef(\"Sink\", PortType.Input, \"in\")\n    ),\n]\n\ngraph = Graph([source_node, processor_node, sink_node], edges)\nprint(f\"Created pipeline: {list(graph.nodes().keys())}\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 2: Configure Net with Error Handling\n\nWe configure:\n- `on_error=\"continue\"` to keep processing other nodes on failure\n- An error callback to log errors\n- DLQ in memory mode",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Track errors for demonstration\nerror_log = []\n\ndef error_callback(exception, node_name, epoch_id):\n    \"\"\"Called when a node fails after all retries.\"\"\"\n    error_log.append({\n        \"node\": node_name,\n        \"error\": str(exception),\n        \"epoch_id\": epoch_id[:8] + \"...\",\n    })\n    print(f\"[ERROR] {node_name} failed: {exception}\")\n\n# Create net with error handling configured\nnet = Net(\n    graph,\n    consumed_packet_storage=True,\n    on_error=\"continue\",  # Keep running on errors\n    error_callback=error_callback,\n    dead_letter_queue=\"memory\",\n)\n\nprint(f\"Created Net with on_error='{net._on_error}'\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 3: Define Node Functions with Retries\n\nThe Processor has a 60% failure rate on first attempt.\nWith retries, most packets should eventually succeed.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Tracking for demonstration\nexecution_log = []\nresults = []\n\n# Simulate unreliable processing\nfail_rate = 0.6\nrandom.seed(42)  # For reproducibility\n\ndef source_exec(ctx, packets):\n    \"\"\"Generate multiple data packets.\"\"\"\n    execution_log.append(f\"Source: generating packets\")\n    for i in range(3):\n        pkt = ctx.create_packet({\"id\": i, \"data\": f\"item-{i}\"})\n        ctx.load_output_port(\"out\", pkt)\n        ctx.send_output_salvo(\"send\")\n    execution_log.append(f\"Source: sent 3 packets\")\n\ndef processor_exec(ctx, packets):\n    \"\"\"Process data with simulated failures.\"\"\"\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            value = ctx.consume_packet(pkt)\n\n            # Simulate unreliable processing\n            # Fail more often on first attempts, less on retries\n            adjusted_fail_rate = fail_rate / (ctx.retry_count + 1)\n            if random.random() < adjusted_fail_rate:\n                execution_log.append(\n                    f\"Processor: FAILED on {value['id']} (attempt {ctx.retry_count + 1})\"\n                )\n                raise RuntimeError(f\"Processing failed for item {value['id']}\")\n\n            execution_log.append(\n                f\"Processor: processed {value['id']} (attempt {ctx.retry_count + 1})\"\n            )\n\n            # Create output\n            output = {**value, \"processed\": True}\n            out_pkt = ctx.create_packet(output)\n            ctx.load_output_port(\"out\", out_pkt)\n            ctx.send_output_salvo(\"send\")\n\ndef processor_failed(failure_ctx):\n    \"\"\"Called after each failure.\"\"\"\n    execution_log.append(\n        f\"Processor: failed_func called (retry {failure_ctx.retry_count})\"\n    )\n\ndef sink_exec(ctx, packets):\n    \"\"\"Collect processed results.\"\"\"\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            value = ctx.consume_packet(pkt)\n            results.append(value)\n            execution_log.append(f\"Sink: received {value['id']}\")\n\n# Register execution functions\nnet.set_node_exec(\"Source\", source_exec)\nnet.set_node_exec(\"Processor\", processor_exec, failed_func=processor_failed)\nnet.set_node_exec(\"Sink\", sink_exec)\n\n# Configure Processor with retries\nnet.set_node_config(\n    \"Processor\",\n    retries=3,               # Up to 3 retries (4 total attempts)\n    retry_wait=0.01,         # Small delay between retries\n    defer_net_actions=True,  # Required for retries\n)\n\nprint(\"Node functions and retry configuration set up\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 4: Run the Pipeline",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Clear tracking\nexecution_log.clear()\nresults.clear()\nerror_log.clear()\n\n# Inject source epoch\nnet.inject_source_epoch(\"Source\")\n\nprint(\"Running pipeline with unreliable Processor...\\n\")\nnet.start()\n\nprint(\"\\n--- Execution Log ---\")\nfor entry in execution_log:\n    print(f\"  {entry}\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 5: Analyze Results",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nprint(\"\\n--- Results ---\")\nprint(f\"Successfully processed: {len(results)} items\")\nfor r in results:\n    print(f\"  {r}\")\n\nprint(f\"\\n--- Dead Letter Queue ---\")\ndlq_entries = net.dead_letter_queue.get_all()\nprint(f\"Failed items in DLQ: {len(dlq_entries)}\")\nfor entry in dlq_entries:\n    print(f\"  Node: {entry.node_name}\")\n    print(f\"  Error: {entry.exception}\")\n    print(f\"  Retries: {entry.retry_count}\")\n    print(f\"  Input packets: {entry.input_packets}\")\n\nprint(f\"\\n--- Error Log ---\")\nprint(f\"Total errors (after retries exhausted): {len(error_log)}\")\nfor err in error_log:\n    print(f\"  {err}\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 6: Demonstrate Different on_error Modes\n\nLet's create a new net with `on_error=\"raise\"` to see the difference.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nprint(\"\\n\" + \"=\"*60)\nprint(\"Demonstrating on_error='raise' mode\")\nprint(\"=\"*60 + \"\\n\")\n\n# Create a new net with raise mode\nnet_raise = Net(\n    graph,\n    on_error=\"raise\",  # Raise exception on error\n)\n\ncall_count = [0]\n\ndef source_exec_raise(ctx, packets):\n    pkt = ctx.create_packet({\"id\": 0})\n    ctx.load_output_port(\"out\", pkt)\n    ctx.send_output_salvo(\"send\")\n\ndef processor_exec_raise(ctx, packets):\n    call_count[0] += 1\n    raise ValueError(\"Always fails!\")\n\ndef sink_exec_raise(ctx, packets):\n    pass\n\nnet_raise.set_node_exec(\"Source\", source_exec_raise)\nnet_raise.set_node_exec(\"Processor\", processor_exec_raise)\nnet_raise.set_node_exec(\"Sink\", sink_exec_raise)\n\nnet_raise.inject_source_epoch(\"Source\")\n\ntry:\n    net_raise.start()\nexcept Exception as e:\n    print(f\"Caught exception: {type(e).__name__}\")\n    print(f\"  Message: {e}\")\n    print(f\"  Net state: {net_raise.state}\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Summary\n\nThis example demonstrated:\n\n1. **Retry Configuration**: Using `retries` and `retry_wait` for unreliable nodes\n2. **Deferred Actions**: Required (`defer_net_actions=True`) when using retries\n3. **Failed Function**: `failed_func` is called after each failure\n4. **Dead Letter Queue**: Failed packets (after all retries) go to the DLQ\n5. **Error Callback**: `error_callback` is called after retries are exhausted\n6. **on_error Modes**:\n   - `\"continue\"`: Keep running other nodes, put failed epoch in DLQ\n   - `\"pause\"`: Stop starting new epochs\n   - `\"raise\"`: Pause then raise exception\n\nKey points:\n- Retries require `defer_net_actions=True` so actions can be rolled back\n- The retry context provides info about previous attempts\n- DLQ entries contain full context for debugging and recovery",
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
