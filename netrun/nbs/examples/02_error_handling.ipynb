{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Example 02: Error Handling and Retries\n",
        "\n",
        "This example demonstrates netrun's error handling capabilities:\n",
        "\n",
        "- Configuring retries for unreliable nodes\n",
        "- Using the dead letter queue (DLQ) for failed packets\n",
        "- Error callbacks and failure handlers\n",
        "- Different `on_error` modes\n",
        "\n",
        "## Scenario\n",
        "\n",
        "We simulate a pipeline where the Processor node has a chance of failing.\n",
        "With retries configured, it will automatically retry on failure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp 02_error_handling"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import random\n",
        "from netrun.core import (\n",
        "    # Graph building\n",
        "    Graph,\n",
        "    Node,\n",
        "    Edge,\n",
        "    Port,\n",
        "    PortType,\n",
        "    PortRef,\n",
        "    PortState,\n",
        "    MaxSalvos,\n",
        "    SalvoCondition,\n",
        "    SalvoConditionTerm,\n",
        "    # Net and configuration\n",
        "    Net,\n",
        "    NetState,\n",
        "    # DLQ\n",
        "    DeadLetterEntry,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Create a Simple Pipeline\n",
        "\n",
        "Source -> Processor (unreliable) -> Sink"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "source_node = Node(\n",
        "    name=\"Source\",\n",
        "    out_ports={\"out\": Port()},\n",
        "    out_salvo_conditions={\n",
        "        \"send\": SalvoCondition(\n",
        "            MaxSalvos.infinite(),\n",
        "            \"out\",\n",
        "            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "processor_node = Node(\n",
        "    name=\"Processor\",\n",
        "    in_ports={\"in\": Port()},\n",
        "    out_ports={\"out\": Port()},\n",
        "    in_salvo_conditions={\n",
        "        \"receive\": SalvoCondition(\n",
        "            MaxSalvos.finite(1),\n",
        "            \"in\",\n",
        "            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n",
        "        )\n",
        "    },\n",
        "    out_salvo_conditions={\n",
        "        \"send\": SalvoCondition(\n",
        "            MaxSalvos.infinite(),\n",
        "            \"out\",\n",
        "            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "sink_node = Node(\n",
        "    name=\"Sink\",\n",
        "    in_ports={\"in\": Port()},\n",
        "    in_salvo_conditions={\n",
        "        \"receive\": SalvoCondition(\n",
        "            MaxSalvos.finite(1),\n",
        "            \"in\",\n",
        "            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "edges = [\n",
        "    Edge(\n",
        "        PortRef(\"Source\", PortType.Output, \"out\"),\n",
        "        PortRef(\"Processor\", PortType.Input, \"in\")\n",
        "    ),\n",
        "    Edge(\n",
        "        PortRef(\"Processor\", PortType.Output, \"out\"),\n",
        "        PortRef(\"Sink\", PortType.Input, \"in\")\n",
        "    ),\n",
        "]\n",
        "\n",
        "graph = Graph([source_node, processor_node, sink_node], edges)\n",
        "print(f\"Created pipeline: {list(graph.nodes().keys())}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Configure Net with Error Handling\n",
        "\n",
        "We configure:\n",
        "- `on_error=\"continue\"` to keep processing other nodes on failure\n",
        "- An error callback to log errors\n",
        "- DLQ in memory mode"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "# Track errors for demonstration\n",
        "error_log = []\n",
        "\n",
        "def error_callback(exception, node_name, epoch_id):\n",
        "    \"\"\"Called when a node fails after all retries.\"\"\"\n",
        "    error_log.append({\n",
        "        \"node\": node_name,\n",
        "        \"error\": str(exception),\n",
        "        \"epoch_id\": epoch_id[:8] + \"...\",\n",
        "    })\n",
        "    print(f\"[ERROR] {node_name} failed: {exception}\")\n",
        "\n",
        "# Create net with error handling configured\n",
        "net = Net(\n",
        "    graph,\n",
        "    consumed_packet_storage=True,\n",
        "    on_error=\"continue\",  # Keep running on errors\n",
        "    error_callback=error_callback,\n",
        "    dead_letter_queue=\"memory\",\n",
        ")\n",
        "\n",
        "print(f\"Created Net with on_error='{net._on_error}'\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Define Node Functions with Retries\n",
        "\n",
        "The Processor has a 60% failure rate on first attempt.\n",
        "With retries, most packets should eventually succeed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "# Tracking for demonstration\n",
        "execution_log = []\n",
        "results = []\n",
        "\n",
        "# Simulate unreliable processing\n",
        "fail_rate = 0.6\n",
        "random.seed(42)  # For reproducibility\n",
        "\n",
        "def source_exec(ctx, packets):\n",
        "    \"\"\"Generate multiple data packets.\"\"\"\n",
        "    execution_log.append(f\"Source: generating packets\")\n",
        "    for i in range(3):\n",
        "        pkt = ctx.create_packet({\"id\": i, \"data\": f\"item-{i}\"})\n",
        "        ctx.load_output_port(\"out\", pkt)\n",
        "        ctx.send_output_salvo(\"send\")\n",
        "    execution_log.append(f\"Source: sent 3 packets\")\n",
        "\n",
        "def processor_exec(ctx, packets):\n",
        "    \"\"\"Process data with simulated failures.\"\"\"\n",
        "    for port_name, pkts in packets.items():\n",
        "        for pkt in pkts:\n",
        "            value = ctx.consume_packet(pkt)\n",
        "\n",
        "            # Simulate unreliable processing\n",
        "            # Fail more often on first attempts, less on retries\n",
        "            adjusted_fail_rate = fail_rate / (ctx.retry_count + 1)\n",
        "            if random.random() < adjusted_fail_rate:\n",
        "                execution_log.append(\n",
        "                    f\"Processor: FAILED on {value['id']} (attempt {ctx.retry_count + 1})\"\n",
        "                )\n",
        "                raise RuntimeError(f\"Processing failed for item {value['id']}\")\n",
        "\n",
        "            execution_log.append(\n",
        "                f\"Processor: processed {value['id']} (attempt {ctx.retry_count + 1})\"\n",
        "            )\n",
        "\n",
        "            # Create output\n",
        "            output = {**value, \"processed\": True}\n",
        "            out_pkt = ctx.create_packet(output)\n",
        "            ctx.load_output_port(\"out\", out_pkt)\n",
        "            ctx.send_output_salvo(\"send\")\n",
        "\n",
        "def processor_failed(failure_ctx):\n",
        "    \"\"\"Called after each failure.\"\"\"\n",
        "    execution_log.append(\n",
        "        f\"Processor: failed_func called (retry {failure_ctx.retry_count})\"\n",
        "    )\n",
        "\n",
        "def sink_exec(ctx, packets):\n",
        "    \"\"\"Collect processed results.\"\"\"\n",
        "    for port_name, pkts in packets.items():\n",
        "        for pkt in pkts:\n",
        "            value = ctx.consume_packet(pkt)\n",
        "            results.append(value)\n",
        "            execution_log.append(f\"Sink: received {value['id']}\")\n",
        "\n",
        "# Register execution functions\n",
        "net.set_node_exec(\"Source\", source_exec)\n",
        "net.set_node_exec(\"Processor\", processor_exec, failed_func=processor_failed)\n",
        "net.set_node_exec(\"Sink\", sink_exec)\n",
        "\n",
        "# Configure Processor with retries\n",
        "net.set_node_config(\n",
        "    \"Processor\",\n",
        "    retries=3,               # Up to 3 retries (4 total attempts)\n",
        "    retry_wait=0.01,         # Small delay between retries\n",
        "    defer_net_actions=True,  # Required for retries\n",
        ")\n",
        "\n",
        "print(\"Node functions and retry configuration set up\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Run the Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "# Clear tracking\n",
        "execution_log.clear()\n",
        "results.clear()\n",
        "error_log.clear()\n",
        "\n",
        "# Inject source epoch\n",
        "net.inject_source_epoch(\"Source\")\n",
        "\n",
        "print(\"Running pipeline with unreliable Processor...\\n\")\n",
        "net.start()\n",
        "\n",
        "print(\"\\n--- Execution Log ---\")\n",
        "for entry in execution_log:\n",
        "    print(f\"  {entry}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Analyze Results"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "print(\"\\n--- Results ---\")\n",
        "print(f\"Successfully processed: {len(results)} items\")\n",
        "for r in results:\n",
        "    print(f\"  {r}\")\n",
        "\n",
        "print(f\"\\n--- Dead Letter Queue ---\")\n",
        "dlq_entries = net.dead_letter_queue.get_all()\n",
        "print(f\"Failed items in DLQ: {len(dlq_entries)}\")\n",
        "for entry in dlq_entries:\n",
        "    print(f\"  Node: {entry.node_name}\")\n",
        "    print(f\"  Error: {entry.exception}\")\n",
        "    print(f\"  Retries: {entry.retry_count}\")\n",
        "    print(f\"  Input packets: {entry.input_packets}\")\n",
        "\n",
        "print(f\"\\n--- Error Log ---\")\n",
        "print(f\"Total errors (after retries exhausted): {len(error_log)}\")\n",
        "for err in error_log:\n",
        "    print(f\"  {err}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Demonstrate Different on_error Modes\n",
        "\n",
        "Let's create a new net with `on_error=\"raise\"` to see the difference."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Demonstrating on_error='raise' mode\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Create a new net with raise mode\n",
        "net_raise = Net(\n",
        "    graph,\n",
        "    on_error=\"raise\",  # Raise exception on error\n",
        ")\n",
        "\n",
        "call_count = [0]\n",
        "\n",
        "def source_exec_raise(ctx, packets):\n",
        "    pkt = ctx.create_packet({\"id\": 0})\n",
        "    ctx.load_output_port(\"out\", pkt)\n",
        "    ctx.send_output_salvo(\"send\")\n",
        "\n",
        "def processor_exec_raise(ctx, packets):\n",
        "    call_count[0] += 1\n",
        "    raise ValueError(\"Always fails!\")\n",
        "\n",
        "def sink_exec_raise(ctx, packets):\n",
        "    pass\n",
        "\n",
        "net_raise.set_node_exec(\"Source\", source_exec_raise)\n",
        "net_raise.set_node_exec(\"Processor\", processor_exec_raise)\n",
        "net_raise.set_node_exec(\"Sink\", sink_exec_raise)\n",
        "\n",
        "net_raise.inject_source_epoch(\"Source\")\n",
        "\n",
        "try:\n",
        "    net_raise.start()\n",
        "except Exception as e:\n",
        "    print(f\"Caught exception: {type(e).__name__}\")\n",
        "    print(f\"  Message: {e}\")\n",
        "    print(f\"  Net state: {net_raise.state}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "This example demonstrated:\n",
        "\n",
        "1. **Retry Configuration**: Using `retries` and `retry_wait` for unreliable nodes\n",
        "2. **Deferred Actions**: Required (`defer_net_actions=True`) when using retries\n",
        "3. **Failed Function**: `failed_func` is called after each failure\n",
        "4. **Dead Letter Queue**: Failed packets (after all retries) go to the DLQ\n",
        "5. **Error Callback**: `error_callback` is called after retries are exhausted\n",
        "6. **on_error Modes**:\n",
        "   - `\"continue\"`: Keep running other nodes, put failed epoch in DLQ\n",
        "   - `\"pause\"`: Stop starting new epochs\n",
        "   - `\"raise\"`: Pause then raise exception\n",
        "\n",
        "Key points:\n",
        "- Retries require `defer_net_actions=True` so actions can be rolled back\n",
        "- The retry context provides info about previous attempts\n",
        "- DLQ entries contain full context for debugging and recovery"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
