{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Example 03: Async Node Functions\n\nThis example demonstrates async execution in `netrun`:\n\n- Using async `exec_func` for nodes\n- Mixing sync and async nodes in the same pipeline\n- Using async start/stop functions\n- Async value functions for lazy evaluation\n\n## The Pipeline\n\n```\nSource (async) -> Processor (sync) -> Sink (async)\n```\n\nThis demonstrates that sync and async nodes can be freely mixed.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|default_exp 03_async_nodes",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nimport asyncio\nfrom netrun import (\n    # Graph building\n    Graph,\n    Node,\n    Edge,\n    Port,\n    PortType,\n    PortRef,\n    PortState,\n    MaxSalvos,\n    SalvoCondition,\n    SalvoConditionTerm,\n    # Net and configuration\n    Net,\n    NetState,\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 1: Define the Graph\n\nWe create a three-node pipeline with mixed sync/async nodes.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nsource_node = Node(\n    name=\"Source\",\n    out_ports={\"out\": Port()},\n    out_salvo_conditions={\n        \"send\": SalvoCondition(\n            MaxSalvos.infinite(),\n            \"out\",\n            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n        )\n    }\n)\n\nprocessor_node = Node(\n    name=\"Processor\",\n    in_ports={\"in\": Port()},\n    out_ports={\"out\": Port()},\n    in_salvo_conditions={\n        \"receive\": SalvoCondition(\n            MaxSalvos.finite(1),\n            \"in\",\n            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n        )\n    },\n    out_salvo_conditions={\n        \"send\": SalvoCondition(\n            MaxSalvos.infinite(),\n            \"out\",\n            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n        )\n    }\n)\n\nsink_node = Node(\n    name=\"Sink\",\n    in_ports={\"in\": Port()},\n    in_salvo_conditions={\n        \"receive\": SalvoCondition(\n            MaxSalvos.finite(1),\n            \"in\",\n            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n        )\n    }\n)\n\nedges = [\n    Edge(\n        PortRef(\"Source\", PortType.Output, \"out\"),\n        PortRef(\"Processor\", PortType.Input, \"in\")\n    ),\n    Edge(\n        PortRef(\"Processor\", PortType.Output, \"out\"),\n        PortRef(\"Sink\", PortType.Input, \"in\")\n    ),\n]\n\ngraph = Graph([source_node, processor_node, sink_node], edges)\nprint(f\"Created pipeline: {list(graph.nodes().keys())}\")",
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created pipeline: ['Sink', 'Processor', 'Source']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 2: Create Net with Async Node Functions\n\nWe define a mix of sync and async execution functions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nnet = Net(\n    graph,\n    consumed_packet_storage=True,\n    on_error=\"raise\",\n)\n\n# Storage for results and logs\nresults = []\nexecution_log = []\n\n# Async Source: simulates fetching data from an async API\nasync def source_exec(ctx, packets):\n    \"\"\"Async source that simulates API calls.\"\"\"\n    execution_log.append(\"Source: starting async data fetch\")\n\n    # Simulate async operations (like HTTP requests)\n    for i in range(3):\n        await asyncio.sleep(0.01)  # Simulate network delay\n\n        # Create packet with fetched data\n        data = {\n            \"id\": i,\n            \"fetched_at\": f\"timestamp_{i}\",\n            \"value\": f\"async_data_{i}\"\n        }\n        pkt = ctx.create_packet(data)\n        ctx.load_output_port(\"out\", pkt)\n        ctx.send_output_salvo(\"send\")\n\n        execution_log.append(f\"Source: fetched and sent item {i}\")\n\n    execution_log.append(\"Source: completed async fetch\")\n\n# Sync Processor: demonstrates mixing with sync nodes\ndef processor_exec(ctx, packets):\n    \"\"\"Sync processor that transforms data.\"\"\"\n    execution_log.append(\"Processor: starting sync processing\")\n\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            value = ctx.consume_packet(pkt)\n\n            # Transform the data\n            transformed = {\n                **value,\n                \"processed\": True,\n                \"value\": value[\"value\"].upper()\n            }\n\n            execution_log.append(f\"Processor: transformed {value['id']}\")\n\n            out_pkt = ctx.create_packet(transformed)\n            ctx.load_output_port(\"out\", out_pkt)\n            ctx.send_output_salvo(\"send\")\n\n# Async Sink: simulates async storage\nasync def sink_exec(ctx, packets):\n    \"\"\"Async sink that simulates database writes.\"\"\"\n    execution_log.append(\"Sink: starting async storage\")\n\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            value = ctx.consume_packet(pkt)\n\n            # Simulate async database write\n            await asyncio.sleep(0.01)\n\n            results.append(value)\n            execution_log.append(f\"Sink: stored item {value['id']}\")\n\n    execution_log.append(\"Sink: completed async storage\")\n\n# Async start/stop functions\nasync def source_start(net):\n    \"\"\"Async initialization for Source node.\"\"\"\n    execution_log.append(\"Source: async start - initializing connection\")\n    await asyncio.sleep(0.01)  # Simulate connection setup\n\nasync def source_stop(net):\n    \"\"\"Async cleanup for Source node.\"\"\"\n    execution_log.append(\"Source: async stop - closing connection\")\n    await asyncio.sleep(0.01)  # Simulate connection cleanup\n\n# Register execution functions\nnet.set_node_exec(\n    \"Source\",\n    source_exec,\n    start_func=source_start,\n    stop_func=source_stop\n)\nnet.set_node_exec(\"Processor\", processor_exec)\nnet.set_node_exec(\"Sink\", sink_exec)\n\nprint(\"Registered mixed sync/async execution functions\")",
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registered mixed sync/async execution functions\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 3: Run the Pipeline Asynchronously\n\nWe use `async_start()` to run the network with proper async support.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nasync def run_async_pipeline():\n    \"\"\"Run the pipeline asynchronously.\"\"\"\n    global results, execution_log\n\n    # Clear previous results\n    results.clear()\n    execution_log.clear()\n\n    # Inject source epoch\n    source_epoch = net.inject_source_epoch(\"Source\")\n    print(f\"Injected Source epoch: {source_epoch[:8]}...\")\n\n    # Run the network asynchronously\n    print(\"\\nStarting async network execution...\\n\")\n    await net.async_start()\n\n    print(\"\\n--- Execution Log ---\")\n    for entry in execution_log:\n        print(f\"  {entry}\")\n\n    print(\"\\n--- Results ---\")\n    for r in results:\n        print(f\"  {r}\")\n\n    print(f\"\\nTotal results: {len(results)}\")\n    print(f\"Net state: {net.state}\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "If in a `.py` file, then we're outside the event loop, so we run with `asyncio.run`:",
      "metadata": {},
      "id": "1a365301"
    },
    {
      "cell_type": "code",
      "source": "#|export\ntry:\n    asyncio.get_running_loop()\nexcept RuntimeError:\n    asyncio.run(run_async_pipeline())",
      "metadata": {},
      "id": "7d23b57c",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Otherwise we use `await`:",
      "metadata": {},
      "id": "b061ad19"
    },
    {
      "cell_type": "code",
      "source": "# Run the async pipeline\nawait run_async_pipeline()",
      "metadata": {},
      "id": "d542e4a3",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected Source epoch: 01KEV9Q1...\n",
            "\n",
            "Starting async network execution...\n",
            "\n",
            "\n",
            "--- Execution Log ---\n",
            "  Source: async start - initializing connection\n",
            "  Source: starting async data fetch\n",
            "  Source: fetched and sent item 0\n",
            "  Source: fetched and sent item 1\n",
            "  Source: fetched and sent item 2\n",
            "  Source: completed async fetch\n",
            "  Processor: starting sync processing\n",
            "  Processor: transformed 0\n",
            "  Processor: starting sync processing\n",
            "  Processor: transformed 2\n",
            "  Processor: starting sync processing\n",
            "  Processor: transformed 1\n",
            "  Sink: starting async storage\n",
            "  Sink: stored item 0\n",
            "  Sink: completed async storage\n",
            "  Sink: starting async storage\n",
            "  Sink: stored item 2\n",
            "  Sink: completed async storage\n",
            "  Sink: starting async storage\n",
            "  Sink: stored item 1\n",
            "  Sink: completed async storage\n",
            "  Source: async stop - closing connection\n",
            "\n",
            "--- Results ---\n",
            "  {'id': 0, 'fetched_at': 'timestamp_0', 'value': 'ASYNC_DATA_0', 'processed': True}\n",
            "  {'id': 2, 'fetched_at': 'timestamp_2', 'value': 'ASYNC_DATA_2', 'processed': True}\n",
            "  {'id': 1, 'fetched_at': 'timestamp_1', 'value': 'ASYNC_DATA_1', 'processed': True}\n",
            "\n",
            "Total results: 3\n",
            "Net state: NetState.PAUSED\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 4: Demonstrate Async Value Functions\n\nPackets can have async value functions for lazy evaluation.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Create a fresh net for this demonstration\nnet2 = Net(\n    graph,\n    consumed_packet_storage=True,\n    on_error=\"raise\",\n)\n\nresults2 = []\n\nasync def source_with_async_value(ctx, packets):\n    \"\"\"Source that creates packets with async value functions.\"\"\"\n    for i in range(2):\n        # Create an async value function\n        async def make_async_value(idx=i):\n            await asyncio.sleep(0.01)  # Simulate async computation\n            return {\"computed_async\": True, \"index\": idx}\n\n        pkt = ctx.create_packet_from_value_func(make_async_value)\n        ctx.load_output_port(\"out\", pkt)\n        ctx.send_output_salvo(\"send\")\n\nasync def processor2(ctx, packets):\n    \"\"\"Async processor for async value functions.\"\"\"\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            # Must use async_consume_packet for async value functions\n            value = await ctx.async_consume_packet(pkt)\n            out_pkt = ctx.create_packet({**value, \"processed\": True})\n            ctx.load_output_port(\"out\", out_pkt)\n            ctx.send_output_salvo(\"send\")\n\nasync def sink_with_async_consume(ctx, packets):\n    \"\"\"Sink that uses async_consume_packet for async value functions.\"\"\"\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            # Use async_consume_packet for async value functions\n            value = await ctx.async_consume_packet(pkt)\n            results2.append(value)\n\nnet2.set_node_exec(\"Source\", source_with_async_value)\nnet2.set_node_exec(\"Processor\", processor2)\nnet2.set_node_exec(\"Sink\", sink_with_async_consume)\n\nasync def run_async_value_demo():\n    \"\"\"Demonstrate async value functions.\"\"\"\n    net2.inject_source_epoch(\"Source\")\n    await net2.async_start()\n\n    print(\"\\n--- Async Value Function Results ---\")\n    for r in results2:\n        print(f\"  {r}\")\n\n    assert all(r.get(\"computed_async\") for r in results2)\n    print(\"\\nAll values were computed asynchronously!\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\ntry:\n    asyncio.get_running_loop()\nexcept RuntimeError:\n    asyncio.run(run_async_pipeline())",
      "metadata": {},
      "id": "e8f7a6ee",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Run the async pipeline\nawait run_async_pipeline()",
      "metadata": {},
      "id": "5e86d6a4",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected Source epoch: 01KEV9Q1...\n",
            "\n",
            "Starting async network execution...\n",
            "\n",
            "\n",
            "--- Execution Log ---\n",
            "  Source: async start - initializing connection\n",
            "  Source: starting async data fetch\n",
            "  Source: fetched and sent item 0\n",
            "  Source: fetched and sent item 1\n",
            "  Source: fetched and sent item 2\n",
            "  Source: completed async fetch\n",
            "  Processor: starting sync processing\n",
            "  Processor: transformed 2\n",
            "  Processor: starting sync processing\n",
            "  Processor: transformed 0\n",
            "  Processor: starting sync processing\n",
            "  Processor: transformed 1\n",
            "  Sink: starting async storage\n",
            "  Sink: stored item 2\n",
            "  Sink: completed async storage\n",
            "  Sink: starting async storage\n",
            "  Sink: stored item 0\n",
            "  Sink: completed async storage\n",
            "  Sink: starting async storage\n",
            "  Sink: stored item 1\n",
            "  Sink: completed async storage\n",
            "  Source: async stop - closing connection\n",
            "\n",
            "--- Results ---\n",
            "  {'id': 2, 'fetched_at': 'timestamp_2', 'value': 'ASYNC_DATA_2', 'processed': True}\n",
            "  {'id': 0, 'fetched_at': 'timestamp_0', 'value': 'ASYNC_DATA_0', 'processed': True}\n",
            "  {'id': 1, 'fetched_at': 'timestamp_1', 'value': 'ASYNC_DATA_1', 'processed': True}\n",
            "\n",
            "Total results: 3\n",
            "Net state: NetState.PAUSED\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Summary\n\nThis example demonstrated:\n\n1. **Async Execution Functions**: Using `async def` for node `exec_func`\n2. **Mixed Sync/Async**: Combining sync and async nodes in the same pipeline\n3. **Async Start/Stop**: Using async `start_func` and `stop_func`\n4. **Async Net Methods**: Using `async_start()` instead of `start()`\n5. **Async Value Functions**: Creating packets with lazy async computation\n6. **Async Consume**: Using `ctx.async_consume_packet()` for async values\n\nKey points:\n- Use `async_start()` when any node has async functions\n- Sync and async nodes can be freely mixed\n- Async start/stop functions are properly awaited\n- Async value functions are awaited when consumed",
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
