{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Example 03: Async Node Functions\n",
        "\n",
        "This example demonstrates async execution in `netrun`:\n",
        "\n",
        "- Using async `exec_func` for nodes\n",
        "- Mixing sync and async nodes in the same pipeline\n",
        "- Using async start/stop functions\n",
        "- Async value functions for lazy evaluation\n",
        "\n",
        "## The Pipeline\n",
        "\n",
        "```\n",
        "Source (async) -> Processor (sync) -> Sink (async)\n",
        "```\n",
        "\n",
        "This demonstrates that sync and async nodes can be freely mixed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp 03_async_nodes"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import asyncio\n",
        "from netrun import (\n",
        "    # Graph building\n",
        "    Graph,\n",
        "    Node,\n",
        "    Edge,\n",
        "    Port,\n",
        "    PortType,\n",
        "    PortRef,\n",
        "    PortState,\n",
        "    MaxSalvos,\n",
        "    SalvoCondition,\n",
        "    SalvoConditionTerm,\n",
        "    # Net and configuration\n",
        "    Net,\n",
        "    NetState,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Define the Graph\n",
        "\n",
        "We create a three-node pipeline with mixed sync/async nodes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "source_node = Node(\n",
        "    name=\"Source\",\n",
        "    out_ports={\"out\": Port()},\n",
        "    out_salvo_conditions={\n",
        "        \"send\": SalvoCondition(\n",
        "            MaxSalvos.infinite(),\n",
        "            \"out\",\n",
        "            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "processor_node = Node(\n",
        "    name=\"Processor\",\n",
        "    in_ports={\"in\": Port()},\n",
        "    out_ports={\"out\": Port()},\n",
        "    in_salvo_conditions={\n",
        "        \"receive\": SalvoCondition(\n",
        "            MaxSalvos.finite(1),\n",
        "            \"in\",\n",
        "            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n",
        "        )\n",
        "    },\n",
        "    out_salvo_conditions={\n",
        "        \"send\": SalvoCondition(\n",
        "            MaxSalvos.infinite(),\n",
        "            \"out\",\n",
        "            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "sink_node = Node(\n",
        "    name=\"Sink\",\n",
        "    in_ports={\"in\": Port()},\n",
        "    in_salvo_conditions={\n",
        "        \"receive\": SalvoCondition(\n",
        "            MaxSalvos.finite(1),\n",
        "            \"in\",\n",
        "            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "edges = [\n",
        "    Edge(\n",
        "        PortRef(\"Source\", PortType.Output, \"out\"),\n",
        "        PortRef(\"Processor\", PortType.Input, \"in\")\n",
        "    ),\n",
        "    Edge(\n",
        "        PortRef(\"Processor\", PortType.Output, \"out\"),\n",
        "        PortRef(\"Sink\", PortType.Input, \"in\")\n",
        "    ),\n",
        "]\n",
        "\n",
        "graph = Graph([source_node, processor_node, sink_node], edges)\n",
        "print(f\"Created pipeline: {list(graph.nodes().keys())}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Create Net with Async Node Functions\n",
        "\n",
        "We define a mix of sync and async execution functions."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "net = Net(\n",
        "    graph,\n",
        "    consumed_packet_storage=True,\n",
        "    on_error=\"raise\",\n",
        ")\n",
        "\n",
        "# Storage for results and logs\n",
        "results = []\n",
        "execution_log = []\n",
        "\n",
        "# Async Source: simulates fetching data from an async API\n",
        "async def source_exec(ctx, packets):\n",
        "    \"\"\"Async source that simulates API calls.\"\"\"\n",
        "    execution_log.append(\"Source: starting async data fetch\")\n",
        "\n",
        "    # Simulate async operations (like HTTP requests)\n",
        "    for i in range(3):\n",
        "        await asyncio.sleep(0.01)  # Simulate network delay\n",
        "\n",
        "        # Create packet with fetched data\n",
        "        data = {\n",
        "            \"id\": i,\n",
        "            \"fetched_at\": f\"timestamp_{i}\",\n",
        "            \"value\": f\"async_data_{i}\"\n",
        "        }\n",
        "        pkt = ctx.create_packet(data)\n",
        "        ctx.load_output_port(\"out\", pkt)\n",
        "        ctx.send_output_salvo(\"send\")\n",
        "\n",
        "        execution_log.append(f\"Source: fetched and sent item {i}\")\n",
        "\n",
        "    execution_log.append(\"Source: completed async fetch\")\n",
        "\n",
        "# Sync Processor: demonstrates mixing with sync nodes\n",
        "def processor_exec(ctx, packets):\n",
        "    \"\"\"Sync processor that transforms data.\"\"\"\n",
        "    execution_log.append(\"Processor: starting sync processing\")\n",
        "\n",
        "    for port_name, pkts in packets.items():\n",
        "        for pkt in pkts:\n",
        "            value = ctx.consume_packet(pkt)\n",
        "\n",
        "            # Transform the data\n",
        "            transformed = {\n",
        "                **value,\n",
        "                \"processed\": True,\n",
        "                \"value\": value[\"value\"].upper()\n",
        "            }\n",
        "\n",
        "            execution_log.append(f\"Processor: transformed {value['id']}\")\n",
        "\n",
        "            out_pkt = ctx.create_packet(transformed)\n",
        "            ctx.load_output_port(\"out\", out_pkt)\n",
        "            ctx.send_output_salvo(\"send\")\n",
        "\n",
        "# Async Sink: simulates async storage\n",
        "async def sink_exec(ctx, packets):\n",
        "    \"\"\"Async sink that simulates database writes.\"\"\"\n",
        "    execution_log.append(\"Sink: starting async storage\")\n",
        "\n",
        "    for port_name, pkts in packets.items():\n",
        "        for pkt in pkts:\n",
        "            value = ctx.consume_packet(pkt)\n",
        "\n",
        "            # Simulate async database write\n",
        "            await asyncio.sleep(0.01)\n",
        "\n",
        "            results.append(value)\n",
        "            execution_log.append(f\"Sink: stored item {value['id']}\")\n",
        "\n",
        "    execution_log.append(\"Sink: completed async storage\")\n",
        "\n",
        "# Async start/stop functions\n",
        "async def source_start(net):\n",
        "    \"\"\"Async initialization for Source node.\"\"\"\n",
        "    execution_log.append(\"Source: async start - initializing connection\")\n",
        "    await asyncio.sleep(0.01)  # Simulate connection setup\n",
        "\n",
        "async def source_stop(net):\n",
        "    \"\"\"Async cleanup for Source node.\"\"\"\n",
        "    execution_log.append(\"Source: async stop - closing connection\")\n",
        "    await asyncio.sleep(0.01)  # Simulate connection cleanup\n",
        "\n",
        "# Register execution functions\n",
        "net.set_node_exec(\n",
        "    \"Source\",\n",
        "    source_exec,\n",
        "    start_func=source_start,\n",
        "    stop_func=source_stop\n",
        ")\n",
        "net.set_node_exec(\"Processor\", processor_exec)\n",
        "net.set_node_exec(\"Sink\", sink_exec)\n",
        "\n",
        "print(\"Registered mixed sync/async execution functions\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Run the Pipeline Asynchronously\n",
        "\n",
        "We use `async_start()` to run the network with proper async support."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "async def run_async_pipeline():\n",
        "    \"\"\"Run the pipeline asynchronously.\"\"\"\n",
        "    global results, execution_log\n",
        "\n",
        "    # Clear previous results\n",
        "    results.clear()\n",
        "    execution_log.clear()\n",
        "\n",
        "    # Inject source epoch\n",
        "    source_epoch = net.inject_source_epoch(\"Source\")\n",
        "    print(f\"Injected Source epoch: {source_epoch[:8]}...\")\n",
        "\n",
        "    # Run the network asynchronously\n",
        "    print(\"\\nStarting async network execution...\\n\")\n",
        "    await net.async_start()\n",
        "\n",
        "    print(\"\\n--- Execution Log ---\")\n",
        "    for entry in execution_log:\n",
        "        print(f\"  {entry}\")\n",
        "\n",
        "    print(\"\\n--- Results ---\")\n",
        "    for r in results:\n",
        "        print(f\"  {r}\")\n",
        "\n",
        "    print(f\"\\nTotal results: {len(results)}\")\n",
        "    print(f\"Net state: {net.state}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "If in a `.py` file, then we're outside the event loop, so we run with `asyncio.run`:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "try:\n",
        "    asyncio.get_running_loop()\n",
        "except RuntimeError:\n",
        "    asyncio.run(run_async_pipeline())"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otherwise we use `await`:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the async pipeline\n",
        "await run_async_pipeline()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Demonstrate Async Value Functions\n",
        "\n",
        "Packets can have async value functions for lazy evaluation."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "# Create a fresh net for this demonstration\n",
        "net2 = Net(\n",
        "    graph,\n",
        "    consumed_packet_storage=True,\n",
        "    on_error=\"raise\",\n",
        ")\n",
        "\n",
        "results2 = []\n",
        "\n",
        "async def source_with_async_value(ctx, packets):\n",
        "    \"\"\"Source that creates packets with async value functions.\"\"\"\n",
        "    for i in range(2):\n",
        "        # Create an async value function\n",
        "        async def make_async_value(idx=i):\n",
        "            await asyncio.sleep(0.01)  # Simulate async computation\n",
        "            return {\"computed_async\": True, \"index\": idx}\n",
        "\n",
        "        pkt = ctx.create_packet_from_value_func(make_async_value)\n",
        "        ctx.load_output_port(\"out\", pkt)\n",
        "        ctx.send_output_salvo(\"send\")\n",
        "\n",
        "async def processor2(ctx, packets):\n",
        "    \"\"\"Async processor for async value functions.\"\"\"\n",
        "    for port_name, pkts in packets.items():\n",
        "        for pkt in pkts:\n",
        "            # Must use async_consume_packet for async value functions\n",
        "            value = await ctx.async_consume_packet(pkt)\n",
        "            out_pkt = ctx.create_packet({**value, \"processed\": True})\n",
        "            ctx.load_output_port(\"out\", out_pkt)\n",
        "            ctx.send_output_salvo(\"send\")\n",
        "\n",
        "async def sink_with_async_consume(ctx, packets):\n",
        "    \"\"\"Sink that uses async_consume_packet for async value functions.\"\"\"\n",
        "    for port_name, pkts in packets.items():\n",
        "        for pkt in pkts:\n",
        "            # Use async_consume_packet for async value functions\n",
        "            value = await ctx.async_consume_packet(pkt)\n",
        "            results2.append(value)\n",
        "\n",
        "net2.set_node_exec(\"Source\", source_with_async_value)\n",
        "net2.set_node_exec(\"Processor\", processor2)\n",
        "net2.set_node_exec(\"Sink\", sink_with_async_consume)\n",
        "\n",
        "async def run_async_value_demo():\n",
        "    \"\"\"Demonstrate async value functions.\"\"\"\n",
        "    net2.inject_source_epoch(\"Source\")\n",
        "    await net2.async_start()\n",
        "\n",
        "    print(\"\\n--- Async Value Function Results ---\")\n",
        "    for r in results2:\n",
        "        print(f\"  {r}\")\n",
        "\n",
        "    assert all(r.get(\"computed_async\") for r in results2)\n",
        "    print(\"\\nAll values were computed asynchronously!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "try:\n",
        "    asyncio.get_running_loop()\n",
        "except RuntimeError:\n",
        "    asyncio.run(run_async_pipeline())"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the async pipeline\n",
        "await run_async_pipeline()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "This example demonstrated:\n",
        "\n",
        "1. **Async Execution Functions**: Using `async def` for node `exec_func`\n",
        "2. **Mixed Sync/Async**: Combining sync and async nodes in the same pipeline\n",
        "3. **Async Start/Stop**: Using async `start_func` and `stop_func`\n",
        "4. **Async Net Methods**: Using `async_start()` instead of `start()`\n",
        "5. **Async Value Functions**: Creating packets with lazy async computation\n",
        "6. **Async Consume**: Using `ctx.async_consume_packet()` for async values\n",
        "\n",
        "Key points:\n",
        "- Use `async_start()` when any node has async functions\n",
        "- Sync and async nodes can be freely mixed\n",
        "- Async start/stop functions are properly awaited\n",
        "- Async value functions are awaited when consumed"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
