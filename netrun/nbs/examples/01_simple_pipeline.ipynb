{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Example 01: Simple Pipeline Execution\n\nThis example demonstrates how to execute a simple data pipeline in `netrun`:\n\n- Creating a Source -> Processor -> Sink pipeline\n- Setting up execution functions for each node\n- Running the network and observing packet flow\n- Using deferred actions in the Processor node\n\n## The Pipeline\n\n```\nSource -> Processor -> Sink\n```\n\n- **Source**: Generates data packets\n- **Processor**: Transforms incoming data (uppercase)\n- **Sink**: Collects and stores the results",
      "metadata": {},
      "id": "830fcc0b"
    },
    {
      "cell_type": "code",
      "source": "#|default_exp 01_simple_pipeline",
      "metadata": {},
      "id": "06efb573",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nfrom netrun import (\n    # Graph building\n    Graph,\n    Node,\n    Edge,\n    Port,\n    PortType,\n    PortRef,\n    PortState,\n    MaxSalvos,\n    SalvoCondition,\n    SalvoConditionTerm,\n    # Net and configuration\n    Net,\n    NetState,\n)",
      "metadata": {},
      "id": "ab03985b",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 1: Define the Graph\n\nWe create a three-node pipeline: Source -> Processor -> Sink",
      "metadata": {},
      "id": "470f32fc"
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Define Source node - generates data\nsource_node = Node(\n    name=\"Source\",\n    out_ports={\"out\": Port()},\n    out_salvo_conditions={\n        \"send\": SalvoCondition(\n            MaxSalvos.infinite(),\n            \"out\",\n            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n        )\n    }\n)\n\n# Define Processor node - transforms data\nprocessor_node = Node(\n    name=\"Processor\",\n    in_ports={\"in\": Port()},\n    out_ports={\"out\": Port()},\n    in_salvo_conditions={\n        \"receive\": SalvoCondition(\n            MaxSalvos.finite(1),\n            \"in\",\n            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n        )\n    },\n    out_salvo_conditions={\n        \"send\": SalvoCondition(\n            MaxSalvos.infinite(),\n            \"out\",\n            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n        )\n    }\n)\n\n# Define Sink node - collects results\nsink_node = Node(\n    name=\"Sink\",\n    in_ports={\"in\": Port()},\n    in_salvo_conditions={\n        \"receive\": SalvoCondition(\n            MaxSalvos.finite(1),\n            \"in\",\n            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n        )\n    }\n)\n\n# Connect the nodes\nedges = [\n    Edge(\n        PortRef(\"Source\", PortType.Output, \"out\"),\n        PortRef(\"Processor\", PortType.Input, \"in\")\n    ),\n    Edge(\n        PortRef(\"Processor\", PortType.Output, \"out\"),\n        PortRef(\"Sink\", PortType.Input, \"in\")\n    ),\n]\n\n# Create the graph\ngraph = Graph([source_node, processor_node, sink_node], edges)\nprint(f\"Created pipeline: {list(graph.nodes().keys())}\")",
      "metadata": {},
      "id": "c040726c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created pipeline: ['Source', 'Sink', 'Processor']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 2: Create the Net and Set Up Execution Functions\n\nEach node needs an execution function that defines its behavior.",
      "metadata": {},
      "id": "0f3378a0"
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Create the Net with consumed packet storage enabled\nnet = Net(\n    graph,\n    consumed_packet_storage=True,\n    consumed_packet_storage_limit=100,\n    on_error=\"raise\",  # Raise exceptions on error\n)\n\n# Storage for results\nresults = []\nexecution_log = []\n\n# Source: generates data packets\ndef source_exec(ctx, packets):\n    \"\"\"Generate data packets.\"\"\"\n    execution_log.append(f\"Source executing (epoch {ctx.epoch_id[:8]}...)\")\n\n    # Create and send multiple data packets\n    for i, message in enumerate([\"hello\", \"world\", \"from\", \"netrun\"]):\n        pkt = ctx.create_packet({\"index\": i, \"message\": message})\n        ctx.load_output_port(\"out\", pkt)\n        ctx.send_output_salvo(\"send\")\n\n    execution_log.append(f\"Source sent 4 packets\")\n\n# Processor: transforms data (uppercase messages)\ndef processor_exec(ctx, packets):\n    \"\"\"Transform incoming data.\"\"\"\n    execution_log.append(f\"Processor executing (epoch {ctx.epoch_id[:8]}...)\")\n\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            # Get the input value\n            value = ctx.consume_packet(pkt)\n\n            # Transform: uppercase the message\n            transformed = {\n                \"index\": value[\"index\"],\n                \"message\": value[\"message\"].upper(),\n                \"processed\": True\n            }\n\n            execution_log.append(f\"  Transformed: {value['message']} -> {transformed['message']}\")\n\n            # Create output packet and send\n            out_pkt = ctx.create_packet(transformed)\n            ctx.load_output_port(\"out\", out_pkt)\n            ctx.send_output_salvo(\"send\")\n\n# Sink: collects results\ndef sink_exec(ctx, packets):\n    \"\"\"Collect and store results.\"\"\"\n    execution_log.append(f\"Sink executing (epoch {ctx.epoch_id[:8]}...)\")\n\n    for port_name, pkts in packets.items():\n        for pkt in pkts:\n            value = ctx.consume_packet(pkt)\n            results.append(value)\n            execution_log.append(f\"  Collected: {value}\")\n\n# Register execution functions\nnet.set_node_exec(\"Source\", source_exec)\nnet.set_node_exec(\"Processor\", processor_exec)\nnet.set_node_exec(\"Sink\", sink_exec)\n\nprint(\"Execution functions registered\")",
      "metadata": {},
      "id": "2f46b9b1",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution functions registered\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 3: Run the Pipeline\n\nWe inject an epoch for the Source node (since it has no inputs),\nthen run the network until completion.",
      "metadata": {},
      "id": "bb158bba"
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Clear any previous results\nresults.clear()\nexecution_log.clear()\n\n# Inject a Source epoch to kick off the pipeline\nsource_epoch = net.inject_source_epoch(\"Source\")\nprint(f\"Injected Source epoch: {source_epoch[:8]}...\")\n\n# Run the network\nprint(\"\\nStarting network execution...\\n\")\nnet.start()\n\nprint(\"\\n--- Execution Log ---\")\nfor entry in execution_log:\n    print(entry)\n\nprint(\"\\n--- Results ---\")\nfor result in results:\n    print(f\"  {result}\")\n\nprint(f\"\\nTotal results collected: {len(results)}\")\nprint(f\"Net state after execution: {net.state}\")",
      "metadata": {},
      "id": "02c9be8a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected Source epoch: 01KEV8P9...\n",
            "\n",
            "Starting network execution...\n",
            "\n",
            "\n",
            "--- Execution Log ---\n",
            "Source executing (epoch 01KEV8P9...)\n",
            "Source sent 4 packets\n",
            "Processor executing (epoch 01KEV8P9...)\n",
            "  Transformed: hello -> HELLO\n",
            "Processor executing (epoch 01KEV8P9...)\n",
            "  Transformed: netrun -> NETRUN\n",
            "Processor executing (epoch 01KEV8P9...)\n",
            "  Transformed: world -> WORLD\n",
            "Processor executing (epoch 01KEV8P9...)\n",
            "  Transformed: from -> FROM\n",
            "Sink executing (epoch 01KEV8P9...)\n",
            "  Collected: {'index': 1, 'message': 'WORLD', 'processed': True}\n",
            "Sink executing (epoch 01KEV8P9...)\n",
            "  Collected: {'index': 3, 'message': 'NETRUN', 'processed': True}\n",
            "Sink executing (epoch 01KEV8P9...)\n",
            "  Collected: {'index': 2, 'message': 'FROM', 'processed': True}\n",
            "Sink executing (epoch 01KEV8P9...)\n",
            "  Collected: {'index': 0, 'message': 'HELLO', 'processed': True}\n",
            "\n",
            "--- Results ---\n",
            "  {'index': 1, 'message': 'WORLD', 'processed': True}\n",
            "  {'index': 3, 'message': 'NETRUN', 'processed': True}\n",
            "  {'index': 2, 'message': 'FROM', 'processed': True}\n",
            "  {'index': 0, 'message': 'HELLO', 'processed': True}\n",
            "\n",
            "Total results collected: 4\n",
            "Net state after execution: NetState.PAUSED\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Part 4: Verify the Results\n\nLet's verify that all data was processed correctly.",
      "metadata": {},
      "id": "9a72521a"
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Verify results\nexpected_messages = [\"HELLO\", \"WORLD\", \"FROM\", \"NETRUN\"]\nactual_messages = [r[\"message\"] for r in results]\n\nprint(\"Verification:\")\nprint(f\"  Expected: {expected_messages}\")\nprint(f\"  Actual:   {actual_messages}\")\nprint(f\"  Match: {expected_messages == actual_messages}\")\n\n# All results should have 'processed' flag\nall_processed = all(r.get(\"processed\", False) for r in results)\nprint(f\"  All processed: {all_processed}\")",
      "metadata": {},
      "id": "3b1715aa",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verification:\n",
            "  Expected: ['HELLO', 'WORLD', 'FROM', 'NETRUN']\n",
            "  Actual:   ['WORLD', 'NETRUN', 'FROM', 'HELLO']\n",
            "  Match: False\n",
            "  All processed: True\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Summary\n\nThis example demonstrated:\n\n1. **Pipeline Creation**: Building a Source -> Processor -> Sink graph\n2. **Execution Functions**: Defining node behavior with `exec_func`\n3. **Packet Creation**: Using `ctx.create_packet()` to create data\n4. **Packet Consumption**: Using `ctx.consume_packet()` to read data\n5. **Output Sending**: Using `ctx.load_output_port()` and `ctx.send_output_salvo()`\n6. **Running the Network**: Using `inject_source_epoch()` and `start()`\n\nKey points:\n- Source nodes need manual epoch injection via `inject_source_epoch()`\n- The network runs until fully blocked (no more executable epochs)\n- Each packet flows through the pipeline: Source -> Processor -> Sink",
      "metadata": {},
      "id": "fedff2b1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "nblite_source_hash": "ef289692c32106c91438f3a11935cd68d4f2bf94607f19b2f813bf57b21e0646"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}