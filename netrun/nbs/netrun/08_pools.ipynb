{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Thread and Process Pools\n\nThis module provides pool management for parallel execution of nodes.\nSupports both `ThreadPoolExecutor` and `ProcessPoolExecutor`.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|default_exp pools",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|hide\nfrom nblite import nbl_export, show_doc; nbl_export();",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nimport asyncio\nimport threading\nimport pickle\nimport multiprocessing\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, Future\nfrom dataclasses import dataclass, field\nfrom enum import Enum, auto\nfrom typing import Any, Callable, Dict, List, Optional, Set, Tuple, TYPE_CHECKING\nfrom queue import Queue, Empty\n\nif TYPE_CHECKING:\n    from netrun.net import Net\n\n\nclass PoolType(Enum):\n    \"\"\"Type of execution pool.\"\"\"\n    THREAD = auto()\n    PROCESS = auto()\n\n\n@dataclass\nclass PoolConfig:\n    \"\"\"Configuration for a pool.\"\"\"\n    name: str\n    pool_type: PoolType\n    size: int\n\n    def __post_init__(self):\n        if self.size < 1:\n            raise ValueError(f\"Pool size must be at least 1, got {self.size}\")\n\n\nclass PoolInitMode(Enum):\n    \"\"\"How start/stop functions are called for pooled nodes.\"\"\"\n    PER_WORKER = \"per_worker\"  # Once per worker thread/process\n    GLOBAL = \"global\"  # Once globally",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Pool Manager\n\nThe `PoolManager` class manages all thread and process pools for a Net.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nclass WorkerState:\n    \"\"\"Tracks state for a single worker in a pool.\"\"\"\n\n    def __init__(self, worker_id: int, pool_name: str):\n        self.worker_id = worker_id\n        self.pool_name = pool_name\n        self.active_tasks: int = 0\n        self.initialized_nodes: Set[str] = set()\n        self._lock = threading.Lock()\n\n    def acquire_task(self) -> None:\n        \"\"\"Mark a task as starting on this worker.\"\"\"\n        with self._lock:\n            self.active_tasks += 1\n\n    def release_task(self) -> None:\n        \"\"\"Mark a task as completed on this worker.\"\"\"\n        with self._lock:\n            self.active_tasks -= 1\n\n    def mark_node_initialized(self, node_name: str) -> None:\n        \"\"\"Mark a node as initialized on this worker.\"\"\"\n        with self._lock:\n            self.initialized_nodes.add(node_name)\n\n    def is_node_initialized(self, node_name: str) -> bool:\n        \"\"\"Check if a node is initialized on this worker.\"\"\"\n        with self._lock:\n            return node_name in self.initialized_nodes\n\n\nclass ManagedPool:\n    \"\"\"Wrapper around ThreadPoolExecutor or ProcessPoolExecutor.\"\"\"\n\n    def __init__(self, config: PoolConfig):\n        self.config = config\n        self.name = config.name\n        self.pool_type = config.pool_type\n        self.size = config.size\n\n        self._executor: Optional[ThreadPoolExecutor | ProcessPoolExecutor] = None\n        self._workers: List[WorkerState] = []\n        self._started = False\n        self._lock = threading.Lock()\n\n        # For tracking which nodes have been globally initialized\n        self._globally_initialized_nodes: Set[str] = set()\n\n    def start(self) -> None:\n        \"\"\"Start the pool.\"\"\"\n        with self._lock:\n            if self._started:\n                return\n\n            if self.pool_type == PoolType.THREAD:\n                self._executor = ThreadPoolExecutor(\n                    max_workers=self.size,\n                    thread_name_prefix=f\"netrun-{self.name}-\"\n                )\n            else:\n                self._executor = ProcessPoolExecutor(max_workers=self.size)\n\n            # Create worker state trackers\n            self._workers = [WorkerState(i, self.name) for i in range(self.size)]\n            self._started = True\n\n    def stop(self) -> None:\n        \"\"\"Stop the pool and wait for pending tasks.\"\"\"\n        with self._lock:\n            if not self._started or self._executor is None:\n                return\n\n            self._executor.shutdown(wait=True)\n            self._executor = None\n            self._workers = []\n            self._started = False\n            self._globally_initialized_nodes.clear()\n\n    def get_available_workers(self) -> int:\n        \"\"\"Get the number of workers with no active tasks.\"\"\"\n        with self._lock:\n            return sum(1 for w in self._workers if w.active_tasks == 0)\n\n    def get_total_active_tasks(self) -> int:\n        \"\"\"Get total number of active tasks across all workers.\"\"\"\n        with self._lock:\n            return sum(w.active_tasks for w in self._workers)\n\n    def get_least_busy_worker(self) -> Optional[WorkerState]:\n        \"\"\"Get the worker with the fewest active tasks.\"\"\"\n        with self._lock:\n            if not self._workers:\n                return None\n            return min(self._workers, key=lambda w: w.active_tasks)\n\n    def submit(\n        self,\n        fn: Callable,\n        *args,\n        worker_state: Optional[WorkerState] = None,\n        **kwargs\n    ) -> Future:\n        \"\"\"Submit a task to the pool.\"\"\"\n        if not self._started or self._executor is None:\n            raise RuntimeError(f\"Pool '{self.name}' is not started\")\n\n        # Track task on the assigned worker\n        if worker_state is not None:\n            worker_state.acquire_task()\n\n        def wrapped_fn(*args, **kwargs):\n            try:\n                return fn(*args, **kwargs)\n            finally:\n                if worker_state is not None:\n                    worker_state.release_task()\n\n        return self._executor.submit(wrapped_fn, *args, **kwargs)\n\n    def mark_node_globally_initialized(self, node_name: str) -> None:\n        \"\"\"Mark a node as globally initialized.\"\"\"\n        with self._lock:\n            self._globally_initialized_nodes.add(node_name)\n\n    def is_node_globally_initialized(self, node_name: str) -> bool:\n        \"\"\"Check if a node has been globally initialized.\"\"\"\n        with self._lock:\n            return node_name in self._globally_initialized_nodes\n\n    @property\n    def is_thread_pool(self) -> bool:\n        \"\"\"Check if this is a thread pool.\"\"\"\n        return self.pool_type == PoolType.THREAD\n\n    @property\n    def is_process_pool(self) -> bool:\n        \"\"\"Check if this is a process pool.\"\"\"\n        return self.pool_type == PoolType.PROCESS\n\n\nclass PoolManager:\n    \"\"\"Manages all pools for a Net instance.\"\"\"\n\n    def __init__(\n        self,\n        thread_pools: Optional[Dict[str, dict]] = None,\n        process_pools: Optional[Dict[str, dict]] = None,\n    ):\n        \"\"\"\n        Initialize the pool manager.\n\n        Args:\n            thread_pools: Dict of pool name -> config ({\"size\": N})\n            process_pools: Dict of pool name -> config ({\"size\": N})\n        \"\"\"\n        self._pools: Dict[str, ManagedPool] = {}\n        self._started = False\n        self._lock = threading.Lock()\n\n        # Create thread pool configs\n        if thread_pools:\n            for name, config in thread_pools.items():\n                pool_config = PoolConfig(\n                    name=name,\n                    pool_type=PoolType.THREAD,\n                    size=config.get(\"size\", 4),\n                )\n                self._pools[name] = ManagedPool(pool_config)\n\n        # Create process pool configs\n        if process_pools:\n            for name, config in process_pools.items():\n                pool_config = PoolConfig(\n                    name=name,\n                    pool_type=PoolType.PROCESS,\n                    size=config.get(\"size\", 4),\n                )\n                self._pools[name] = ManagedPool(pool_config)\n\n    def start(self) -> None:\n        \"\"\"Start all pools.\"\"\"\n        with self._lock:\n            if self._started:\n                return\n            for pool in self._pools.values():\n                pool.start()\n            self._started = True\n\n    def stop(self) -> None:\n        \"\"\"Stop all pools.\"\"\"\n        with self._lock:\n            if not self._started:\n                return\n            for pool in self._pools.values():\n                pool.stop()\n            self._started = False\n\n    def get_pool(self, name: str) -> Optional[ManagedPool]:\n        \"\"\"Get a pool by name.\"\"\"\n        return self._pools.get(name)\n\n    def get_pools(self, names: List[str]) -> List[ManagedPool]:\n        \"\"\"Get multiple pools by name.\"\"\"\n        return [self._pools[n] for n in names if n in self._pools]\n\n    def select_pool(\n        self,\n        pool_names: List[str],\n        algorithm: str = \"least_busy\"\n    ) -> Optional[ManagedPool]:\n        \"\"\"\n        Select a pool from multiple options.\n\n        Args:\n            pool_names: List of pool names to choose from\n            algorithm: Selection algorithm (\"least_busy\")\n\n        Returns:\n            The selected pool, or None if no valid pools\n        \"\"\"\n        pools = self.get_pools(pool_names)\n        if not pools:\n            return None\n\n        if algorithm == \"least_busy\":\n            # Select pool with most available workers (least busy)\n            return max(pools, key=lambda p: p.get_available_workers())\n        else:\n            raise ValueError(f\"Unknown pool selection algorithm: {algorithm}\")\n\n    def has_pools(self) -> bool:\n        \"\"\"Check if any pools are configured.\"\"\"\n        return len(self._pools) > 0\n\n    @property\n    def pool_names(self) -> List[str]:\n        \"\"\"Get all pool names.\"\"\"\n        return list(self._pools.keys())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Process Pool Utilities\n\nUtilities for running tasks in process pools, including pickling validation.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\ndef validate_picklable(value: Any, context: str = \"\") -> None:\n    \"\"\"\n    Validate that a value can be pickled for process pool execution.\n\n    Args:\n        value: The value to check\n        context: Description for error messages\n\n    Raises:\n        ValueError: If the value cannot be pickled\n    \"\"\"\n    try:\n        pickle.dumps(value)\n    except (pickle.PicklingError, TypeError, AttributeError) as e:\n        ctx = f\" ({context})\" if context else \"\"\n        raise ValueError(\n            f\"Value{ctx} cannot be pickled for process pool execution: {e}\"\n        ) from e\n\n\ndef run_in_process_with_event_loop(func: Callable, *args, **kwargs) -> Any:\n    \"\"\"\n    Run a function in a process with its own event loop.\n\n    For async functions, creates a new event loop and runs until complete.\n    \"\"\"\n    import asyncio\n    import inspect\n\n    if asyncio.iscoroutinefunction(func) or inspect.iscoroutinefunction(func):\n        # Create new event loop for this process\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        try:\n            return loop.run_until_complete(func(*args, **kwargs))\n        finally:\n            loop.close()\n    else:\n        return func(*args, **kwargs)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Background Net Runner\n\nFor running a Net in a background thread.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#|export\nclass BackgroundNetRunner:\n    \"\"\"\n    Runs a Net in a background thread with control methods.\n\n    Provides methods to control the net execution:\n    - wait_until_blocked(): Wait for net to block\n    - poll(): Check if net is blocked\n    - pause(): Pause net execution\n    - stop(): Stop net execution\n    \"\"\"\n\n    def __init__(self, net: \"Net\"):\n        self._net = net\n        self._thread: Optional[threading.Thread] = None\n        self._stop_event = threading.Event()\n        self._blocked_event = threading.Event()\n        self._exception: Optional[Exception] = None\n        self._lock = threading.Lock()\n\n    def start(self) -> None:\n        \"\"\"Start running the net in a background thread.\"\"\"\n        with self._lock:\n            if self._thread is not None and self._thread.is_alive():\n                raise RuntimeError(\"Net is already running in background\")\n\n            self._stop_event.clear()\n            self._blocked_event.clear()\n            self._exception = None\n\n            self._thread = threading.Thread(\n                target=self._run_loop,\n                name=\"netrun-background\",\n                daemon=True,\n            )\n            self._thread.start()\n\n    def _run_loop(self) -> None:\n        \"\"\"Main loop for background execution.\"\"\"\n        try:\n            from netrun.net import NetState\n\n            # Run until blocked, stopped, or error\n            while not self._stop_event.is_set():\n                # Check if net is paused or stopped\n                if self._net.state in (NetState.PAUSED, NetState.STOPPED):\n                    self._blocked_event.set()\n                    break\n\n                # Run one step\n                had_work = self._net.run_step(start_epochs=True)\n\n                if not had_work:\n                    # Check if fully blocked\n                    if not self._net.get_startable_epochs():\n                        self._blocked_event.set()\n                        # Wait a bit before checking again\n                        if self._stop_event.wait(timeout=0.01):\n                            break\n        except Exception as e:\n            self._exception = e\n            self._blocked_event.set()\n\n    def wait_until_blocked(self, timeout: Optional[float] = None) -> bool:\n        \"\"\"\n        Wait until the net is blocked (no progress can be made).\n\n        Returns True if blocked, False if timeout expired.\n        \"\"\"\n        return self._blocked_event.wait(timeout=timeout)\n\n    def poll(self) -> bool:\n        \"\"\"Check if the net is currently blocked.\"\"\"\n        return self._blocked_event.is_set()\n\n    def pause(self) -> None:\n        \"\"\"Request the net to pause.\"\"\"\n        self._net.pause()\n\n    def stop(self) -> None:\n        \"\"\"Stop the background execution.\"\"\"\n        self._stop_event.set()\n        if self._thread is not None:\n            self._thread.join(timeout=5.0)\n\n    def get_exception(self) -> Optional[Exception]:\n        \"\"\"Get any exception that occurred during execution.\"\"\"\n        return self._exception\n\n    @property\n    def is_running(self) -> bool:\n        \"\"\"Check if the background thread is running.\"\"\"\n        return self._thread is not None and self._thread.is_alive()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
