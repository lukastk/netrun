{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Net Class\n",
        "\n",
        "The main `Net` class wraps `netrun-sim`'s `NetSim` and provides the high-level API\n",
        "for running flow-based networks."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp net"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|hide\n",
        "from nblite import nbl_export, show_doc; nbl_export();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import asyncio\n",
        "import inspect\n",
        "import time\n",
        "from typing import Any, Callable, Dict, List, Optional, Union\n",
        "from pathlib import Path\n",
        "from enum import Enum, auto\n",
        "from datetime import datetime\n",
        "\n",
        "# Re-export graph types from netrun_sim\n",
        "from netrun_sim import (\n",
        "    Graph,\n",
        "    Node,\n",
        "    Edge,\n",
        "    Port,\n",
        "    PortType,\n",
        "    PortRef,\n",
        "    PortSlotSpec,\n",
        "    PortState,\n",
        "    PacketCount,\n",
        "    MaxSalvos,\n",
        "    SalvoCondition,\n",
        "    SalvoConditionTerm,\n",
        "    NetSim,\n",
        "    NetAction,\n",
        "    NetEvent,\n",
        "    NetActionResponseData,\n",
        "    Packet,\n",
        "    PacketLocation,\n",
        "    Epoch,\n",
        "    EpochState,\n",
        "    Salvo,\n",
        "    NodeNotFoundError,\n",
        ")\n",
        "\n",
        "from netrun.errors import (\n",
        "    NetrunRuntimeError,\n",
        "    NodeExecutionFailed,\n",
        "    EpochTimeout,\n",
        "    EpochCancelled,\n",
        "    NetNotPausedError,\n",
        ")\n",
        "from netrun.storage import PacketValueStore\n",
        "from netrun.config import NodeConfig, NodeExecFuncs\n",
        "from netrun.dlq import DeadLetterQueue, DeadLetterEntry\n",
        "from netrun.deferred import (\n",
        "    DeferredPacket,\n",
        "    DeferredAction,\n",
        "    DeferredActionType,\n",
        "    DeferredActionQueue,\n",
        ")\n",
        "from netrun.context import NodeExecutionContext, NodeFailureContext\n",
        "from netrun.pools import (\n",
        "    PoolType,\n",
        "    PoolConfig,\n",
        "    PoolInitMode,\n",
        "    ManagedPool,\n",
        "    PoolManager,\n",
        "    BackgroundNetRunner,\n",
        ")\n",
        "from netrun.history import (\n",
        "    HistoryEntry,\n",
        "    EventHistory,\n",
        "    NodeLogEntry,\n",
        "    NodeLog,\n",
        "    NodeLogManager,\n",
        "    StdoutCapture,\n",
        "    capture_stdout,\n",
        ")\n",
        "from netrun.port_types import (\n",
        "    PortTypeSpec,\n",
        "    PortTypeRegistry,\n",
        "    check_value_type,\n",
        ")\n",
        "from netrun.dsl import (\n",
        "    NetDSLConfig,\n",
        "    parse_toml_string,\n",
        "    parse_toml_file,\n",
        "    net_config_to_toml,\n",
        "    save_toml_file,\n",
        "    resolve_import_path,\n",
        "    get_import_path,\n",
        ")\n",
        "\n",
        "\n",
        "class NetState(Enum):\n",
        "    \"\"\"The current state of the Net.\"\"\"\n",
        "    CREATED = auto()      # Net created but not started\n",
        "    RUNNING = auto()      # Net is actively running\n",
        "    PAUSED = auto()       # Net is paused (can resume)\n",
        "    STOPPED = auto()      # Net is stopped (cannot resume)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "\n",
        "These functions are used internally by the Net class."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def _is_async_func(func: Optional[Callable]) -> bool:\n",
        "    \"\"\"Check if a function is async (coroutine function).\"\"\"\n",
        "    if func is None:\n",
        "        return False\n",
        "    return asyncio.iscoroutinefunction(func) or inspect.iscoroutinefunction(func)\n",
        "\n",
        "\n",
        "def _commit_deferred_actions(\n",
        "    net: \"Net\",\n",
        "    epoch_id: str,\n",
        "    queue: DeferredActionQueue,\n",
        ") -> dict[str, Packet]:\n",
        "    \"\"\"\n",
        "    Commit all deferred actions to NetSim.\n",
        "\n",
        "    Returns a mapping from deferred_id to real Packet.\n",
        "    \"\"\"\n",
        "    # Map from deferred_id to real packet\n",
        "    resolved_packets: dict[str, Packet] = {}\n",
        "\n",
        "    for action in queue.actions:\n",
        "        if action.action_type == DeferredActionType.CREATE_PACKET:\n",
        "            # Create the packet\n",
        "            net_action = NetAction.create_packet(epoch_id)\n",
        "            response_data, _ = net._sim.do_action(net_action)\n",
        "\n",
        "            # Get the packet ID from response data\n",
        "            packet_id = response_data.packet_id\n",
        "\n",
        "            # Store the value\n",
        "            net._value_store.store_value(packet_id, action.value)\n",
        "\n",
        "            # Resolve the deferred packet\n",
        "            real_packet = net._sim.get_packet(packet_id)\n",
        "            if action.deferred_packet is not None:\n",
        "                action.deferred_packet._resolve(real_packet)\n",
        "                resolved_packets[action.deferred_packet.deferred_id] = real_packet\n",
        "\n",
        "        elif action.action_type == DeferredActionType.CREATE_PACKET_FROM_FUNC:\n",
        "            # Create the packet\n",
        "            net_action = NetAction.create_packet(epoch_id)\n",
        "            response_data, _ = net._sim.do_action(net_action)\n",
        "\n",
        "            # Get the packet ID from response data\n",
        "            packet_id = response_data.packet_id\n",
        "\n",
        "            # Store the value function\n",
        "            net._value_store.store_value_func(packet_id, action.value_func)\n",
        "\n",
        "            # Resolve the deferred packet\n",
        "            real_packet = net._sim.get_packet(packet_id)\n",
        "            if action.deferred_packet is not None:\n",
        "                action.deferred_packet._resolve(real_packet)\n",
        "                resolved_packets[action.deferred_packet.deferred_id] = real_packet\n",
        "\n",
        "        elif action.action_type == DeferredActionType.CONSUME_PACKET:\n",
        "            # Consume was already done for value retrieval, just commit to NetSim\n",
        "            packet = action.packet\n",
        "            if isinstance(packet, DeferredPacket):\n",
        "                if not packet.is_resolved:\n",
        "                    raise RuntimeError(\"Trying to consume unresolved deferred packet on commit\")\n",
        "                packet_id = packet.id\n",
        "            else:\n",
        "                packet_id = packet.id\n",
        "\n",
        "            net_action = NetAction.consume_packet(packet_id)\n",
        "            net._sim.do_action(net_action)\n",
        "\n",
        "        elif action.action_type == DeferredActionType.LOAD_OUTPUT_PORT:\n",
        "            packet = action.packet\n",
        "            if isinstance(packet, DeferredPacket):\n",
        "                if not packet.is_resolved:\n",
        "                    raise RuntimeError(\"Trying to load unresolved deferred packet on commit\")\n",
        "                packet_id = packet.id\n",
        "            else:\n",
        "                packet_id = packet.id\n",
        "\n",
        "            net_action = NetAction.load_packet_into_output_port(packet_id, action.port_name)\n",
        "            net._sim.do_action(net_action)\n",
        "\n",
        "        elif action.action_type == DeferredActionType.SEND_OUTPUT_SALVO:\n",
        "            net_action = NetAction.send_output_salvo(epoch_id, action.salvo_condition_name)\n",
        "            net._sim.do_action(net_action)\n",
        "\n",
        "    return resolved_packets\n",
        "\n",
        "\n",
        "def _unconsume_packets_for_retry(\n",
        "    net: \"Net\",\n",
        "    consumed_values: dict[str, Any],\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Restore consumed packet values for retry.\n",
        "\n",
        "    Called when an epoch fails and will be retried.\n",
        "    \"\"\"\n",
        "    for packet_id, value in consumed_values.items():\n",
        "        net._value_store.unconsume(packet_id, value)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Net Class"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "class Net:\n",
        "    \"\"\"\n",
        "    High-level runtime for flow-based development graphs.\n",
        "\n",
        "    Wraps `netrun-sim`'s `NetSim` to provide:\n",
        "    - Actual node execution logic\n",
        "    - Packet value storage\n",
        "    - Configuration and control methods\n",
        "\n",
        "    The underlying `NetSim` is hidden from users - all interactions\n",
        "    go through this class's methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        graph: Graph,\n",
        "        *,\n",
        "        # Packet storage\n",
        "        consumed_packet_storage: bool = False,\n",
        "        consumed_packet_storage_limit: Optional[int] = None,\n",
        "        packet_storage_path: Optional[Union[str, Path]] = None,\n",
        "        # Pools\n",
        "        thread_pools: Optional[Dict[str, dict]] = None,\n",
        "        process_pools: Optional[Dict[str, dict]] = None,\n",
        "        # Error handling\n",
        "        on_error: str = \"pause\",  # \"continue\", \"pause\", \"raise\"\n",
        "        error_callback: Optional[Callable] = None,\n",
        "        # Dead letter queue\n",
        "        dead_letter_queue: str = \"memory\",  # \"memory\", \"file\", or callback\n",
        "        dead_letter_path: Optional[Union[str, Path]] = None,\n",
        "        dead_letter_callback: Optional[Callable] = None,\n",
        "        # History\n",
        "        history_max_size: Optional[int] = None,\n",
        "        history_file: Optional[Union[str, Path]] = None,\n",
        "        history_chunk_size: int = 100,\n",
        "        history_flush_on_pause: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create a new Net from a graph.\n",
        "\n",
        "        Args:\n",
        "            graph: The network topology (from netrun_sim.Graph)\n",
        "            consumed_packet_storage: Keep values after consumption\n",
        "            consumed_packet_storage_limit: Max consumed values to keep\n",
        "            packet_storage_path: Path for file-based packet storage\n",
        "            thread_pools: Thread pool configurations {\"name\": {\"size\": N}}\n",
        "            process_pools: Process pool configurations {\"name\": {\"size\": N}}\n",
        "            on_error: Error handling mode (\"continue\", \"pause\", \"raise\")\n",
        "            error_callback: Called on any node error\n",
        "            dead_letter_queue: DLQ mode (\"memory\", \"file\", or callback)\n",
        "            dead_letter_path: Path for file-based DLQ\n",
        "            dead_letter_callback: Callback for DLQ\n",
        "            history_max_size: Max events in memory\n",
        "            history_file: Path for history persistence\n",
        "            history_chunk_size: Events per history write\n",
        "            history_flush_on_pause: Flush history when paused\n",
        "        \"\"\"\n",
        "        # Validate on_error\n",
        "        if on_error not in (\"continue\", \"pause\", \"raise\"):\n",
        "            raise ValueError(f\"on_error must be 'continue', 'pause', or 'raise', got '{on_error}'\")\n",
        "\n",
        "        # Store the graph and create internal NetSim\n",
        "        self._graph = graph\n",
        "        self._sim = NetSim(graph)\n",
        "\n",
        "        # Packet value storage\n",
        "        self._value_store = PacketValueStore(\n",
        "            consumed_storage=consumed_packet_storage,\n",
        "            consumed_storage_limit=consumed_packet_storage_limit,\n",
        "            storage_path=packet_storage_path,\n",
        "        )\n",
        "\n",
        "        # Node configurations and execution functions\n",
        "        self._node_configs: Dict[str, NodeConfig] = {}\n",
        "        self._node_exec_funcs: Dict[str, NodeExecFuncs] = {}\n",
        "\n",
        "        # Pool manager\n",
        "        self._pool_manager = PoolManager(\n",
        "            thread_pools=thread_pools,\n",
        "            process_pools=process_pools,\n",
        "        )\n",
        "\n",
        "        # Background runner for threaded execution\n",
        "        self._background_runner: Optional[BackgroundNetRunner] = None\n",
        "\n",
        "        # Error handling\n",
        "        self._on_error = on_error\n",
        "        self._error_callback = error_callback\n",
        "\n",
        "        # Dead letter queue\n",
        "        dlq_path = Path(dead_letter_path) if dead_letter_path else None\n",
        "        if callable(dead_letter_queue):\n",
        "            # If a callable is passed, use callback mode\n",
        "            self._dead_letter_queue = DeadLetterQueue(\n",
        "                mode=\"callback\",\n",
        "                callback=dead_letter_queue,\n",
        "            )\n",
        "        else:\n",
        "            self._dead_letter_queue = DeadLetterQueue(\n",
        "                mode=dead_letter_queue,\n",
        "                file_path=dlq_path,\n",
        "                callback=dead_letter_callback,\n",
        "            )\n",
        "\n",
        "        # Event history\n",
        "        self._event_history = EventHistory(\n",
        "            max_size=history_max_size,\n",
        "            file_path=history_file,\n",
        "            chunk_size=history_chunk_size,\n",
        "            flush_on_pause=history_flush_on_pause,\n",
        "        )\n",
        "\n",
        "        # Node log manager\n",
        "        self._node_log_manager = NodeLogManager()\n",
        "\n",
        "        # Port type registry\n",
        "        self._port_type_registry = PortTypeRegistry()\n",
        "\n",
        "        # Runtime state\n",
        "        self._state = NetState.CREATED\n",
        "        # Track manually-created Running epochs that need execution\n",
        "        self._pending_running_epochs: set[str] = set()\n",
        "\n",
        "        # Rate limiting and parallel epoch control (Milestone 7)\n",
        "        # Track currently running epochs per node\n",
        "        self._running_epochs_by_node: Dict[str, set] = {}\n",
        "        # Track epoch start timestamps per node for rate limiting\n",
        "        self._epoch_start_times_by_node: Dict[str, List[float]] = {}\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Properties\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def graph(self) -> Graph:\n",
        "        \"\"\"The network graph topology.\"\"\"\n",
        "        return self._graph\n",
        "\n",
        "    @property\n",
        "    def state(self) -> NetState:\n",
        "        \"\"\"The current state of the Net.\"\"\"\n",
        "        return self._state\n",
        "\n",
        "    @property\n",
        "    def dead_letter_queue(self) -> DeadLetterQueue:\n",
        "        \"\"\"The dead letter queue for failed epochs.\"\"\"\n",
        "        return self._dead_letter_queue\n",
        "\n",
        "    @property\n",
        "    def value_store(self) -> PacketValueStore:\n",
        "        \"\"\"The packet value store.\"\"\"\n",
        "        return self._value_store\n",
        "\n",
        "    @property\n",
        "    def pool_manager(self) -> PoolManager:\n",
        "        \"\"\"The pool manager for parallel execution.\"\"\"\n",
        "        return self._pool_manager\n",
        "\n",
        "    @property\n",
        "    def event_history(self) -> EventHistory:\n",
        "        \"\"\"The event history recorder.\"\"\"\n",
        "        return self._event_history\n",
        "\n",
        "    @property\n",
        "    def node_log_manager(self) -> NodeLogManager:\n",
        "        \"\"\"The node log manager.\"\"\"\n",
        "        return self._node_log_manager\n",
        "\n",
        "    @property\n",
        "    def port_type_registry(self) -> PortTypeRegistry:\n",
        "        \"\"\"The port type registry for type checking.\"\"\"\n",
        "        return self._port_type_registry\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Logging Methods\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def get_node_log(\n",
        "        self,\n",
        "        node_name: str,\n",
        "        limit: Optional[int] = None,\n",
        "    ) -> List[NodeLogEntry]:\n",
        "        \"\"\"\n",
        "        Get log entries for a node.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            limit: Maximum entries to return (most recent)\n",
        "\n",
        "        Returns:\n",
        "            List of log entries\n",
        "        \"\"\"\n",
        "        return self._node_log_manager.get_node_log(node_name, limit=limit)\n",
        "\n",
        "    def get_epoch_log(\n",
        "        self,\n",
        "        node_name: str,\n",
        "        epoch_id: str,\n",
        "        limit: Optional[int] = None,\n",
        "    ) -> List[NodeLogEntry]:\n",
        "        \"\"\"\n",
        "        Get log entries for a specific epoch.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            epoch_id: ID of the epoch\n",
        "            limit: Maximum entries to return\n",
        "\n",
        "        Returns:\n",
        "            List of log entries\n",
        "        \"\"\"\n",
        "        return self._node_log_manager.get_epoch_log(node_name, epoch_id, limit=limit)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Node Configuration\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def set_node_exec(\n",
        "        self,\n",
        "        node_name: str,\n",
        "        exec_func: Callable,\n",
        "        start_func: Optional[Callable] = None,\n",
        "        stop_func: Optional[Callable] = None,\n",
        "        failed_func: Optional[Callable] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Set execution functions for a node.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            exec_func: Main execution function (required)\n",
        "            start_func: Called when net starts (optional)\n",
        "            stop_func: Called when net stops (optional)\n",
        "            failed_func: Called after failed execution (optional)\n",
        "        \"\"\"\n",
        "        # Validate node exists\n",
        "        nodes = self._sim.graph.nodes()\n",
        "        if node_name not in nodes:\n",
        "            raise NodeNotFoundError(f\"Node '{node_name}' not found in graph\")\n",
        "\n",
        "        self._node_exec_funcs[node_name] = NodeExecFuncs(\n",
        "            exec_func=exec_func,\n",
        "            start_func=start_func,\n",
        "            stop_func=stop_func,\n",
        "            failed_func=failed_func,\n",
        "        )\n",
        "\n",
        "    def set_node_config(self, node_name: str, **options) -> None:\n",
        "        \"\"\"\n",
        "        Set configuration options for a node.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            **options: Configuration options (see NodeConfig)\n",
        "        \"\"\"\n",
        "        # Validate node exists\n",
        "        nodes = self._sim.graph.nodes()\n",
        "        if node_name not in nodes:\n",
        "            raise NodeNotFoundError(f\"Node '{node_name}' not found in graph\")\n",
        "\n",
        "        # Validate option names\n",
        "        valid_options = {f.name for f in NodeConfig.__dataclass_fields__.values()}\n",
        "        for opt_name in options:\n",
        "            if opt_name not in valid_options:\n",
        "                raise ValueError(f\"Unknown config option: '{opt_name}'\")\n",
        "\n",
        "        # Get existing config or create default\n",
        "        if node_name in self._node_configs:\n",
        "            # Update existing config\n",
        "            current = self._node_configs[node_name]\n",
        "            # Create new config with updated values\n",
        "            config_dict = {\n",
        "                field: getattr(current, field)\n",
        "                for field in valid_options\n",
        "            }\n",
        "            config_dict.update(options)\n",
        "            self._node_configs[node_name] = NodeConfig(**config_dict)\n",
        "        else:\n",
        "            # Create new config\n",
        "            self._node_configs[node_name] = NodeConfig(**options)\n",
        "\n",
        "    def get_node_config(self, node_name: str) -> NodeConfig:\n",
        "        \"\"\"Get the configuration for a node (returns default if not set).\"\"\"\n",
        "        return self._node_configs.get(node_name, NodeConfig())\n",
        "\n",
        "    def get_node_exec_funcs(self, node_name: str) -> Optional[NodeExecFuncs]:\n",
        "        \"\"\"Get the execution functions for a node.\"\"\"\n",
        "        return self._node_exec_funcs.get(node_name)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Port Type Configuration\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def set_input_port_type(\n",
        "        self,\n",
        "        node_name: str,\n",
        "        port_name: str,\n",
        "        type_spec: Union[str, type, dict, None],\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Set the expected type for an input port.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            port_name: Name of the input port\n",
        "            type_spec: Type specification:\n",
        "                - str: Class name to match against __class__.__name__\n",
        "                - type: Class to check with isinstance\n",
        "                - dict: {\"class\": Type, \"isinstance\": bool} or\n",
        "                        {\"class\": Type, \"subclass\": bool}\n",
        "                - None: No type checking\n",
        "        \"\"\"\n",
        "        # Validate node exists\n",
        "        nodes = self._sim.graph.nodes()\n",
        "        if node_name not in nodes:\n",
        "            raise NodeNotFoundError(f\"Node '{node_name}' not found in graph\")\n",
        "\n",
        "        self._port_type_registry.set_input_port_type(node_name, port_name, type_spec)\n",
        "\n",
        "    def set_output_port_type(\n",
        "        self,\n",
        "        node_name: str,\n",
        "        port_name: str,\n",
        "        type_spec: Union[str, type, dict, None],\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Set the expected type for an output port.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            port_name: Name of the output port\n",
        "            type_spec: Type specification (see set_input_port_type)\n",
        "        \"\"\"\n",
        "        # Validate node exists\n",
        "        nodes = self._sim.graph.nodes()\n",
        "        if node_name not in nodes:\n",
        "            raise NodeNotFoundError(f\"Node '{node_name}' not found in graph\")\n",
        "\n",
        "        self._port_type_registry.set_output_port_type(node_name, port_name, type_spec)\n",
        "\n",
        "    def get_input_port_type(self, node_name: str, port_name: str) -> Optional[Any]:\n",
        "        \"\"\"Get the type specification for an input port.\"\"\"\n",
        "        return self._port_type_registry.get_input_port_type(node_name, port_name)\n",
        "\n",
        "    def get_output_port_type(self, node_name: str, port_name: str) -> Optional[Any]:\n",
        "        \"\"\"Get the type specification for an output port.\"\"\"\n",
        "        return self._port_type_registry.get_output_port_type(node_name, port_name)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Wrapper Methods (hide NetSim)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def get_startable_epochs(self) -> list[str]:\n",
        "        \"\"\"Get list of epoch IDs that are ready to start.\"\"\"\n",
        "        return list(self._sim.get_startable_epochs())\n",
        "\n",
        "    def get_startable_epochs_by_node(self, node_name: str) -> list[str]:\n",
        "        \"\"\"Get list of startable epoch IDs for a specific node.\"\"\"\n",
        "        all_startable = self._sim.get_startable_epochs()\n",
        "        result = []\n",
        "        for epoch_id in all_startable:\n",
        "            epoch = self._sim.get_epoch(epoch_id)\n",
        "            if epoch and epoch.node_name == node_name:\n",
        "                result.append(epoch_id)\n",
        "        return result\n",
        "\n",
        "    def get_epoch(self, epoch_id: str) -> Optional[Epoch]:\n",
        "        \"\"\"Get an epoch by ID.\"\"\"\n",
        "        return self._sim.get_epoch(epoch_id)\n",
        "\n",
        "    def get_packet(self, packet_id: str) -> Optional[Packet]:\n",
        "        \"\"\"Get a packet by ID.\"\"\"\n",
        "        return self._sim.get_packet(packet_id)\n",
        "\n",
        "    def inject_source_epoch(self, node_name: str) -> str:\n",
        "        \"\"\"\n",
        "        Inject a source epoch for a node with no input ports.\n",
        "\n",
        "        Returns the epoch ID.\n",
        "        \"\"\"\n",
        "        # Create an empty salvo for source nodes (no input condition needed)\n",
        "        # Use empty string as placeholder for salvo condition\n",
        "        salvo = Salvo(\"__manual_inject__\", [])\n",
        "        action = NetAction.create_and_start_epoch(node_name, salvo)\n",
        "        response_data, _ = self._sim.do_action(action)\n",
        "\n",
        "        # Get the epoch ID from the response data\n",
        "        epoch_id = response_data.epoch.id\n",
        "\n",
        "        # Track this epoch for execution\n",
        "        self._pending_running_epochs.add(epoch_id)\n",
        "\n",
        "        return epoch_id\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Rate Limiting and Parallel Epoch Control (Milestone 7)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _can_start_epoch(self, node_name: str) -> tuple[bool, Optional[float]]:\n",
        "        \"\"\"\n",
        "        Check if an epoch can start for a node based on rate limiting and parallelism.\n",
        "\n",
        "        Returns:\n",
        "            (can_start, wait_time): can_start is True if epoch can start now,\n",
        "            wait_time is the time to wait if rate limited (None if not rate limited)\n",
        "        \"\"\"\n",
        "        config = self.get_node_config(node_name)\n",
        "\n",
        "        # Check max_parallel_epochs\n",
        "        if config.max_parallel_epochs is not None:\n",
        "            running = self._running_epochs_by_node.get(node_name, set())\n",
        "            if len(running) >= config.max_parallel_epochs:\n",
        "                return (False, None)\n",
        "\n",
        "        # Check rate_limit_per_second\n",
        "        if config.rate_limit_per_second is not None and config.rate_limit_per_second > 0:\n",
        "            now = time.time()\n",
        "            window = 1.0 / config.rate_limit_per_second\n",
        "\n",
        "            # Get recent start times\n",
        "            start_times = self._epoch_start_times_by_node.get(node_name, [])\n",
        "\n",
        "            # Clean up old timestamps (older than 1 second)\n",
        "            cutoff = now - 1.0\n",
        "            start_times = [t for t in start_times if t > cutoff]\n",
        "            self._epoch_start_times_by_node[node_name] = start_times\n",
        "\n",
        "            if start_times:\n",
        "                last_start = start_times[-1]\n",
        "                time_since_last = now - last_start\n",
        "                if time_since_last < window:\n",
        "                    wait_time = window - time_since_last\n",
        "                    return (False, wait_time)\n",
        "\n",
        "        return (True, None)\n",
        "\n",
        "    def _record_epoch_start(self, node_name: str, epoch_id: str) -> None:\n",
        "        \"\"\"Record that an epoch has started for rate limiting tracking.\"\"\"\n",
        "        # Track running epoch\n",
        "        if node_name not in self._running_epochs_by_node:\n",
        "            self._running_epochs_by_node[node_name] = set()\n",
        "        self._running_epochs_by_node[node_name].add(epoch_id)\n",
        "\n",
        "        # Track start time for rate limiting\n",
        "        if node_name not in self._epoch_start_times_by_node:\n",
        "            self._epoch_start_times_by_node[node_name] = []\n",
        "        self._epoch_start_times_by_node[node_name].append(time.time())\n",
        "\n",
        "    def _record_epoch_end(self, node_name: str, epoch_id: str) -> None:\n",
        "        \"\"\"Record that an epoch has ended.\"\"\"\n",
        "        if node_name in self._running_epochs_by_node:\n",
        "            self._running_epochs_by_node[node_name].discard(epoch_id)\n",
        "\n",
        "    def get_running_epochs_count(self, node_name: str) -> int:\n",
        "        \"\"\"Get the number of currently running epochs for a node.\"\"\"\n",
        "        return len(self._running_epochs_by_node.get(node_name, set()))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Internal Execution Methods\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _get_input_packets(self, epoch: Epoch) -> dict[str, list[Packet]]:\n",
        "        \"\"\"Get the input packets for an epoch, grouped by port name.\"\"\"\n",
        "        input_packets: dict[str, list[Packet]] = {}\n",
        "\n",
        "        # Get packets from the input salvo\n",
        "        in_salvo = epoch.in_salvo\n",
        "        if in_salvo is None:\n",
        "            return input_packets\n",
        "\n",
        "        # in_salvo.packets is a list of (port_name, packet_id) tuples\n",
        "        for port_name, packet_id in in_salvo.packets:\n",
        "            if port_name not in input_packets:\n",
        "                input_packets[port_name] = []\n",
        "            packet = self._sim.get_packet(str(packet_id))\n",
        "            if packet is not None:\n",
        "                input_packets[port_name].append(packet)\n",
        "\n",
        "        return input_packets\n",
        "\n",
        "    def _execute_epoch(self, epoch_id: str) -> None:\n",
        "        \"\"\"\n",
        "        Execute a single epoch with retry support.\n",
        "\n",
        "        This is the main execution logic for a node.\n",
        "        \"\"\"\n",
        "        epoch = self._sim.get_epoch(epoch_id)\n",
        "        if epoch is None:\n",
        "            raise ValueError(f\"Epoch {epoch_id} not found\")\n",
        "\n",
        "        node_name = epoch.node_name\n",
        "        config = self.get_node_config(node_name)\n",
        "        exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "\n",
        "        # Skip if no exec_func defined\n",
        "        if exec_funcs is None or exec_funcs.exec_func is None:\n",
        "            return\n",
        "\n",
        "        # Start the epoch if not already Running\n",
        "        if epoch.state == EpochState.Startable:\n",
        "            action = NetAction.start_epoch(epoch_id)\n",
        "            self._sim.do_action(action)\n",
        "\n",
        "        # Remove from pending running epochs if present\n",
        "        self._pending_running_epochs.discard(epoch_id)\n",
        "\n",
        "        # Record epoch start for rate limiting tracking\n",
        "        self._record_epoch_start(node_name, epoch_id)\n",
        "\n",
        "        try:\n",
        "            # Get input packets\n",
        "            input_packets = self._get_input_packets(epoch)\n",
        "\n",
        "            # Build input packet IDs for dead letter queue\n",
        "            input_packet_ids = {}\n",
        "            for port_name, pkts in input_packets.items():\n",
        "                input_packet_ids[port_name] = [str(pkt.id) for pkt in pkts]\n",
        "\n",
        "            # Build packet-to-port map for type checking\n",
        "            packet_to_port_map = {}\n",
        "            for port_name, pkts in input_packets.items():\n",
        "                for pkt in pkts:\n",
        "                    packet_to_port_map[pkt.id] = port_name\n",
        "\n",
        "            # Retry state\n",
        "            max_attempts = config.retries + 1\n",
        "            retry_timestamps: List[datetime] = []\n",
        "            retry_exceptions: List[Exception] = []\n",
        "            final_exception = None\n",
        "            success = False\n",
        "\n",
        "            # Track start time for timeout\n",
        "            start_time = time.time()\n",
        "\n",
        "            for attempt in range(max_attempts):\n",
        "                retry_count = attempt\n",
        "                exception_raised = None\n",
        "\n",
        "                # Create fresh execution context for each attempt\n",
        "                ctx = NodeExecutionContext(\n",
        "                    net=self,\n",
        "                    epoch_id=epoch_id,\n",
        "                    node_name=node_name,\n",
        "                    defer_net_actions=config.defer_net_actions,\n",
        "                    retry_count=retry_count,\n",
        "                    retry_timestamps=retry_timestamps.copy(),\n",
        "                    retry_exceptions=retry_exceptions.copy(),\n",
        "                    packet_to_port_map=packet_to_port_map,\n",
        "                )\n",
        "\n",
        "                try:\n",
        "                    # Check for timeout before execution\n",
        "                    if config.timeout is not None:\n",
        "                        elapsed = time.time() - start_time\n",
        "                        if elapsed >= config.timeout:\n",
        "                            raise EpochTimeout(node_name, epoch_id, config.timeout)\n",
        "\n",
        "                    # Execute the node function with optional stdout capture\n",
        "                    if config.capture_stdout:\n",
        "                        node_log = self._node_log_manager.get_log(node_name)\n",
        "                        with capture_stdout(node_log, epoch_id, echo=config.echo_stdout):\n",
        "                            exec_funcs.exec_func(ctx, input_packets)\n",
        "                    else:\n",
        "                        exec_funcs.exec_func(ctx, input_packets)\n",
        "\n",
        "                    # Success - commit deferred actions if any\n",
        "                    if config.defer_net_actions and ctx._deferred_queue is not None:\n",
        "                        _commit_deferred_actions(self, epoch_id, ctx._deferred_queue)\n",
        "\n",
        "                    # Finish the epoch\n",
        "                    action = NetAction.finish_epoch(epoch_id)\n",
        "                    self._sim.do_action(action)\n",
        "                    success = True\n",
        "                    break\n",
        "\n",
        "                except EpochCancelled:\n",
        "                    # Epoch was cancelled by the node\n",
        "                    action = NetAction.cancel_epoch(epoch_id)\n",
        "                    self._sim.do_action(action)\n",
        "                    raise\n",
        "\n",
        "                except (EpochTimeout, Exception) as e:\n",
        "                    exception_raised = e\n",
        "                    retry_timestamps.append(datetime.now())\n",
        "                    retry_exceptions.append(e)\n",
        "\n",
        "                    # Call failed_func after each failure\n",
        "                    if exec_funcs.failed_func is not None:\n",
        "                        failure_ctx = NodeFailureContext(\n",
        "                            epoch_id=epoch_id,\n",
        "                            node_name=node_name,\n",
        "                            retry_count=retry_count,\n",
        "                            retry_timestamps=retry_timestamps.copy(),\n",
        "                            retry_exceptions=retry_exceptions.copy(),\n",
        "                            input_salvo=input_packets,\n",
        "                            packet_values=ctx._get_consumed_values(),\n",
        "                            exception=exception_raised,\n",
        "                        )\n",
        "                        try:\n",
        "                            exec_funcs.failed_func(failure_ctx)\n",
        "                        except Exception:\n",
        "                            pass\n",
        "\n",
        "                    # Check if we have more retries\n",
        "                    if attempt < max_attempts - 1:\n",
        "                        # Unconsume packets for retry\n",
        "                        if config.defer_net_actions:\n",
        "                            consumed_values = ctx._get_consumed_values()\n",
        "                            _unconsume_packets_for_retry(self, consumed_values)\n",
        "\n",
        "                        # Wait before retry\n",
        "                        if config.retry_wait > 0:\n",
        "                            time.sleep(config.retry_wait)\n",
        "\n",
        "                        continue\n",
        "                    else:\n",
        "                        # Max retries exceeded\n",
        "                        final_exception = exception_raised\n",
        "\n",
        "            # Handle final failure\n",
        "            if not success and final_exception is not None:\n",
        "                # Cancel the epoch\n",
        "                action = NetAction.cancel_epoch(epoch_id)\n",
        "                self._sim.do_action(action)\n",
        "\n",
        "                # Add to dead letter queue if enabled\n",
        "                if config.dead_letter_queue:\n",
        "                    dlq_entry = DeadLetterEntry(\n",
        "                        epoch_id=epoch_id,\n",
        "                        node_name=node_name,\n",
        "                        exception=final_exception,\n",
        "                        retry_count=len(retry_exceptions) - 1,\n",
        "                        retry_timestamps=retry_timestamps,\n",
        "                        retry_exceptions=retry_exceptions,\n",
        "                        input_packets=input_packet_ids,\n",
        "                        packet_values=ctx._get_consumed_values() if ctx else {},\n",
        "                        timestamp=datetime.now(),\n",
        "                    )\n",
        "                    self._dead_letter_queue.add(dlq_entry)\n",
        "\n",
        "                # Call error callback if set\n",
        "                if self._error_callback is not None:\n",
        "                    try:\n",
        "                        self._error_callback(final_exception, node_name, epoch_id)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "                # Handle based on on_error setting\n",
        "                if self._on_error == \"raise\":\n",
        "                    self._state = NetState.PAUSED\n",
        "                    raise NodeExecutionFailed(node_name, epoch_id, final_exception) from final_exception\n",
        "                elif self._on_error == \"pause\":\n",
        "                    self._state = NetState.PAUSED\n",
        "                # \"continue\" - just keep going\n",
        "\n",
        "        finally:\n",
        "            # Record epoch end for rate limiting tracking\n",
        "            self._record_epoch_end(node_name, epoch_id)\n",
        "\n",
        "    async def _execute_epoch_async(self, epoch_id: str) -> None:\n",
        "        \"\"\"\n",
        "        Execute a single epoch asynchronously with retry support.\n",
        "\n",
        "        This is the async version of _execute_epoch for nodes with async exec_func.\n",
        "        \"\"\"\n",
        "        epoch = self._sim.get_epoch(epoch_id)\n",
        "        if epoch is None:\n",
        "            raise ValueError(f\"Epoch {epoch_id} not found\")\n",
        "\n",
        "        node_name = epoch.node_name\n",
        "        config = self.get_node_config(node_name)\n",
        "        exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "\n",
        "        # Skip if no exec_func defined\n",
        "        if exec_funcs is None or exec_funcs.exec_func is None:\n",
        "            return\n",
        "\n",
        "        # Start the epoch if not already Running\n",
        "        if epoch.state == EpochState.Startable:\n",
        "            action = NetAction.start_epoch(epoch_id)\n",
        "            self._sim.do_action(action)\n",
        "\n",
        "        # Remove from pending running epochs if present\n",
        "        self._pending_running_epochs.discard(epoch_id)\n",
        "\n",
        "        # Record epoch start for rate limiting tracking\n",
        "        self._record_epoch_start(node_name, epoch_id)\n",
        "\n",
        "        try:\n",
        "            # Get input packets\n",
        "            input_packets = self._get_input_packets(epoch)\n",
        "\n",
        "            # Build input packet IDs for dead letter queue\n",
        "            input_packet_ids = {}\n",
        "            for port_name, pkts in input_packets.items():\n",
        "                input_packet_ids[port_name] = [str(pkt.id) for pkt in pkts]\n",
        "\n",
        "            # Build packet-to-port map for type checking\n",
        "            packet_to_port_map = {}\n",
        "            for port_name, pkts in input_packets.items():\n",
        "                for pkt in pkts:\n",
        "                    packet_to_port_map[pkt.id] = port_name\n",
        "\n",
        "            # Retry state\n",
        "            max_attempts = config.retries + 1\n",
        "            retry_timestamps: List[datetime] = []\n",
        "            retry_exceptions: List[Exception] = []\n",
        "            final_exception = None\n",
        "            success = False\n",
        "\n",
        "            # Track start time for timeout\n",
        "            start_time = time.time()\n",
        "\n",
        "            for attempt in range(max_attempts):\n",
        "                retry_count = attempt\n",
        "                exception_raised = None\n",
        "\n",
        "                # Create fresh execution context for each attempt\n",
        "                ctx = NodeExecutionContext(\n",
        "                    net=self,\n",
        "                    epoch_id=epoch_id,\n",
        "                    node_name=node_name,\n",
        "                    defer_net_actions=config.defer_net_actions,\n",
        "                    retry_count=retry_count,\n",
        "                    retry_timestamps=retry_timestamps.copy(),\n",
        "                    retry_exceptions=retry_exceptions.copy(),\n",
        "                    packet_to_port_map=packet_to_port_map,\n",
        "                )\n",
        "\n",
        "                try:\n",
        "                    # Check for timeout before execution\n",
        "                    if config.timeout is not None:\n",
        "                        elapsed = time.time() - start_time\n",
        "                        if elapsed >= config.timeout:\n",
        "                            raise EpochTimeout(node_name, epoch_id, config.timeout)\n",
        "\n",
        "                    # Execute the node function (async) with optional stdout capture\n",
        "                    if config.capture_stdout:\n",
        "                        node_log = self._node_log_manager.get_log(node_name)\n",
        "                        with capture_stdout(node_log, epoch_id, echo=config.echo_stdout):\n",
        "                            result = exec_funcs.exec_func(ctx, input_packets)\n",
        "                            if asyncio.iscoroutine(result):\n",
        "                                await result\n",
        "                    else:\n",
        "                        result = exec_funcs.exec_func(ctx, input_packets)\n",
        "                        if asyncio.iscoroutine(result):\n",
        "                            await result\n",
        "\n",
        "                    # Success - commit deferred actions if any\n",
        "                    if config.defer_net_actions and ctx._deferred_queue is not None:\n",
        "                        _commit_deferred_actions(self, epoch_id, ctx._deferred_queue)\n",
        "\n",
        "                    # Finish the epoch\n",
        "                    action = NetAction.finish_epoch(epoch_id)\n",
        "                    self._sim.do_action(action)\n",
        "                    success = True\n",
        "                    break\n",
        "\n",
        "                except EpochCancelled:\n",
        "                    action = NetAction.cancel_epoch(epoch_id)\n",
        "                    self._sim.do_action(action)\n",
        "                    raise\n",
        "\n",
        "                except (EpochTimeout, Exception) as e:\n",
        "                    exception_raised = e\n",
        "                    retry_timestamps.append(datetime.now())\n",
        "                    retry_exceptions.append(e)\n",
        "\n",
        "                    # Call failed_func after each failure\n",
        "                    if exec_funcs.failed_func is not None:\n",
        "                        failure_ctx = NodeFailureContext(\n",
        "                            epoch_id=epoch_id,\n",
        "                            node_name=node_name,\n",
        "                            retry_count=retry_count,\n",
        "                            retry_timestamps=retry_timestamps.copy(),\n",
        "                            retry_exceptions=retry_exceptions.copy(),\n",
        "                            input_salvo=input_packets,\n",
        "                            packet_values=ctx._get_consumed_values(),\n",
        "                            exception=exception_raised,\n",
        "                        )\n",
        "                        try:\n",
        "                            result = exec_funcs.failed_func(failure_ctx)\n",
        "                            if asyncio.iscoroutine(result):\n",
        "                                await result\n",
        "                        except Exception:\n",
        "                            pass\n",
        "\n",
        "                    # Check if we have more retries\n",
        "                    if attempt < max_attempts - 1:\n",
        "                        if config.defer_net_actions:\n",
        "                            consumed_values = ctx._get_consumed_values()\n",
        "                            _unconsume_packets_for_retry(self, consumed_values)\n",
        "\n",
        "                        # Wait before retry (async sleep)\n",
        "                        if config.retry_wait > 0:\n",
        "                            await asyncio.sleep(config.retry_wait)\n",
        "\n",
        "                        continue\n",
        "                    else:\n",
        "                        final_exception = exception_raised\n",
        "\n",
        "            # Handle final failure\n",
        "            if not success and final_exception is not None:\n",
        "                action = NetAction.cancel_epoch(epoch_id)\n",
        "                self._sim.do_action(action)\n",
        "\n",
        "                if config.dead_letter_queue:\n",
        "                    dlq_entry = DeadLetterEntry(\n",
        "                        epoch_id=epoch_id,\n",
        "                        node_name=node_name,\n",
        "                        exception=final_exception,\n",
        "                        retry_count=len(retry_exceptions) - 1,\n",
        "                        retry_timestamps=retry_timestamps,\n",
        "                        retry_exceptions=retry_exceptions,\n",
        "                        input_packets=input_packet_ids,\n",
        "                        packet_values=ctx._get_consumed_values() if ctx else {},\n",
        "                        timestamp=datetime.now(),\n",
        "                    )\n",
        "                    self._dead_letter_queue.add(dlq_entry)\n",
        "\n",
        "                if self._error_callback is not None:\n",
        "                    try:\n",
        "                        result = self._error_callback(final_exception, node_name, epoch_id)\n",
        "                        if asyncio.iscoroutine(result):\n",
        "                            await result\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "                if self._on_error == \"raise\":\n",
        "                    self._state = NetState.PAUSED\n",
        "                    raise NodeExecutionFailed(node_name, epoch_id, final_exception) from final_exception\n",
        "                elif self._on_error == \"pause\":\n",
        "                    self._state = NetState.PAUSED\n",
        "\n",
        "        finally:\n",
        "            # Record epoch end for rate limiting tracking\n",
        "            self._record_epoch_end(node_name, epoch_id)\n",
        "\n",
        "    def _call_start_funcs(self) -> None:\n",
        "        \"\"\"Call start_node_func for all nodes that have one defined.\"\"\"\n",
        "        # Start pools first\n",
        "        self._pool_manager.start()\n",
        "\n",
        "        for node_name in self._graph.nodes():\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "            if exec_funcs is not None and exec_funcs.start_func is not None:\n",
        "                exec_funcs.start_func(self)\n",
        "\n",
        "    def _call_stop_funcs(self) -> None:\n",
        "        \"\"\"Call stop_node_func for all nodes that have one defined.\"\"\"\n",
        "        for node_name in self._graph.nodes():\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "            if exec_funcs is not None and exec_funcs.stop_func is not None:\n",
        "                exec_funcs.stop_func(self)\n",
        "\n",
        "        # Stop pools after node stop_funcs\n",
        "        self._pool_manager.stop()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Sync Execution Methods\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_step(self, start_epochs: bool = True) -> bool:\n",
        "        \"\"\"\n",
        "        Run one step of the network.\n",
        "\n",
        "        This method:\n",
        "        1. Runs NetSim until blocked (moves packets, creates startable epochs)\n",
        "        2. If start_epochs=True, executes all startable epochs\n",
        "        3. Returns when no more progress can be made in this step\n",
        "\n",
        "        Args:\n",
        "            start_epochs: Whether to start and execute ready epochs\n",
        "\n",
        "        Returns:\n",
        "            True if work was done (epochs executed), False otherwise\n",
        "        \"\"\"\n",
        "\n",
        "        if self._state == NetState.STOPPED:\n",
        "            raise RuntimeError(\"Cannot run_step on a stopped net\")\n",
        "\n",
        "        if self._state == NetState.PAUSED:\n",
        "            return False  # Don't do anything if paused\n",
        "\n",
        "        self._state = NetState.RUNNING\n",
        "\n",
        "        # Run NetSim until blocked\n",
        "        action = NetAction.run_net_until_blocked()\n",
        "        self._sim.do_action(action)\n",
        "\n",
        "        if not start_epochs:\n",
        "            return False\n",
        "\n",
        "        # Combine startable epochs and pending running epochs\n",
        "        startable = list(self._sim.get_startable_epochs())\n",
        "        pending_running = list(self._pending_running_epochs)\n",
        "        epochs_to_execute = startable + pending_running\n",
        "\n",
        "        executed_count = 0\n",
        "        skipped_due_to_limits = 0\n",
        "\n",
        "        for epoch_id in epochs_to_execute:\n",
        "            # Convert ULID to string if needed\n",
        "            epoch_id = str(epoch_id)\n",
        "\n",
        "            if self._state == NetState.PAUSED:\n",
        "                break  # Stop if we got paused during execution\n",
        "\n",
        "            epoch = self._sim.get_epoch(epoch_id)\n",
        "            if epoch is None:\n",
        "                continue\n",
        "\n",
        "            node_name = epoch.node_name\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "\n",
        "            # Skip nodes without exec_func\n",
        "            if exec_funcs is None or exec_funcs.exec_func is None:\n",
        "                continue\n",
        "\n",
        "            # Check rate limiting and max parallel epochs\n",
        "            can_start, wait_time = self._can_start_epoch(node_name)\n",
        "            if not can_start:\n",
        "                if wait_time is not None:\n",
        "                    # Rate limited - wait and then proceed\n",
        "                    time.sleep(wait_time)\n",
        "                    # Re-check after waiting\n",
        "                    can_start, _ = self._can_start_epoch(node_name)\n",
        "\n",
        "                if not can_start:\n",
        "                    # Still can't start (max_parallel_epochs reached)\n",
        "                    skipped_due_to_limits += 1\n",
        "                    continue\n",
        "\n",
        "            try:\n",
        "                self._execute_epoch(epoch_id)\n",
        "                executed_count += 1\n",
        "            except EpochCancelled:\n",
        "                executed_count += 1  # Still counts as work done\n",
        "            except NodeExecutionFailed:\n",
        "                executed_count += 1  # Still counts as work done\n",
        "                if self._on_error == \"raise\":\n",
        "                    raise\n",
        "                # For \"pause\" and \"continue\", error is already handled\n",
        "\n",
        "        return executed_count > 0\n",
        "\n",
        "    def start(self, threaded: bool = False) -> Optional[BackgroundNetRunner]:\n",
        "        \"\"\"\n",
        "        Start the network and run until fully blocked.\n",
        "\n",
        "        This method:\n",
        "        1. Calls start_node_func for all nodes\n",
        "        2. Runs run_step() in a loop until no more progress\n",
        "        3. Calls stop_node_func for all nodes when done\n",
        "\n",
        "        Args:\n",
        "            threaded: If True, run in background thread and return BackgroundNetRunner\n",
        "\n",
        "        Returns:\n",
        "            BackgroundNetRunner if threaded=True, else None\n",
        "        \"\"\"\n",
        "        if threaded:\n",
        "            # Start pools and start_funcs\n",
        "            self._call_start_funcs()\n",
        "            self._state = NetState.RUNNING\n",
        "\n",
        "            # Create and start background runner\n",
        "            self._background_runner = BackgroundNetRunner(self)\n",
        "            self._background_runner.start()\n",
        "            return self._background_runner\n",
        "\n",
        "        if self._state == NetState.STOPPED:\n",
        "            raise RuntimeError(\"Cannot start a stopped net\")\n",
        "\n",
        "        # Call start functions\n",
        "        self._call_start_funcs()\n",
        "\n",
        "        self._state = NetState.RUNNING\n",
        "\n",
        "        try:\n",
        "            # Run until fully blocked\n",
        "            while self._state == NetState.RUNNING:\n",
        "                # Check what epochs we can execute before this step\n",
        "                startable_before = set(self._sim.get_startable_epochs())\n",
        "                pending_before = set(self._pending_running_epochs)\n",
        "                epochs_before = startable_before | pending_before\n",
        "\n",
        "                self.run_step(start_epochs=True)\n",
        "\n",
        "                # After run_step, move any new packets from edges to input ports\n",
        "                # This ensures epochs created by output packets are visible\n",
        "                action = NetAction.run_net_until_blocked()\n",
        "                self._sim.do_action(action)\n",
        "\n",
        "                # Check what epochs we can execute after this step\n",
        "                startable_after = set(self._sim.get_startable_epochs())\n",
        "                pending_after = set(self._pending_running_epochs)\n",
        "                epochs_after = startable_after | pending_after\n",
        "\n",
        "                # Check if we're fully blocked\n",
        "                # Fully blocked = no epochs to execute and no progress was made\n",
        "                can_execute = False\n",
        "                for epoch_id in epochs_after:\n",
        "                    epoch = self._sim.get_epoch(str(epoch_id))\n",
        "                    if epoch:\n",
        "                        exec_funcs = self.get_node_exec_funcs(epoch.node_name)\n",
        "                        if exec_funcs and exec_funcs.exec_func:\n",
        "                            can_execute = True\n",
        "                            break\n",
        "\n",
        "                if not can_execute and epochs_before == epochs_after:\n",
        "                    # No progress made and no executable epochs\n",
        "                    break\n",
        "\n",
        "        finally:\n",
        "            # Call stop functions\n",
        "            self._call_stop_funcs()\n",
        "            if self._state == NetState.RUNNING:\n",
        "                self._state = NetState.PAUSED\n",
        "\n",
        "        return None\n",
        "\n",
        "    def pause(self) -> None:\n",
        "        \"\"\"\n",
        "        Pause the network (finish running epochs, don't start new ones).\n",
        "\n",
        "        Sets state to PAUSED, which will cause the run loop to stop\n",
        "        starting new epochs after current ones finish.\n",
        "        \"\"\"\n",
        "        self._state = NetState.PAUSED\n",
        "\n",
        "        # Flush history if configured\n",
        "        if self._event_history.flush_on_pause:\n",
        "            self._event_history.flush()\n",
        "\n",
        "        # If running in background, stop the runner\n",
        "        if self._background_runner is not None:\n",
        "            self._background_runner.pause()\n",
        "\n",
        "    def stop(self) -> None:\n",
        "        \"\"\"\n",
        "        Stop the network entirely.\n",
        "\n",
        "        Sets state to STOPPED, stops background runner if any, and\n",
        "        calls stop_funcs.\n",
        "        \"\"\"\n",
        "        # Stop background runner if any\n",
        "        if self._background_runner is not None:\n",
        "            self._background_runner.stop()\n",
        "            self._background_runner = None\n",
        "\n",
        "        # Call stop funcs if we were running\n",
        "        if self._state == NetState.RUNNING:\n",
        "            self._call_stop_funcs()\n",
        "\n",
        "        self._state = NetState.STOPPED\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Async Execution Methods (Milestone 5)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    async def _call_start_funcs_async(self) -> None:\n",
        "        \"\"\"Async version: call start_node_func for all nodes.\"\"\"\n",
        "        # Start pools first\n",
        "        self._pool_manager.start()\n",
        "\n",
        "        for node_name in self._graph.nodes():\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "            if exec_funcs is not None and exec_funcs.start_func is not None:\n",
        "                result = exec_funcs.start_func(self)\n",
        "                if asyncio.iscoroutine(result):\n",
        "                    await result\n",
        "\n",
        "    async def _call_stop_funcs_async(self) -> None:\n",
        "        \"\"\"Async version: call stop_node_func for all nodes.\"\"\"\n",
        "        for node_name in self._graph.nodes():\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "            if exec_funcs is not None and exec_funcs.stop_func is not None:\n",
        "                result = exec_funcs.stop_func(self)\n",
        "                if asyncio.iscoroutine(result):\n",
        "                    await result\n",
        "\n",
        "        # Stop pools after node stop_funcs\n",
        "        self._pool_manager.stop()\n",
        "\n",
        "    async def async_run_step(self, start_epochs: bool = True) -> bool:\n",
        "        \"\"\"\n",
        "        Async version of run_step.\n",
        "\n",
        "        Run one step of the network asynchronously.\n",
        "\n",
        "        This method:\n",
        "        1. Runs NetSim until blocked (moves packets, creates startable epochs)\n",
        "        2. If start_epochs=True, executes all startable epochs\n",
        "        3. Returns when no more progress can be made in this step\n",
        "\n",
        "        Supports both sync and async node exec_funcs - sync funcs are awaited as-is,\n",
        "        async funcs are properly awaited.\n",
        "\n",
        "        Args:\n",
        "            start_epochs: Whether to start and execute ready epochs\n",
        "\n",
        "        Returns:\n",
        "            True if work was done (epochs executed), False otherwise\n",
        "        \"\"\"\n",
        "        if self._state == NetState.STOPPED:\n",
        "            raise RuntimeError(\"Cannot run_step on a stopped net\")\n",
        "\n",
        "        if self._state == NetState.PAUSED:\n",
        "            return False\n",
        "\n",
        "        self._state = NetState.RUNNING\n",
        "\n",
        "        # Run NetSim until blocked\n",
        "        action = NetAction.run_net_until_blocked()\n",
        "        self._sim.do_action(action)\n",
        "\n",
        "        if not start_epochs:\n",
        "            return False\n",
        "\n",
        "        # Combine startable epochs and pending running epochs\n",
        "        startable = list(self._sim.get_startable_epochs())\n",
        "        pending_running = list(self._pending_running_epochs)\n",
        "        epochs_to_execute = startable + pending_running\n",
        "\n",
        "        executed_count = 0\n",
        "        skipped_due_to_limits = 0\n",
        "\n",
        "        for epoch_id in epochs_to_execute:\n",
        "            epoch_id = str(epoch_id)\n",
        "\n",
        "            if self._state == NetState.PAUSED:\n",
        "                break\n",
        "\n",
        "            epoch = self._sim.get_epoch(epoch_id)\n",
        "            if epoch is None:\n",
        "                continue\n",
        "\n",
        "            node_name = epoch.node_name\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "\n",
        "            if exec_funcs is None or exec_funcs.exec_func is None:\n",
        "                continue\n",
        "\n",
        "            # Check rate limiting and max parallel epochs\n",
        "            can_start, wait_time = self._can_start_epoch(node_name)\n",
        "            if not can_start:\n",
        "                if wait_time is not None:\n",
        "                    # Rate limited - wait asynchronously and then proceed\n",
        "                    await asyncio.sleep(wait_time)\n",
        "                    # Re-check after waiting\n",
        "                    can_start, _ = self._can_start_epoch(node_name)\n",
        "\n",
        "                if not can_start:\n",
        "                    # Still can't start (max_parallel_epochs reached)\n",
        "                    skipped_due_to_limits += 1\n",
        "                    continue\n",
        "\n",
        "            try:\n",
        "                # Check if exec_func is async\n",
        "                if _is_async_func(exec_funcs.exec_func):\n",
        "                    await self._execute_epoch_async(epoch_id)\n",
        "                else:\n",
        "                    self._execute_epoch(epoch_id)\n",
        "                executed_count += 1\n",
        "            except EpochCancelled:\n",
        "                executed_count += 1\n",
        "            except NodeExecutionFailed:\n",
        "                executed_count += 1\n",
        "                if self._on_error == \"raise\":\n",
        "                    raise\n",
        "\n",
        "        return executed_count > 0\n",
        "\n",
        "    async def async_start(self) -> None:\n",
        "        \"\"\"\n",
        "        Async version of start.\n",
        "\n",
        "        Start the network and run until fully blocked, asynchronously.\n",
        "\n",
        "        This method:\n",
        "        1. Calls start_node_func for all nodes (async if they are async)\n",
        "        2. Runs async_run_step() in a loop until no more progress\n",
        "        3. Calls stop_node_func for all nodes when done (async if they are async)\n",
        "\n",
        "        Supports both sync and async node functions mixed together.\n",
        "        \"\"\"\n",
        "        if self._state == NetState.STOPPED:\n",
        "            raise RuntimeError(\"Cannot start a stopped net\")\n",
        "\n",
        "        # Call start functions (async-aware)\n",
        "        await self._call_start_funcs_async()\n",
        "\n",
        "        self._state = NetState.RUNNING\n",
        "\n",
        "        try:\n",
        "            while self._state == NetState.RUNNING:\n",
        "                startable_before = set(self._sim.get_startable_epochs())\n",
        "                pending_before = set(self._pending_running_epochs)\n",
        "                epochs_before = startable_before | pending_before\n",
        "\n",
        "                await self.async_run_step(start_epochs=True)\n",
        "\n",
        "                action = NetAction.run_net_until_blocked()\n",
        "                self._sim.do_action(action)\n",
        "\n",
        "                startable_after = set(self._sim.get_startable_epochs())\n",
        "                pending_after = set(self._pending_running_epochs)\n",
        "                epochs_after = startable_after | pending_after\n",
        "\n",
        "                can_execute = False\n",
        "                for epoch_id in epochs_after:\n",
        "                    epoch = self._sim.get_epoch(str(epoch_id))\n",
        "                    if epoch:\n",
        "                        exec_funcs = self.get_node_exec_funcs(epoch.node_name)\n",
        "                        if exec_funcs and exec_funcs.exec_func:\n",
        "                            can_execute = True\n",
        "                            break\n",
        "\n",
        "                if not can_execute and epochs_before == epochs_after:\n",
        "                    break\n",
        "\n",
        "        finally:\n",
        "            await self._call_stop_funcs_async()\n",
        "            if self._state == NetState.RUNNING:\n",
        "                self._state = NetState.PAUSED\n",
        "\n",
        "    async def async_pause(self) -> None:\n",
        "        \"\"\"\n",
        "        Async version of pause.\n",
        "\n",
        "        Pause the network (finish running epochs, don't start new ones).\n",
        "        \"\"\"\n",
        "        self._state = NetState.PAUSED\n",
        "\n",
        "    async def async_stop(self) -> None:\n",
        "        \"\"\"\n",
        "        Async version of stop.\n",
        "\n",
        "        Stop the network entirely.\n",
        "        \"\"\"\n",
        "        self._state = NetState.STOPPED\n",
        "\n",
        "    async def async_wait_until_blocked(self) -> None:\n",
        "        \"\"\"\n",
        "        Wait until the network is fully blocked.\n",
        "\n",
        "        This is useful when the network is running in a separate task.\n",
        "        (Full implementation in Milestone 6 with threaded support)\n",
        "        \"\"\"\n",
        "        while self._state == NetState.RUNNING:\n",
        "            await asyncio.sleep(0.01)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Checkpoint Methods (Milestone 13)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def save_checkpoint(self, path: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Save a complete checkpoint of the network state.\n",
        "\n",
        "        Requires the net to be paused.\n",
        "\n",
        "        (To be implemented in Milestone 13)\n",
        "        \"\"\"\n",
        "        if self._state != NetState.PAUSED:\n",
        "            raise NetNotPausedError(\"save_checkpoint\")\n",
        "        raise NotImplementedError(\"save_checkpoint will be implemented in Milestone 13\")\n",
        "\n",
        "    @classmethod\n",
        "    def load_checkpoint(cls, path: Union[str, Path]) -> \"Net\":\n",
        "        \"\"\"\n",
        "        Load a network from a checkpoint.\n",
        "\n",
        "        (To be implemented in Milestone 13)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"load_checkpoint will be implemented in Milestone 13\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DSL Methods (Milestone 10)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def to_dsl_config(self) -> NetDSLConfig:\n",
        "        \"\"\"\n",
        "        Convert the current Net configuration to a DSLConfig.\n",
        "\n",
        "        Note: This captures the configuration but not runtime state.\n",
        "        Exec functions are only included if they have resolvable import paths.\n",
        "\n",
        "        Returns:\n",
        "            NetDSLConfig representing the current configuration\n",
        "        \"\"\"\n",
        "        config = NetDSLConfig(\n",
        "            graph=self._graph,\n",
        "            on_error=self._on_error,\n",
        "            consumed_packet_storage=self._value_store._consumed_storage,\n",
        "            consumed_storage_limit=self._value_store._consumed_storage_limit,\n",
        "            history_file=str(self._event_history._file_path) if self._event_history._file_path else None,\n",
        "            history_max_size=self._event_history._max_size,\n",
        "        )\n",
        "\n",
        "        # Node configs\n",
        "        for node_name, node_config in self._node_configs.items():\n",
        "            options = {}\n",
        "            if node_config.pool:\n",
        "                options[\"pool\"] = node_config.pool\n",
        "            if node_config.retries > 0:\n",
        "                options[\"retries\"] = node_config.retries\n",
        "            if node_config.defer_net_actions:\n",
        "                options[\"defer_net_actions\"] = node_config.defer_net_actions\n",
        "            if node_config.timeout is not None:\n",
        "                options[\"timeout\"] = node_config.timeout\n",
        "            if node_config.max_parallel_epochs is not None:\n",
        "                options[\"max_parallel_epochs\"] = node_config.max_parallel_epochs\n",
        "            if node_config.rate_limit_per_second is not None:\n",
        "                options[\"rate_limit_per_second\"] = node_config.rate_limit_per_second\n",
        "            if options:\n",
        "                config.node_configs[node_name] = options\n",
        "\n",
        "        # Node exec paths (best effort - only if import paths are resolvable)\n",
        "        for node_name, exec_funcs in self._node_exec_funcs.items():\n",
        "            paths = {}\n",
        "            if exec_funcs.exec_func:\n",
        "                path = get_import_path(exec_funcs.exec_func)\n",
        "                if path:\n",
        "                    paths[\"exec_func\"] = path\n",
        "            if exec_funcs.start_func:\n",
        "                path = get_import_path(exec_funcs.start_func)\n",
        "                if path:\n",
        "                    paths[\"start_func\"] = path\n",
        "            if exec_funcs.stop_func:\n",
        "                path = get_import_path(exec_funcs.stop_func)\n",
        "                if path:\n",
        "                    paths[\"stop_func\"] = path\n",
        "            if exec_funcs.failed_func:\n",
        "                path = get_import_path(exec_funcs.failed_func)\n",
        "                if path:\n",
        "                    paths[\"failed_func\"] = path\n",
        "            if paths:\n",
        "                config.node_exec_paths[node_name] = paths\n",
        "\n",
        "        # Port types\n",
        "        for (node_name, port_name), type_spec in self._port_type_registry._input_port_types.items():\n",
        "            if node_name not in config.port_types:\n",
        "                config.port_types[node_name] = {}\n",
        "            config.port_types[node_name][f\"in.{port_name}\"] = type_spec\n",
        "        for (node_name, port_name), type_spec in self._port_type_registry._output_port_types.items():\n",
        "            if node_name not in config.port_types:\n",
        "                config.port_types[node_name] = {}\n",
        "            config.port_types[node_name][f\"out.{port_name}\"] = type_spec\n",
        "\n",
        "        return config\n",
        "\n",
        "    def to_toml(self) -> str:\n",
        "        \"\"\"\n",
        "        Serialize the Net configuration to a TOML string.\n",
        "\n",
        "        Note: This captures the configuration but not runtime state.\n",
        "        Exec functions are only included if they have resolvable import paths.\n",
        "\n",
        "        Returns:\n",
        "            TOML string representation\n",
        "        \"\"\"\n",
        "        config = self.to_dsl_config()\n",
        "        return net_config_to_toml(config)\n",
        "\n",
        "    def save_toml(self, path: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Save the Net configuration to a TOML file.\n",
        "\n",
        "        Args:\n",
        "            path: Path to write the TOML file\n",
        "        \"\"\"\n",
        "        config = self.to_dsl_config()\n",
        "        save_toml_file(config, path)\n",
        "\n",
        "    @classmethod\n",
        "    def from_toml(cls, toml_str: str, resolve_funcs: bool = True) -> \"Net\":\n",
        "        \"\"\"\n",
        "        Create a Net from a TOML configuration string.\n",
        "\n",
        "        Args:\n",
        "            toml_str: TOML configuration string\n",
        "            resolve_funcs: Whether to resolve and set exec function import paths\n",
        "\n",
        "        Returns:\n",
        "            A new Net instance configured according to the TOML\n",
        "        \"\"\"\n",
        "        config = parse_toml_string(toml_str)\n",
        "        return cls._from_dsl_config(config, resolve_funcs)\n",
        "\n",
        "    @classmethod\n",
        "    def from_toml_file(cls, path: Union[str, Path], resolve_funcs: bool = True) -> \"Net\":\n",
        "        \"\"\"\n",
        "        Create a Net from a TOML configuration file.\n",
        "\n",
        "        Args:\n",
        "            path: Path to the TOML file\n",
        "            resolve_funcs: Whether to resolve and set exec function import paths\n",
        "\n",
        "        Returns:\n",
        "            A new Net instance configured according to the TOML\n",
        "        \"\"\"\n",
        "        config = parse_toml_file(path)\n",
        "        return cls._from_dsl_config(config, resolve_funcs)\n",
        "\n",
        "    @classmethod\n",
        "    def _from_dsl_config(cls, config: NetDSLConfig, resolve_funcs: bool = True) -> \"Net\":\n",
        "        \"\"\"Create a Net from a DSLConfig.\"\"\"\n",
        "        # Create Net with basic config\n",
        "        net = cls(\n",
        "            graph=config.graph,\n",
        "            on_error=config.on_error,\n",
        "            consumed_packet_storage=config.consumed_packet_storage,\n",
        "            consumed_packet_storage_limit=config.consumed_storage_limit,\n",
        "            history_file=config.history_file,\n",
        "            history_max_size=config.history_max_size,\n",
        "            history_chunk_size=config.history_chunk_size,\n",
        "        )\n",
        "\n",
        "        # Apply node configs\n",
        "        for node_name, options in config.node_configs.items():\n",
        "            net.set_node_config(node_name, **options)\n",
        "\n",
        "        # Resolve and set exec functions\n",
        "        if resolve_funcs:\n",
        "            for node_name, paths in config.node_exec_paths.items():\n",
        "                exec_func = None\n",
        "                start_func = None\n",
        "                stop_func = None\n",
        "                failed_func = None\n",
        "\n",
        "                if \"exec_func\" in paths:\n",
        "                    exec_func = resolve_import_path(paths[\"exec_func\"])\n",
        "                if \"start_func\" in paths:\n",
        "                    start_func = resolve_import_path(paths[\"start_func\"])\n",
        "                if \"stop_func\" in paths:\n",
        "                    stop_func = resolve_import_path(paths[\"stop_func\"])\n",
        "                if \"failed_func\" in paths:\n",
        "                    failed_func = resolve_import_path(paths[\"failed_func\"])\n",
        "\n",
        "                if exec_func:\n",
        "                    net.set_node_exec(\n",
        "                        node_name,\n",
        "                        exec_func,\n",
        "                        start_func=start_func,\n",
        "                        stop_func=stop_func,\n",
        "                        failed_func=failed_func,\n",
        "                    )\n",
        "\n",
        "        # Set port types\n",
        "        for node_name, port_types in config.port_types.items():\n",
        "            for port_key, type_spec in port_types.items():\n",
        "                if port_key.startswith(\"in.\"):\n",
        "                    port_name = port_key[3:]\n",
        "                    net.set_input_port_type(node_name, port_name, type_spec)\n",
        "                elif port_key.startswith(\"out.\"):\n",
        "                    port_name = port_key[4:]\n",
        "                    net.set_output_port_type(node_name, port_name, type_spec)\n",
        "\n",
        "        # Resolve and set factories\n",
        "        if resolve_funcs:\n",
        "            from netrun.factories import load_factory\n",
        "\n",
        "            for node_name, factory_info in config.node_factories.items():\n",
        "                factory_path = factory_info.get(\"factory\")\n",
        "                factory_args = factory_info.get(\"factory_args\", {})\n",
        "\n",
        "                if factory_path:\n",
        "                    result = load_factory(factory_path, **factory_args)\n",
        "\n",
        "                    # Set the exec functions from the factory\n",
        "                    if result.exec_node_func:\n",
        "                        net.set_node_exec(\n",
        "                            node_name,\n",
        "                            result.exec_node_func,\n",
        "                            start_func=result.start_node_func,\n",
        "                            stop_func=result.stop_node_func,\n",
        "                            failed_func=result.exec_failed_node_func,\n",
        "                        )\n",
        "\n",
        "        return net\n",
        "\n",
        "    @staticmethod\n",
        "    def from_factory(\n",
        "        factory_path: str,\n",
        "        **factory_args\n",
        "    ) -> tuple:\n",
        "        \"\"\"\n",
        "        Load a node factory and return its spec and functions.\n",
        "\n",
        "        This is a convenience method for working with node factories.\n",
        "\n",
        "        Args:\n",
        "            factory_path: Dotted import path to the factory module\n",
        "            **factory_args: Arguments to pass to the factory functions\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (node_spec, exec_func, start_func, stop_func, failed_func)\n",
        "\n",
        "        Example:\n",
        "            spec, exec_fn, start_fn, stop_fn, failed_fn = Net.from_factory(\n",
        "                \"my_module.my_factory\",\n",
        "                num_inputs=3,\n",
        "                timeout=30,\n",
        "            )\n",
        "            node = Node(**spec)\n",
        "            net.set_node_exec(node.name, exec_fn, start_fn, stop_fn, failed_fn)\n",
        "        \"\"\"\n",
        "        from netrun.factories import load_factory\n",
        "\n",
        "        result = load_factory(factory_path, **factory_args)\n",
        "        return (\n",
        "            result.node_spec,\n",
        "            result.exec_node_func,\n",
        "            result.start_node_func,\n",
        "            result.stop_node_func,\n",
        "            result.exec_failed_node_func,\n",
        "        )\n",
        "\n",
        "    # =========================================================================\n",
        "    # Checkpointing Methods\n",
        "    # =========================================================================\n",
        "\n",
        "    def save_checkpoint(self, path: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Save the complete Net state to a checkpoint directory.\n",
        "\n",
        "        The net must be paused (or not yet started) before saving a checkpoint.\n",
        "        This ensures no epochs are in a running state during serialization.\n",
        "\n",
        "        Creates the following files:\n",
        "        - metadata.json: Checkpoint metadata\n",
        "        - net_definition.toml: Net graph and configuration\n",
        "        - packet_states.json: Packet locations\n",
        "        - packet_values.pkl: Pickled packet values\n",
        "        - node_configs.json: Node configurations\n",
        "        - history.jsonl: Event history (if configured)\n",
        "\n",
        "        Args:\n",
        "            path: Directory to save checkpoint files\n",
        "\n",
        "        Raises:\n",
        "            NetNotPausedError: If the net has running epochs\n",
        "        \"\"\"\n",
        "        from netrun.checkpoint import (\n",
        "            get_all_packet_states,\n",
        "            save_checkpoint_state,\n",
        "            CheckpointMetadata,\n",
        "        )\n",
        "\n",
        "        # Check that net is paused or stopped (safe to checkpoint)\n",
        "        # Must be in PAUSED or STOPPED state\n",
        "        allowed_states = {NetState.PAUSED, NetState.STOPPED}\n",
        "        if self._state not in allowed_states:\n",
        "            raise NetNotPausedError(\n",
        "                f\"Cannot save checkpoint in state {self._state}. \"\n",
        "                \"Call net.pause() first to ensure no epochs are running.\"\n",
        "            )\n",
        "\n",
        "        # Get packet IDs from value store\n",
        "        packet_ids = list(self._value_store._values.keys())\n",
        "\n",
        "        # Get packet states\n",
        "        packet_states = get_all_packet_states(self._sim, packet_ids, self._graph)\n",
        "\n",
        "        # Get packet values (make a copy to avoid modifying during iteration)\n",
        "        packet_values = {}\n",
        "        for packet_id, stored_value in self._value_store._values.items():\n",
        "            if stored_value.is_value_func:\n",
        "                # For value functions, we can't serialize them directly\n",
        "                # Store a marker indicating this was a value function\n",
        "                packet_values[packet_id] = {\"__value_func__\": True}\n",
        "            else:\n",
        "                packet_values[packet_id] = stored_value.value\n",
        "\n",
        "        # Get node configs\n",
        "        node_configs = {}\n",
        "        for node_name, config in self._node_configs.items():\n",
        "            node_configs[node_name] = {\n",
        "                \"pool\": config.pool,\n",
        "                \"max_parallel_epochs\": config.max_parallel_epochs,\n",
        "                \"rate_limit_per_second\": config.rate_limit_per_second,\n",
        "                \"defer_net_actions\": config.defer_net_actions,\n",
        "                \"retries\": config.retries,\n",
        "                \"retry_wait\": config.retry_wait,\n",
        "                \"timeout\": config.timeout,\n",
        "                \"dead_letter_queue\": config.dead_letter_queue,\n",
        "                \"capture_stdout\": config.capture_stdout,\n",
        "            }\n",
        "\n",
        "        # Get exec paths (we store the paths for serialization)\n",
        "        node_exec_paths = {}\n",
        "        for node_name, exec_funcs in self._node_exec_funcs.items():\n",
        "            paths = {}\n",
        "            if exec_funcs.exec_func:\n",
        "                paths[\"exec_func\"] = get_import_path(exec_funcs.exec_func)\n",
        "            if exec_funcs.start_func:\n",
        "                paths[\"start_func\"] = get_import_path(exec_funcs.start_func)\n",
        "            if exec_funcs.stop_func:\n",
        "                paths[\"stop_func\"] = get_import_path(exec_funcs.stop_func)\n",
        "            if exec_funcs.failed_func:\n",
        "                paths[\"failed_func\"] = get_import_path(exec_funcs.failed_func)\n",
        "            if paths:\n",
        "                node_exec_paths[node_name] = paths\n",
        "\n",
        "        # Get factory info from DSL config\n",
        "        dsl_config = self.to_dsl_config()\n",
        "        node_factories = dsl_config.node_factories\n",
        "\n",
        "        # Get port types\n",
        "        port_types = dsl_config.port_types\n",
        "\n",
        "        # Get history data if available\n",
        "        history_data = None\n",
        "        if self._event_history is not None:\n",
        "            history_data = [e.to_dict() for e in self._event_history.get_entries()]\n",
        "\n",
        "        # Generate net definition TOML\n",
        "        net_definition_toml = self.to_toml()\n",
        "\n",
        "        # Create metadata\n",
        "        metadata = CheckpointMetadata(\n",
        "            timestamp=datetime.now().isoformat(),\n",
        "            packet_count=len(packet_states),\n",
        "            has_history=history_data is not None,\n",
        "        )\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_checkpoint_state(\n",
        "            checkpoint_dir=Path(path),\n",
        "            net_definition_toml=net_definition_toml,\n",
        "            packet_states=packet_states,\n",
        "            packet_values=packet_values,\n",
        "            node_configs=node_configs,\n",
        "            node_exec_paths=node_exec_paths,\n",
        "            node_factories=node_factories,\n",
        "            port_types=port_types,\n",
        "            history_data=history_data,\n",
        "            metadata=metadata,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def load_checkpoint(\n",
        "        cls,\n",
        "        path: Union[str, Path],\n",
        "        resolve_funcs: bool = True,\n",
        "    ) -> \"Net\":\n",
        "        \"\"\"\n",
        "        Load a Net from a checkpoint directory.\n",
        "\n",
        "        Args:\n",
        "            path: Directory containing checkpoint files\n",
        "            resolve_funcs: Whether to resolve and set exec function import paths\n",
        "\n",
        "        Returns:\n",
        "            A new Net instance restored to the checkpointed state\n",
        "        \"\"\"\n",
        "        from netrun.checkpoint import (\n",
        "            load_checkpoint_state,\n",
        "            restore_packets_to_net,\n",
        "            deserialize_packet_location,\n",
        "        )\n",
        "\n",
        "        # Load checkpoint data\n",
        "        checkpoint = load_checkpoint_state(path)\n",
        "\n",
        "        # Create Net from definition\n",
        "        net = cls.from_toml(checkpoint.net_definition_toml, resolve_funcs=resolve_funcs)\n",
        "\n",
        "        # Restore packets\n",
        "        id_mapping = restore_packets_to_net(\n",
        "            net._sim,\n",
        "            checkpoint.packet_states,\n",
        "            net._graph,\n",
        "        )\n",
        "\n",
        "        # Restore packet values with new IDs\n",
        "        for old_id, new_id in id_mapping.items():\n",
        "            if old_id in checkpoint.packet_values:\n",
        "                value = checkpoint.packet_values[old_id]\n",
        "                if isinstance(value, dict) and value.get(\"__value_func__\"):\n",
        "                    # Value function - can't restore, just skip\n",
        "                    # User will need to set up value functions again\n",
        "                    pass\n",
        "                else:\n",
        "                    net._value_store.store_value(new_id, value)\n",
        "\n",
        "        # Run until blocked to trigger input salvo conditions\n",
        "        net._sim.do_action(NetAction.run_net_until_blocked())\n",
        "\n",
        "        return net\n",
        "\n",
        "    def save_definition(self, path: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Save just the Net definition (without runtime state) to a TOML file.\n",
        "\n",
        "        This saves the graph structure and configuration, but not:\n",
        "        - Current packet locations\n",
        "        - Packet values\n",
        "        - Running epochs\n",
        "        - Event history\n",
        "\n",
        "        Args:\n",
        "            path: Path to save the TOML file\n",
        "        \"\"\"\n",
        "        self.save_toml(path)\n",
        "\n",
        "    @classmethod\n",
        "    def load_definition(\n",
        "        cls,\n",
        "        path: Union[str, Path],\n",
        "        resolve_funcs: bool = True,\n",
        "    ) -> \"Net\":\n",
        "        \"\"\"\n",
        "        Load a Net definition from a TOML file.\n",
        "\n",
        "        This creates a fresh Net without any runtime state.\n",
        "\n",
        "        Args:\n",
        "            path: Path to the TOML file\n",
        "            resolve_funcs: Whether to resolve and set exec function import paths\n",
        "\n",
        "        Returns:\n",
        "            A new Net instance\n",
        "        \"\"\"\n",
        "        return cls.from_toml_file(path, resolve_funcs=resolve_funcs)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
