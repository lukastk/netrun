{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Core\n",
        "\n",
        "This module provides the core functionality for `netrun`, a Python package for running\n",
        "flow-based development (FBD) graphs. It wraps `netrun-sim` to provide actual node execution,\n",
        "packet value storage, and higher-level APIs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp core"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|hide\n",
        "from nblite import nbl_export, show_doc; nbl_export();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-exports from netrun_sim\n",
        "\n",
        "We re-export all public types from `netrun_sim` so users can import everything from `netrun`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import netrun_sim\n",
        "\n",
        "# Graph types\n",
        "from netrun_sim import (\n",
        "    Graph,\n",
        "    Node,\n",
        "    Edge,\n",
        "    Port,\n",
        "    PortType,\n",
        "    PortRef,\n",
        "    PortSlotSpec,\n",
        "    PortState,\n",
        "    PacketCount,\n",
        "    MaxSalvos,\n",
        "    SalvoCondition,\n",
        "    SalvoConditionTerm,\n",
        ")\n",
        "\n",
        "# Net types\n",
        "from netrun_sim import (\n",
        "    NetSim,\n",
        "    NetAction,\n",
        "    NetEvent,\n",
        "    NetActionResponseData,\n",
        "    Packet,\n",
        "    PacketLocation,\n",
        "    Epoch,\n",
        "    EpochState,\n",
        "    Salvo,\n",
        ")\n",
        "\n",
        "# Error types from netrun_sim (using reflection to avoid manual listing)\n",
        "import sys as _sys\n",
        "_netrun_sim_errors = [\n",
        "    name for name in dir(netrun_sim)\n",
        "    if name.endswith('Error') and isinstance(getattr(netrun_sim, name), type)\n",
        "]\n",
        "for _err_name in _netrun_sim_errors:\n",
        "    setattr(_sys.modules[__name__], _err_name, getattr(netrun_sim, _err_name))\n",
        "\n",
        "# Clean up\n",
        "del _sys, _netrun_sim_errors, _err_name"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## netrun-specific Error Types\n",
        "\n",
        "These errors are specific to `netrun` (not `netrun-sim`) and handle higher-level\n",
        "execution concerns."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "class NetrunRuntimeError(Exception):\n",
        "    \"\"\"Base class for netrun runtime errors (distinct from netrun_sim errors).\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class PacketTypeMismatch(NetrunRuntimeError):\n",
        "    \"\"\"Raised when a packet value doesn't match the expected port type.\"\"\"\n",
        "    def __init__(self, packet_id, expected_type, actual_type, port_name=None):\n",
        "        self.packet_id = packet_id\n",
        "        self.expected_type = expected_type\n",
        "        self.actual_type = actual_type\n",
        "        self.port_name = port_name\n",
        "        port_info = f\" on port '{port_name}'\" if port_name else \"\"\n",
        "        super().__init__(\n",
        "            f\"Packet {packet_id}{port_info}: expected type {expected_type}, got {actual_type}\"\n",
        "        )\n",
        "\n",
        "\n",
        "class ValueFunctionFailed(NetrunRuntimeError):\n",
        "    \"\"\"Raised when a packet's value function raises an exception.\"\"\"\n",
        "    def __init__(self, packet_id, original_exception):\n",
        "        self.packet_id = packet_id\n",
        "        self.original_exception = original_exception\n",
        "        super().__init__(\n",
        "            f\"Value function for packet {packet_id} failed: {original_exception}\"\n",
        "        )\n",
        "\n",
        "\n",
        "class NodeExecutionFailed(NetrunRuntimeError):\n",
        "    \"\"\"Raised when a node's exec function raises an exception.\"\"\"\n",
        "    def __init__(self, node_name, epoch_id, original_exception):\n",
        "        self.node_name = node_name\n",
        "        self.epoch_id = epoch_id\n",
        "        self.original_exception = original_exception\n",
        "        super().__init__(\n",
        "            f\"Node '{node_name}' (epoch {epoch_id}) execution failed: {original_exception}\"\n",
        "        )\n",
        "\n",
        "\n",
        "class EpochTimeout(NetrunRuntimeError):\n",
        "    \"\"\"Raised when an epoch exceeds its configured timeout.\"\"\"\n",
        "    def __init__(self, node_name, epoch_id, timeout_seconds):\n",
        "        self.node_name = node_name\n",
        "        self.epoch_id = epoch_id\n",
        "        self.timeout_seconds = timeout_seconds\n",
        "        super().__init__(\n",
        "            f\"Node '{node_name}' (epoch {epoch_id}) timed out after {timeout_seconds}s\"\n",
        "        )\n",
        "\n",
        "\n",
        "class EpochCancelled(NetrunRuntimeError):\n",
        "    \"\"\"Raised when an epoch is cancelled via ctx.cancel_epoch().\"\"\"\n",
        "    def __init__(self, node_name, epoch_id):\n",
        "        self.node_name = node_name\n",
        "        self.epoch_id = epoch_id\n",
        "        super().__init__(f\"Epoch {epoch_id} for node '{node_name}' was cancelled\")\n",
        "\n",
        "\n",
        "class NetNotPausedError(NetrunRuntimeError):\n",
        "    \"\"\"Raised when an operation requires the net to be paused but it isn't.\"\"\"\n",
        "    def __init__(self, operation):\n",
        "        self.operation = operation\n",
        "        super().__init__(f\"Operation '{operation}' requires the net to be paused\")\n",
        "\n",
        "\n",
        "class DeferredPacketIdAccessError(NetrunRuntimeError):\n",
        "    \"\"\"Raised when trying to access the ID of a deferred packet before commit.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            \"Cannot access packet ID before deferred actions are committed. \"\n",
        "            \"The packet ID is assigned when the epoch completes successfully.\"\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packet Value Storage\n",
        "\n",
        "The `PacketValueStore` manages packet values separately from `netrun-sim`'s packet tracking.\n",
        "It supports direct values, lazy value functions, and optional persistence."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from typing import Any, Callable, Optional, Union\n",
        "from dataclasses import dataclass, field\n",
        "from collections import OrderedDict\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import asyncio\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class StoredValue:\n",
        "    \"\"\"A stored packet value, either direct or via a value function.\"\"\"\n",
        "    value: Any = None\n",
        "    value_func: Optional[Callable[[], Any]] = None\n",
        "    is_value_func: bool = False\n",
        "\n",
        "    def get_value(self) -> Any:\n",
        "        \"\"\"Get the value, calling the value function if necessary.\"\"\"\n",
        "        if self.is_value_func and self.value_func is not None:\n",
        "            return self.value_func()\n",
        "        return self.value\n",
        "\n",
        "    async def async_get_value(self) -> Any:\n",
        "        \"\"\"Get the value, awaiting async value functions if necessary.\"\"\"\n",
        "        if self.is_value_func and self.value_func is not None:\n",
        "            result = self.value_func()\n",
        "            if asyncio.iscoroutine(result):\n",
        "                return await result\n",
        "            return result\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class PacketValueStore:\n",
        "    \"\"\"\n",
        "    Manages packet values for the netrun runtime.\n",
        "\n",
        "    Handles:\n",
        "    - Direct value storage/retrieval by packet ID\n",
        "    - Lazy value functions (called on consumption)\n",
        "    - Consumed packet storage with configurable limits\n",
        "    - Optional file-based persistence\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        consumed_storage: bool = False,\n",
        "        consumed_storage_limit: Optional[int] = None,\n",
        "        storage_path: Optional[Union[str, Path]] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the packet value store.\n",
        "\n",
        "        Args:\n",
        "            consumed_storage: Whether to keep values after consumption\n",
        "            consumed_storage_limit: Max consumed values to keep (None = unlimited)\n",
        "            storage_path: Optional path for file-based storage\n",
        "        \"\"\"\n",
        "        self._values: dict[str, StoredValue] = {}\n",
        "        self._consumed_values: OrderedDict[str, Any] = OrderedDict()\n",
        "        self._consumed_storage = consumed_storage\n",
        "        self._consumed_storage_limit = consumed_storage_limit\n",
        "        self._storage_path = Path(storage_path) if storage_path else None\n",
        "\n",
        "        if self._storage_path:\n",
        "            self._storage_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def store_value(self, packet_id: str, value: Any) -> None:\n",
        "        \"\"\"Store a direct value for a packet.\"\"\"\n",
        "        self._values[packet_id] = StoredValue(value=value, is_value_func=False)\n",
        "\n",
        "        if self._storage_path:\n",
        "            self._persist_to_file(packet_id, value)\n",
        "\n",
        "    def store_value_func(self, packet_id: str, func: Callable[[], Any]) -> None:\n",
        "        \"\"\"Store a value function for a packet (called lazily on consumption).\"\"\"\n",
        "        self._values[packet_id] = StoredValue(value_func=func, is_value_func=True)\n",
        "\n",
        "    def get_value(self, packet_id: str) -> Any:\n",
        "        \"\"\"\n",
        "        Get a packet's value (consuming it from the store).\n",
        "\n",
        "        For value functions, this calls the function.\n",
        "        Raises KeyError if packet not found.\n",
        "        \"\"\"\n",
        "        if packet_id not in self._values:\n",
        "            # Check consumed storage\n",
        "            if packet_id in self._consumed_values:\n",
        "                return self._consumed_values[packet_id]\n",
        "            # Check file storage\n",
        "            if self._storage_path:\n",
        "                value = self._load_from_file(packet_id)\n",
        "                if value is not None:\n",
        "                    return value\n",
        "            raise KeyError(f\"Packet {packet_id} not found in value store\")\n",
        "\n",
        "        stored = self._values[packet_id]\n",
        "        try:\n",
        "            value = stored.get_value()\n",
        "        except Exception as e:\n",
        "            raise ValueFunctionFailed(packet_id, e) from e\n",
        "\n",
        "        return value\n",
        "\n",
        "    async def async_get_value(self, packet_id: str) -> Any:\n",
        "        \"\"\"Async version of get_value, supporting async value functions.\"\"\"\n",
        "        if packet_id not in self._values:\n",
        "            if packet_id in self._consumed_values:\n",
        "                return self._consumed_values[packet_id]\n",
        "            if self._storage_path:\n",
        "                value = self._load_from_file(packet_id)\n",
        "                if value is not None:\n",
        "                    return value\n",
        "            raise KeyError(f\"Packet {packet_id} not found in value store\")\n",
        "\n",
        "        stored = self._values[packet_id]\n",
        "        try:\n",
        "            value = await stored.async_get_value()\n",
        "        except Exception as e:\n",
        "            raise ValueFunctionFailed(packet_id, e) from e\n",
        "\n",
        "        return value\n",
        "\n",
        "    def consume(self, packet_id: str) -> Any:\n",
        "        \"\"\"\n",
        "        Consume a packet's value, removing it from active storage.\n",
        "\n",
        "        If consumed_storage is enabled, the value is kept in consumed storage.\n",
        "        \"\"\"\n",
        "        value = self.get_value(packet_id)\n",
        "        self._remove_from_active(packet_id)\n",
        "\n",
        "        if self._consumed_storage:\n",
        "            self._add_to_consumed(packet_id, value)\n",
        "\n",
        "        return value\n",
        "\n",
        "    async def async_consume(self, packet_id: str) -> Any:\n",
        "        \"\"\"Async version of consume.\"\"\"\n",
        "        value = await self.async_get_value(packet_id)\n",
        "        self._remove_from_active(packet_id)\n",
        "\n",
        "        if self._consumed_storage:\n",
        "            self._add_to_consumed(packet_id, value)\n",
        "\n",
        "        return value\n",
        "\n",
        "    def unconsume(self, packet_id: str, value: Any) -> None:\n",
        "        \"\"\"\n",
        "        Restore a consumed packet's value (for retry scenarios).\n",
        "\n",
        "        This moves the value back to active storage.\n",
        "        \"\"\"\n",
        "        self._values[packet_id] = StoredValue(value=value, is_value_func=False)\n",
        "\n",
        "        # Remove from consumed if present\n",
        "        if packet_id in self._consumed_values:\n",
        "            del self._consumed_values[packet_id]\n",
        "\n",
        "    def has_value(self, packet_id: str) -> bool:\n",
        "        \"\"\"Check if a packet has a stored value.\"\"\"\n",
        "        return packet_id in self._values\n",
        "\n",
        "    def remove(self, packet_id: str) -> None:\n",
        "        \"\"\"Remove a packet's value from the store entirely.\"\"\"\n",
        "        self._remove_from_active(packet_id)\n",
        "        if packet_id in self._consumed_values:\n",
        "            del self._consumed_values[packet_id]\n",
        "\n",
        "    def get_consumed_value(self, packet_id: str) -> Optional[Any]:\n",
        "        \"\"\"Get a value from consumed storage (doesn't remove it).\"\"\"\n",
        "        return self._consumed_values.get(packet_id)\n",
        "\n",
        "    def _remove_from_active(self, packet_id: str) -> None:\n",
        "        \"\"\"Remove from active storage.\"\"\"\n",
        "        if packet_id in self._values:\n",
        "            del self._values[packet_id]\n",
        "\n",
        "    def _add_to_consumed(self, packet_id: str, value: Any) -> None:\n",
        "        \"\"\"Add to consumed storage, respecting limits.\"\"\"\n",
        "        self._consumed_values[packet_id] = value\n",
        "\n",
        "        # Enforce limit by removing oldest entries\n",
        "        if self._consumed_storage_limit is not None:\n",
        "            while len(self._consumed_values) > self._consumed_storage_limit:\n",
        "                self._consumed_values.popitem(last=False)\n",
        "\n",
        "    def _persist_to_file(self, packet_id: str, value: Any) -> None:\n",
        "        \"\"\"Persist a value to file storage.\"\"\"\n",
        "        if self._storage_path:\n",
        "            file_path = self._storage_path / f\"{packet_id}.pkl\"\n",
        "            with open(file_path, 'wb') as f:\n",
        "                pickle.dump(value, f)\n",
        "\n",
        "    def _load_from_file(self, packet_id: str) -> Optional[Any]:\n",
        "        \"\"\"Load a value from file storage.\"\"\"\n",
        "        if self._storage_path:\n",
        "            file_path = self._storage_path / f\"{packet_id}.pkl\"\n",
        "            if file_path.exists():\n",
        "                with open(file_path, 'rb') as f:\n",
        "                    return pickle.load(f)\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Configuration\n",
        "\n",
        "Configuration dataclasses for nodes and their execution settings."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class NodeConfig:\n",
        "    \"\"\"Configuration for a node's execution behavior.\"\"\"\n",
        "    pool: Optional[Union[str, List[str]]] = None\n",
        "    max_parallel_epochs: Optional[int] = None\n",
        "    rate_limit_per_second: Optional[float] = None\n",
        "    defer_net_actions: bool = False\n",
        "    retries: int = 0\n",
        "    retry_wait: float = 0.0\n",
        "    timeout: Optional[float] = None\n",
        "    dead_letter_queue: bool = True\n",
        "    capture_stdout: bool = True\n",
        "    echo_stdout: bool = False\n",
        "    pool_init_mode: str = \"per_worker\"  # \"per_worker\" or \"global\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # Enforce constraint: retries > 0 requires defer_net_actions\n",
        "        if self.retries > 0 and not self.defer_net_actions:\n",
        "            raise ValueError(\n",
        "                \"defer_net_actions must be True when retries > 0\"\n",
        "            )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class NodeExecFuncs:\n",
        "    \"\"\"Execution functions for a node.\"\"\"\n",
        "    exec_func: Optional[Callable] = None\n",
        "    start_func: Optional[Callable] = None\n",
        "    stop_func: Optional[Callable] = None\n",
        "    failed_func: Optional[Callable] = None"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Net Class\n",
        "\n",
        "The main `Net` class wraps `netrun-sim`'s `NetSim` and provides the high-level API\n",
        "for running flow-based networks."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from typing import Dict\n",
        "from enum import Enum, auto\n",
        "\n",
        "\n",
        "class NetState(Enum):\n",
        "    \"\"\"The current state of the Net.\"\"\"\n",
        "    CREATED = auto()      # Net created but not started\n",
        "    RUNNING = auto()      # Net is actively running\n",
        "    PAUSED = auto()       # Net is paused (can resume)\n",
        "    STOPPED = auto()      # Net is stopped (cannot resume)\n",
        "\n",
        "\n",
        "class Net:\n",
        "    \"\"\"\n",
        "    High-level runtime for flow-based development graphs.\n",
        "\n",
        "    Wraps `netrun-sim`'s `NetSim` to provide:\n",
        "    - Actual node execution logic\n",
        "    - Packet value storage\n",
        "    - Configuration and control methods\n",
        "\n",
        "    The underlying `NetSim` is hidden from users - all interactions\n",
        "    go through this class's methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        graph: Graph,\n",
        "        *,\n",
        "        # Packet storage\n",
        "        consumed_packet_storage: bool = False,\n",
        "        consumed_packet_storage_limit: Optional[int] = None,\n",
        "        packet_storage_path: Optional[Union[str, Path]] = None,\n",
        "        # Pools\n",
        "        thread_pools: Optional[Dict[str, dict]] = None,\n",
        "        process_pools: Optional[Dict[str, dict]] = None,\n",
        "        # Error handling\n",
        "        on_error: str = \"pause\",  # \"continue\", \"pause\", \"raise\"\n",
        "        error_callback: Optional[Callable] = None,\n",
        "        # Dead letter queue\n",
        "        dead_letter_queue: str = \"memory\",  # \"memory\", \"file\", or callback\n",
        "        dead_letter_path: Optional[Union[str, Path]] = None,\n",
        "        dead_letter_callback: Optional[Callable] = None,\n",
        "        # History\n",
        "        history_max_size: Optional[int] = None,\n",
        "        history_file: Optional[Union[str, Path]] = None,\n",
        "        history_chunk_size: int = 100,\n",
        "        history_flush_on_pause: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create a new Net from a graph.\n",
        "\n",
        "        Args:\n",
        "            graph: The network topology (from netrun_sim.Graph)\n",
        "            consumed_packet_storage: Keep values after consumption\n",
        "            consumed_packet_storage_limit: Max consumed values to keep\n",
        "            packet_storage_path: Path for file-based packet storage\n",
        "            thread_pools: Thread pool configurations {\"name\": {\"size\": N}}\n",
        "            process_pools: Process pool configurations {\"name\": {\"size\": N}}\n",
        "            on_error: Error handling mode (\"continue\", \"pause\", \"raise\")\n",
        "            error_callback: Called on any node error\n",
        "            dead_letter_queue: DLQ mode (\"memory\", \"file\", or callback)\n",
        "            dead_letter_path: Path for file-based DLQ\n",
        "            dead_letter_callback: Callback for DLQ\n",
        "            history_max_size: Max events in memory\n",
        "            history_file: Path for history persistence\n",
        "            history_chunk_size: Events per history write\n",
        "            history_flush_on_pause: Flush history when paused\n",
        "        \"\"\"\n",
        "        # Validate on_error\n",
        "        if on_error not in (\"continue\", \"pause\", \"raise\"):\n",
        "            raise ValueError(f\"on_error must be 'continue', 'pause', or 'raise', got '{on_error}'\")\n",
        "\n",
        "        # Store the graph and create internal NetSim\n",
        "        self._graph = graph\n",
        "        self._sim = NetSim(graph)\n",
        "\n",
        "        # Packet value storage\n",
        "        self._value_store = PacketValueStore(\n",
        "            consumed_storage=consumed_packet_storage,\n",
        "            consumed_storage_limit=consumed_packet_storage_limit,\n",
        "            storage_path=packet_storage_path,\n",
        "        )\n",
        "\n",
        "        # Node configurations and execution functions\n",
        "        self._node_configs: Dict[str, NodeConfig] = {}\n",
        "        self._node_exec_funcs: Dict[str, NodeExecFuncs] = {}\n",
        "\n",
        "        # Pool configurations (to be implemented in Milestone 6)\n",
        "        self._thread_pools_config = thread_pools or {}\n",
        "        self._process_pools_config = process_pools or {}\n",
        "\n",
        "        # Error handling\n",
        "        self._on_error = on_error\n",
        "        self._error_callback = error_callback\n",
        "\n",
        "        # Dead letter queue config (to be implemented in Milestone 4)\n",
        "        self._dlq_mode = dead_letter_queue\n",
        "        self._dlq_path = Path(dead_letter_path) if dead_letter_path else None\n",
        "        self._dlq_callback = dead_letter_callback\n",
        "\n",
        "        # History config (to be implemented in Milestone 8)\n",
        "        self._history_max_size = history_max_size\n",
        "        self._history_file = Path(history_file) if history_file else None\n",
        "        self._history_chunk_size = history_chunk_size\n",
        "        self._history_flush_on_pause = history_flush_on_pause\n",
        "\n",
        "        # Runtime state\n",
        "        self._state = NetState.CREATED\n",
        "        # Track manually-created Running epochs that need execution\n",
        "        self._pending_running_epochs: set[str] = set()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Node Configuration\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def set_node_exec(\n",
        "        self,\n",
        "        node_name: str,\n",
        "        exec_func: Callable,\n",
        "        start_func: Optional[Callable] = None,\n",
        "        stop_func: Optional[Callable] = None,\n",
        "        failed_func: Optional[Callable] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Set execution functions for a node.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            exec_func: Main execution function (required)\n",
        "            start_func: Called when net starts (optional)\n",
        "            stop_func: Called when net stops (optional)\n",
        "            failed_func: Called after failed execution (optional)\n",
        "        \"\"\"\n",
        "        # Validate node exists\n",
        "        nodes = self._sim.graph.nodes()\n",
        "        if node_name not in nodes:\n",
        "            raise NodeNotFoundError(f\"Node '{node_name}' not found in graph\")\n",
        "\n",
        "        self._node_exec_funcs[node_name] = NodeExecFuncs(\n",
        "            exec_func=exec_func,\n",
        "            start_func=start_func,\n",
        "            stop_func=stop_func,\n",
        "            failed_func=failed_func,\n",
        "        )\n",
        "\n",
        "    def set_node_config(self, node_name: str, **options) -> None:\n",
        "        \"\"\"\n",
        "        Set configuration options for a node.\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node\n",
        "            **options: Configuration options (see NodeConfig)\n",
        "        \"\"\"\n",
        "        # Validate node exists\n",
        "        nodes = self._sim.graph.nodes()\n",
        "        if node_name not in nodes:\n",
        "            raise NodeNotFoundError(f\"Node '{node_name}' not found in graph\")\n",
        "\n",
        "        # Validate options before applying\n",
        "        valid_options = {f.name for f in NodeConfig.__dataclass_fields__.values()}\n",
        "        for key in options:\n",
        "            if key not in valid_options:\n",
        "                raise ValueError(f\"Unknown config option: {key}\")\n",
        "\n",
        "        # Get existing config or create new\n",
        "        if node_name in self._node_configs:\n",
        "            # Update existing config\n",
        "            current = self._node_configs[node_name]\n",
        "            for key, value in options.items():\n",
        "                setattr(current, key, value)\n",
        "            # Re-validate after update\n",
        "            current.__post_init__()\n",
        "        else:\n",
        "            # Create new config\n",
        "            self._node_configs[node_name] = NodeConfig(**options)\n",
        "\n",
        "    def get_node_config(self, node_name: str) -> NodeConfig:\n",
        "        \"\"\"Get the configuration for a node (returns default if not set).\"\"\"\n",
        "        return self._node_configs.get(node_name, NodeConfig())\n",
        "\n",
        "    def get_node_exec_funcs(self, node_name: str) -> Optional[NodeExecFuncs]:\n",
        "        \"\"\"Get the execution functions for a node.\"\"\"\n",
        "        return self._node_exec_funcs.get(node_name)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # NetSim Wrapper Methods (hide NetSim from users)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def graph(self) -> Graph:\n",
        "        \"\"\"Get the network topology.\"\"\"\n",
        "        return self._graph\n",
        "\n",
        "    @property\n",
        "    def state(self) -> NetState:\n",
        "        \"\"\"Get the current state of the net.\"\"\"\n",
        "        return self._state\n",
        "\n",
        "    def get_startable_epochs(self) -> list:\n",
        "        \"\"\"Get all epochs that are ready to be started.\"\"\"\n",
        "        return self._sim.get_startable_epochs()\n",
        "\n",
        "    def get_startable_epochs_by_node(self, node_name: str) -> list:\n",
        "        \"\"\"Get startable epochs for a specific node.\"\"\"\n",
        "        all_startable = self._sim.get_startable_epochs()\n",
        "        result = []\n",
        "        for epoch_id in all_startable:\n",
        "            epoch = self._sim.get_epoch(epoch_id)\n",
        "            if epoch and epoch.node_name == node_name:\n",
        "                result.append(epoch_id)\n",
        "        return result\n",
        "\n",
        "    def get_epoch(self, epoch_id) -> Optional[Epoch]:\n",
        "        \"\"\"Get an epoch by ID.\"\"\"\n",
        "        return self._sim.get_epoch(epoch_id)\n",
        "\n",
        "    def get_packet(self, packet_id) -> Optional[Packet]:\n",
        "        \"\"\"Get a packet by ID.\"\"\"\n",
        "        return self._sim.get_packet(packet_id)\n",
        "\n",
        "    def get_packets_at_location(self, location: PacketLocation) -> list:\n",
        "        \"\"\"Get all packet IDs at a specific location.\"\"\"\n",
        "        return self._sim.get_packets_at_location(location)\n",
        "\n",
        "    def packet_count_at(self, location: PacketLocation) -> int:\n",
        "        \"\"\"Get the number of packets at a location.\"\"\"\n",
        "        return self._sim.packet_count_at(location)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Value Store Access\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def value_store(self) -> PacketValueStore:\n",
        "        \"\"\"Access the packet value store.\"\"\"\n",
        "        return self._value_store\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Execution Methods (Milestone 3)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def inject_source_epoch(self, node_name: str, input_salvo: Optional[\"Salvo\"] = None) -> str:\n",
        "        \"\"\"\n",
        "        Manually create and start an epoch for a source node (or any node).\n",
        "\n",
        "        This is used for nodes without input ports (sources) or when manually\n",
        "        injecting data into a node. The epoch is created as Running and\n",
        "        marked for execution by run_step().\n",
        "\n",
        "        Args:\n",
        "            node_name: Name of the node to create an epoch for\n",
        "            input_salvo: Optional Salvo for input packets. Defaults to empty.\n",
        "\n",
        "        Returns:\n",
        "            The epoch ID of the created epoch.\n",
        "        \"\"\"\n",
        "        if input_salvo is None:\n",
        "            input_salvo = Salvo(\"\", [])\n",
        "\n",
        "        action = NetAction.create_and_start_epoch(node_name, input_salvo)\n",
        "        events = self._sim.do_action(action)\n",
        "\n",
        "        # Find the epoch ID from events\n",
        "        epoch_id = None\n",
        "        for e in events[1]:\n",
        "            if hasattr(e, 'epoch_id'):\n",
        "                epoch_id = str(e.epoch_id)\n",
        "                break\n",
        "\n",
        "        if epoch_id is None:\n",
        "            raise RuntimeError(f\"Failed to create epoch for {node_name}\")\n",
        "\n",
        "        # Mark this epoch as needing execution\n",
        "        self._pending_running_epochs.add(epoch_id)\n",
        "        return epoch_id\n",
        "\n",
        "    def _get_input_packets(self, epoch) -> dict[str, list]:\n",
        "        \"\"\"\n",
        "        Get input packets for an epoch organized by port name.\n",
        "\n",
        "        Returns dict[port_name, list[Packet]].\n",
        "        \"\"\"\n",
        "        in_salvo = epoch.in_salvo\n",
        "        if in_salvo is None:\n",
        "            return {}\n",
        "\n",
        "        # in_salvo.packets is a list of (port_name, packet_id) tuples\n",
        "        result = {}\n",
        "        for port_name, pkt_id in in_salvo.packets:\n",
        "            pkt = self._sim.get_packet(pkt_id)\n",
        "            if pkt is not None:\n",
        "                if port_name not in result:\n",
        "                    result[port_name] = []\n",
        "                result[port_name].append(pkt)\n",
        "        return result\n",
        "\n",
        "    def _execute_epoch(self, epoch_id: str) -> None:\n",
        "        \"\"\"\n",
        "        Execute a single epoch synchronously.\n",
        "\n",
        "        This method:\n",
        "        1. Gets the epoch and its input packets\n",
        "        2. Creates a NodeExecutionContext\n",
        "        3. Calls the node's exec_func\n",
        "        4. On success: commits deferred actions and finishes the epoch\n",
        "        5. On failure: calls failed_func and handles based on on_error setting\n",
        "        \"\"\"\n",
        "        import time\n",
        "        from datetime import datetime\n",
        "\n",
        "        epoch = self._sim.get_epoch(epoch_id)\n",
        "        if epoch is None:\n",
        "            raise ValueError(f\"Epoch {epoch_id} not found\")\n",
        "\n",
        "        node_name = epoch.node_name\n",
        "        config = self.get_node_config(node_name)\n",
        "        exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "\n",
        "        # Skip if no exec_func defined (epoch stays Startable)\n",
        "        if exec_funcs is None or exec_funcs.exec_func is None:\n",
        "            return\n",
        "\n",
        "        # Start the epoch if not already Running\n",
        "        # (Epochs from inject_source_epoch are already Running)\n",
        "        if epoch.state == EpochState.Startable:\n",
        "            action = NetAction.start_epoch(epoch_id)\n",
        "            self._sim.do_action(action)\n",
        "\n",
        "        # Remove from pending running epochs if present\n",
        "        self._pending_running_epochs.discard(epoch_id)\n",
        "\n",
        "        # Get input packets\n",
        "        input_packets = self._get_input_packets(epoch)\n",
        "\n",
        "        # Create execution context\n",
        "        ctx = NodeExecutionContext(\n",
        "            net=self,\n",
        "            epoch_id=epoch_id,\n",
        "            node_name=node_name,\n",
        "            defer_net_actions=config.defer_net_actions,\n",
        "            retry_count=0,\n",
        "            retry_timestamps=[],\n",
        "            retry_exceptions=[],\n",
        "        )\n",
        "\n",
        "        # Track start time for timeout\n",
        "        start_time = time.time()\n",
        "        exception_raised = None\n",
        "\n",
        "        try:\n",
        "            # Check for timeout before execution\n",
        "            if config.timeout is not None:\n",
        "                elapsed = time.time() - start_time\n",
        "                if elapsed >= config.timeout:\n",
        "                    raise EpochTimeout(node_name, epoch_id, config.timeout)\n",
        "\n",
        "            # Execute the node function\n",
        "            exec_funcs.exec_func(ctx, input_packets)\n",
        "\n",
        "            # Success - commit deferred actions if any\n",
        "            if config.defer_net_actions and ctx._deferred_queue is not None:\n",
        "                _commit_deferred_actions(self, epoch_id, ctx._deferred_queue)\n",
        "\n",
        "            # Finish the epoch\n",
        "            action = NetAction.finish_epoch(epoch_id)\n",
        "            self._sim.do_action(action)\n",
        "\n",
        "        except EpochCancelled:\n",
        "            # Epoch was cancelled by the node - cancel in NetSim\n",
        "            action = NetAction.cancel_epoch(epoch_id)\n",
        "            self._sim.do_action(action)\n",
        "            raise\n",
        "\n",
        "        except EpochTimeout as e:\n",
        "            exception_raised = e\n",
        "            # Cancel the epoch\n",
        "            action = NetAction.cancel_epoch(epoch_id)\n",
        "            self._sim.do_action(action)\n",
        "\n",
        "        except Exception as e:\n",
        "            exception_raised = e\n",
        "            # Execution failed\n",
        "            # For Milestone 3, we just handle the error based on on_error setting\n",
        "            # Retry logic will be added in Milestone 4\n",
        "\n",
        "            # Cancel the epoch (cleanup)\n",
        "            action = NetAction.cancel_epoch(epoch_id)\n",
        "            self._sim.do_action(action)\n",
        "\n",
        "        # Handle failure\n",
        "        if exception_raised is not None:\n",
        "            # Call failed_func if defined\n",
        "            if exec_funcs.failed_func is not None:\n",
        "                failure_ctx = NodeFailureContext(\n",
        "                    epoch_id=epoch_id,\n",
        "                    node_name=node_name,\n",
        "                    retry_count=0,\n",
        "                    retry_timestamps=[datetime.now()],\n",
        "                    retry_exceptions=[exception_raised],\n",
        "                    input_salvo=input_packets,\n",
        "                    packet_values=ctx._get_consumed_values(),\n",
        "                    exception=exception_raised,\n",
        "                )\n",
        "                try:\n",
        "                    exec_funcs.failed_func(failure_ctx)\n",
        "                except Exception:\n",
        "                    pass  # Ignore errors in failed_func\n",
        "\n",
        "            # Call error callback if defined\n",
        "            if self._error_callback is not None:\n",
        "                try:\n",
        "                    self._error_callback(exception_raised, node_name, epoch_id)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            # Handle based on on_error setting\n",
        "            if self._on_error == \"raise\":\n",
        "                self._state = NetState.PAUSED\n",
        "                raise NodeExecutionFailed(node_name, epoch_id, exception_raised) from exception_raised\n",
        "            elif self._on_error == \"pause\":\n",
        "                self._state = NetState.PAUSED\n",
        "            # \"continue\" - just keep going\n",
        "\n",
        "    def _call_start_funcs(self) -> None:\n",
        "        \"\"\"Call start_node_func for all nodes that have one defined.\"\"\"\n",
        "        for node_name in self._graph.nodes():\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "            if exec_funcs is not None and exec_funcs.start_func is not None:\n",
        "                exec_funcs.start_func(self)\n",
        "\n",
        "    def _call_stop_funcs(self) -> None:\n",
        "        \"\"\"Call stop_node_func for all nodes that have one defined.\"\"\"\n",
        "        for node_name in self._graph.nodes():\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "            if exec_funcs is not None and exec_funcs.stop_func is not None:\n",
        "                exec_funcs.stop_func(self)\n",
        "\n",
        "    def run_step(self, start_epochs: bool = True, threaded: bool = False) -> None:\n",
        "        \"\"\"\n",
        "        Run one step of the network.\n",
        "\n",
        "        This method:\n",
        "        1. Runs NetSim until blocked (moves packets, creates startable epochs)\n",
        "        2. If start_epochs=True, executes all startable epochs\n",
        "        3. Returns when no more progress can be made in this step\n",
        "\n",
        "        Args:\n",
        "            start_epochs: Whether to start and execute ready epochs\n",
        "            threaded: Run in background thread (Milestone 6)\n",
        "        \"\"\"\n",
        "        if threaded:\n",
        "            raise NotImplementedError(\"threaded=True will be implemented in Milestone 6\")\n",
        "\n",
        "        if self._state == NetState.STOPPED:\n",
        "            raise RuntimeError(\"Cannot run_step on a stopped net\")\n",
        "\n",
        "        if self._state == NetState.PAUSED:\n",
        "            return  # Don't do anything if paused\n",
        "\n",
        "        self._state = NetState.RUNNING\n",
        "\n",
        "        # Run NetSim until blocked\n",
        "        action = NetAction.run_net_until_blocked()\n",
        "        self._sim.do_action(action)\n",
        "\n",
        "        if not start_epochs:\n",
        "            return\n",
        "\n",
        "        # Combine startable epochs and pending running epochs\n",
        "        startable = list(self._sim.get_startable_epochs())\n",
        "        pending_running = list(self._pending_running_epochs)\n",
        "        epochs_to_execute = startable + pending_running\n",
        "\n",
        "        for epoch_id in epochs_to_execute:\n",
        "            # Convert ULID to string if needed\n",
        "            epoch_id = str(epoch_id)\n",
        "\n",
        "            if self._state == NetState.PAUSED:\n",
        "                break  # Stop if we got paused during execution\n",
        "\n",
        "            epoch = self._sim.get_epoch(epoch_id)\n",
        "            if epoch is None:\n",
        "                continue\n",
        "\n",
        "            node_name = epoch.node_name\n",
        "            exec_funcs = self.get_node_exec_funcs(node_name)\n",
        "\n",
        "            # Skip nodes without exec_func\n",
        "            if exec_funcs is None or exec_funcs.exec_func is None:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                self._execute_epoch(epoch_id)\n",
        "            except EpochCancelled:\n",
        "                pass  # Epoch was cancelled, continue with others\n",
        "            except NodeExecutionFailed:\n",
        "                if self._on_error == \"raise\":\n",
        "                    raise\n",
        "                # For \"pause\" and \"continue\", error is already handled\n",
        "\n",
        "    def start(self, threaded: bool = False) -> None:\n",
        "        \"\"\"\n",
        "        Start the network and run until fully blocked.\n",
        "\n",
        "        This method:\n",
        "        1. Calls start_node_func for all nodes\n",
        "        2. Runs run_step() in a loop until no more progress\n",
        "        3. Calls stop_node_func for all nodes when done\n",
        "\n",
        "        Args:\n",
        "            threaded: Run in background thread (Milestone 6)\n",
        "        \"\"\"\n",
        "        if threaded:\n",
        "            raise NotImplementedError(\"threaded=True will be implemented in Milestone 6\")\n",
        "\n",
        "        if self._state == NetState.STOPPED:\n",
        "            raise RuntimeError(\"Cannot start a stopped net\")\n",
        "\n",
        "        # Call start functions\n",
        "        self._call_start_funcs()\n",
        "\n",
        "        self._state = NetState.RUNNING\n",
        "\n",
        "        try:\n",
        "            # Run until fully blocked\n",
        "            while self._state == NetState.RUNNING:\n",
        "                # Check what epochs we can execute before this step\n",
        "                startable_before = set(self._sim.get_startable_epochs())\n",
        "                pending_before = set(self._pending_running_epochs)\n",
        "                epochs_before = startable_before | pending_before\n",
        "\n",
        "                self.run_step(start_epochs=True)\n",
        "\n",
        "                # After run_step, move any new packets from edges to input ports\n",
        "                # This ensures epochs created by output packets are visible\n",
        "                action = NetAction.run_net_until_blocked()\n",
        "                self._sim.do_action(action)\n",
        "\n",
        "                # Check what epochs we can execute after this step\n",
        "                startable_after = set(self._sim.get_startable_epochs())\n",
        "                pending_after = set(self._pending_running_epochs)\n",
        "                epochs_after = startable_after | pending_after\n",
        "\n",
        "                # Check if we're fully blocked\n",
        "                # Fully blocked = no epochs to execute and no progress was made\n",
        "                can_execute = False\n",
        "                for epoch_id in epochs_after:\n",
        "                    epoch = self._sim.get_epoch(str(epoch_id))\n",
        "                    if epoch:\n",
        "                        exec_funcs = self.get_node_exec_funcs(epoch.node_name)\n",
        "                        if exec_funcs and exec_funcs.exec_func:\n",
        "                            can_execute = True\n",
        "                            break\n",
        "\n",
        "                if not can_execute and epochs_before == epochs_after:\n",
        "                    # No progress made and no executable epochs\n",
        "                    break\n",
        "\n",
        "        finally:\n",
        "            # Call stop functions\n",
        "            self._call_stop_funcs()\n",
        "            if self._state == NetState.RUNNING:\n",
        "                self._state = NetState.PAUSED\n",
        "\n",
        "    def pause(self) -> None:\n",
        "        \"\"\"\n",
        "        Pause the network (finish running epochs, don't start new ones).\n",
        "\n",
        "        (To be implemented in Milestone 6)\n",
        "        \"\"\"\n",
        "        # For now, just set state\n",
        "        self._state = NetState.PAUSED\n",
        "\n",
        "    def stop(self) -> None:\n",
        "        \"\"\"\n",
        "        Stop the network entirely.\n",
        "\n",
        "        (To be implemented in Milestone 6)\n",
        "        \"\"\"\n",
        "        self._state = NetState.STOPPED\n",
        "\n",
        "    def save_checkpoint(self, path: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Save a complete checkpoint of the network state.\n",
        "\n",
        "        Requires the net to be paused.\n",
        "\n",
        "        (To be implemented in Milestone 13)\n",
        "        \"\"\"\n",
        "        if self._state != NetState.PAUSED:\n",
        "            raise NetNotPausedError(\"save_checkpoint\")\n",
        "        raise NotImplementedError(\"save_checkpoint will be implemented in Milestone 13\")\n",
        "\n",
        "    @classmethod\n",
        "    def load_checkpoint(cls, path: Union[str, Path]) -> \"Net\":\n",
        "        \"\"\"\n",
        "        Load a network from a checkpoint.\n",
        "\n",
        "        (To be implemented in Milestone 13)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"load_checkpoint will be implemented in Milestone 13\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deferred Packets and Actions\n",
        "\n",
        "When `defer_net_actions=True`, packet operations are queued rather than executed immediately.\n",
        "This allows clean retry without orphaned packets."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from datetime import datetime\n",
        "from typing import TYPE_CHECKING\n",
        "import uuid\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from typing import Self\n",
        "\n",
        "\n",
        "class DeferredPacket:\n",
        "    \"\"\"\n",
        "    A placeholder for a packet when defer_net_actions=True.\n",
        "\n",
        "    Behaves like a Packet for node operations (loading to output ports, etc.),\n",
        "    but the actual PacketID is not assigned until deferred actions are committed.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, deferred_id: str):\n",
        "        \"\"\"\n",
        "        Initialize a deferred packet with a temporary internal ID.\n",
        "\n",
        "        Args:\n",
        "            deferred_id: Internal ID used to track this packet until commit\n",
        "        \"\"\"\n",
        "        self._deferred_id = deferred_id\n",
        "        self._resolved_packet: Optional[Packet] = None\n",
        "\n",
        "    @property\n",
        "    def id(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the packet ID.\n",
        "\n",
        "        Raises DeferredPacketIdAccessError if not yet committed.\n",
        "        \"\"\"\n",
        "        if self._resolved_packet is None:\n",
        "            raise DeferredPacketIdAccessError()\n",
        "        return self._resolved_packet.id\n",
        "\n",
        "    @property\n",
        "    def deferred_id(self) -> str:\n",
        "        \"\"\"Get the internal deferred ID (always available).\"\"\"\n",
        "        return self._deferred_id\n",
        "\n",
        "    @property\n",
        "    def is_resolved(self) -> bool:\n",
        "        \"\"\"Check if this deferred packet has been resolved to a real packet.\"\"\"\n",
        "        return self._resolved_packet is not None\n",
        "\n",
        "    def _resolve(self, packet: Packet) -> None:\n",
        "        \"\"\"Internal: resolve this deferred packet to a real packet.\"\"\"\n",
        "        self._resolved_packet = packet\n",
        "\n",
        "    @property\n",
        "    def location(self):\n",
        "        \"\"\"Get the packet location (only available after resolution).\"\"\"\n",
        "        if self._resolved_packet is None:\n",
        "            raise DeferredPacketIdAccessError()\n",
        "        return self._resolved_packet.location\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        if self._resolved_packet is not None:\n",
        "            return f\"DeferredPacket(resolved={self._resolved_packet.id})\"\n",
        "        return f\"DeferredPacket(deferred_id={self._deferred_id})\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "from enum import Enum\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, List, Optional, Union\n",
        "\n",
        "\n",
        "class DeferredActionType(Enum):\n",
        "    \"\"\"Types of deferred actions.\"\"\"\n",
        "    CREATE_PACKET = \"create_packet\"\n",
        "    CREATE_PACKET_FROM_FUNC = \"create_packet_from_func\"\n",
        "    CONSUME_PACKET = \"consume_packet\"\n",
        "    LOAD_OUTPUT_PORT = \"load_output_port\"\n",
        "    SEND_OUTPUT_SALVO = \"send_output_salvo\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DeferredAction:\n",
        "    \"\"\"A single deferred action to be committed or discarded.\"\"\"\n",
        "    action_type: DeferredActionType\n",
        "    # For CREATE_PACKET: value to store\n",
        "    value: Any = None\n",
        "    # For CREATE_PACKET_FROM_FUNC: the value function\n",
        "    value_func: Optional[Callable] = None\n",
        "    # For CREATE_PACKET/CREATE_PACKET_FROM_FUNC: the deferred packet created\n",
        "    deferred_packet: Optional[DeferredPacket] = None\n",
        "    # For CONSUME_PACKET: the packet (or deferred packet) being consumed\n",
        "    packet: Optional[Union[Packet, DeferredPacket]] = None\n",
        "    # For CONSUME_PACKET: the consumed value (stored for unconsume on retry)\n",
        "    consumed_value: Any = None\n",
        "    # For LOAD_OUTPUT_PORT: port name\n",
        "    port_name: Optional[str] = None\n",
        "    # For SEND_OUTPUT_SALVO: salvo condition name\n",
        "    salvo_condition_name: Optional[str] = None\n",
        "\n",
        "\n",
        "class DeferredActionQueue:\n",
        "    \"\"\"\n",
        "    Queue of deferred actions for a node execution.\n",
        "\n",
        "    Used when defer_net_actions=True to buffer operations until successful completion.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._actions: List[DeferredAction] = []\n",
        "        self._deferred_packet_counter = 0\n",
        "        # Track consumed values for unconsume on retry\n",
        "        self._consumed_values: dict[str, Any] = {}\n",
        "\n",
        "    def create_packet(self, value: Any) -> DeferredPacket:\n",
        "        \"\"\"Queue a packet creation with a direct value.\"\"\"\n",
        "        deferred_id = f\"deferred-{self._deferred_packet_counter}\"\n",
        "        self._deferred_packet_counter += 1\n",
        "        deferred_packet = DeferredPacket(deferred_id)\n",
        "        self._actions.append(DeferredAction(\n",
        "            action_type=DeferredActionType.CREATE_PACKET,\n",
        "            value=value,\n",
        "            deferred_packet=deferred_packet,\n",
        "        ))\n",
        "        return deferred_packet\n",
        "\n",
        "    def create_packet_from_func(self, func: Callable) -> DeferredPacket:\n",
        "        \"\"\"Queue a packet creation with a value function.\"\"\"\n",
        "        deferred_id = f\"deferred-{self._deferred_packet_counter}\"\n",
        "        self._deferred_packet_counter += 1\n",
        "        deferred_packet = DeferredPacket(deferred_id)\n",
        "        self._actions.append(DeferredAction(\n",
        "            action_type=DeferredActionType.CREATE_PACKET_FROM_FUNC,\n",
        "            value_func=func,\n",
        "            deferred_packet=deferred_packet,\n",
        "        ))\n",
        "        return deferred_packet\n",
        "\n",
        "    def consume_packet(self, packet: Union[Packet, DeferredPacket], value: Any) -> None:\n",
        "        \"\"\"Queue a packet consumption.\"\"\"\n",
        "        packet_id = packet._deferred_id if isinstance(packet, DeferredPacket) else packet.id\n",
        "        self._consumed_values[packet_id] = value\n",
        "        self._actions.append(DeferredAction(\n",
        "            action_type=DeferredActionType.CONSUME_PACKET,\n",
        "            packet=packet,\n",
        "            consumed_value=value,\n",
        "        ))\n",
        "\n",
        "    def load_output_port(self, port_name: str, packet: Union[Packet, DeferredPacket]) -> None:\n",
        "        \"\"\"Queue loading a packet to an output port.\"\"\"\n",
        "        self._actions.append(DeferredAction(\n",
        "            action_type=DeferredActionType.LOAD_OUTPUT_PORT,\n",
        "            port_name=port_name,\n",
        "            packet=packet,\n",
        "        ))\n",
        "\n",
        "    def send_output_salvo(self, salvo_condition_name: str) -> None:\n",
        "        \"\"\"Queue sending an output salvo.\"\"\"\n",
        "        self._actions.append(DeferredAction(\n",
        "            action_type=DeferredActionType.SEND_OUTPUT_SALVO,\n",
        "            salvo_condition_name=salvo_condition_name,\n",
        "        ))\n",
        "\n",
        "    @property\n",
        "    def actions(self) -> List[DeferredAction]:\n",
        "        \"\"\"Get all queued actions.\"\"\"\n",
        "        return self._actions\n",
        "\n",
        "    @property\n",
        "    def consumed_values(self) -> dict[str, Any]:\n",
        "        \"\"\"Get all consumed values (for unconsume on retry).\"\"\"\n",
        "        return self._consumed_values\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"Clear all queued actions.\"\"\"\n",
        "        self._actions = []\n",
        "        self._consumed_values = {}\n",
        "        self._deferred_packet_counter = 0"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Execution Context\n",
        "\n",
        "The `NodeExecutionContext` is passed to node execution functions and provides\n",
        "methods for packet operations and epoch control."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "class NodeExecutionContext:\n",
        "    \"\"\"\n",
        "    Context passed to node execution functions.\n",
        "\n",
        "    Provides access to packet operations, retry information, and epoch control.\n",
        "    All packet operations respect the defer_net_actions setting.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        net: \"Net\",\n",
        "        epoch_id: str,\n",
        "        node_name: str,\n",
        "        defer_net_actions: bool = False,\n",
        "        retry_count: int = 0,\n",
        "        retry_timestamps: Optional[List[datetime]] = None,\n",
        "        retry_exceptions: Optional[List[Exception]] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the execution context.\n",
        "\n",
        "        Args:\n",
        "            net: The Net instance\n",
        "            epoch_id: ID of the current epoch\n",
        "            node_name: Name of the node being executed\n",
        "            defer_net_actions: Whether to buffer actions until successful completion\n",
        "            retry_count: Current retry attempt (0 = first attempt)\n",
        "            retry_timestamps: Timestamps of previous retry attempts\n",
        "            retry_exceptions: Exceptions from previous retries\n",
        "        \"\"\"\n",
        "        self._net = net\n",
        "        self._epoch_id = epoch_id\n",
        "        self._node_name = node_name\n",
        "        self._defer_net_actions = defer_net_actions\n",
        "        self._retry_count = retry_count\n",
        "        self._retry_timestamps = retry_timestamps or []\n",
        "        self._retry_exceptions = retry_exceptions or []\n",
        "\n",
        "        # Deferred action queue (only used if defer_net_actions=True)\n",
        "        self._deferred_queue: Optional[DeferredActionQueue] = (\n",
        "            DeferredActionQueue() if defer_net_actions else None\n",
        "        )\n",
        "\n",
        "        # Track consumed values for this execution (for failure context)\n",
        "        self._consumed_values: dict[str, Any] = {}\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Properties\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def epoch_id(self) -> str:\n",
        "        \"\"\"The ID of the current epoch.\"\"\"\n",
        "        return self._epoch_id\n",
        "\n",
        "    @property\n",
        "    def node_name(self) -> str:\n",
        "        \"\"\"The name of the node being executed.\"\"\"\n",
        "        return self._node_name\n",
        "\n",
        "    @property\n",
        "    def retry_count(self) -> int:\n",
        "        \"\"\"Current retry attempt (0 = first attempt).\"\"\"\n",
        "        return self._retry_count\n",
        "\n",
        "    @property\n",
        "    def retry_timestamps(self) -> List[datetime]:\n",
        "        \"\"\"Timestamps of previous retry attempts.\"\"\"\n",
        "        return self._retry_timestamps.copy()\n",
        "\n",
        "    @property\n",
        "    def retry_exceptions(self) -> List[Exception]:\n",
        "        \"\"\"Exceptions from previous retries.\"\"\"\n",
        "        return self._retry_exceptions.copy()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Packet Operations (Sync)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def create_packet(self, value: Any) -> Union[Packet, DeferredPacket]:\n",
        "        \"\"\"\n",
        "        Create a new packet with a direct value.\n",
        "\n",
        "        If defer_net_actions=True, returns a DeferredPacket.\n",
        "        Otherwise, creates the packet immediately in NetSim.\n",
        "        \"\"\"\n",
        "        if self._defer_net_actions and self._deferred_queue is not None:\n",
        "            return self._deferred_queue.create_packet(value)\n",
        "\n",
        "        # Immediate mode: create packet in NetSim\n",
        "        action = NetAction.create_packet(self._epoch_id)\n",
        "        events = self._net._sim.do_action(action)\n",
        "\n",
        "        # Get the created packet ID from the events\n",
        "        packet_id = None\n",
        "        for event in events:\n",
        "            if hasattr(event, 'packet_id'):\n",
        "                packet_id = event.packet_id\n",
        "                break\n",
        "\n",
        "        if packet_id is None:\n",
        "            raise RuntimeError(\"Failed to get packet ID from create_packet action\")\n",
        "\n",
        "        # Store the value\n",
        "        self._net._value_store.store_value(packet_id, value)\n",
        "\n",
        "        return self._net._sim.get_packet(packet_id)\n",
        "\n",
        "    def create_packet_from_value_func(self, func: Callable[[], Any]) -> Union[Packet, DeferredPacket]:\n",
        "        \"\"\"\n",
        "        Create a new packet with a lazy value function.\n",
        "\n",
        "        The function is called when the packet is consumed.\n",
        "\n",
        "        If defer_net_actions=True, returns a DeferredPacket.\n",
        "        Otherwise, creates the packet immediately in NetSim.\n",
        "        \"\"\"\n",
        "        if self._defer_net_actions and self._deferred_queue is not None:\n",
        "            return self._deferred_queue.create_packet_from_func(func)\n",
        "\n",
        "        # Immediate mode: create packet in NetSim\n",
        "        action = NetAction.create_packet(self._epoch_id)\n",
        "        events = self._net._sim.do_action(action)\n",
        "\n",
        "        # Get the created packet ID from the events\n",
        "        packet_id = None\n",
        "        for event in events:\n",
        "            if hasattr(event, 'packet_id'):\n",
        "                packet_id = event.packet_id\n",
        "                break\n",
        "\n",
        "        if packet_id is None:\n",
        "            raise RuntimeError(\"Failed to get packet ID from create_packet action\")\n",
        "\n",
        "        # Store the value function\n",
        "        self._net._value_store.store_value_func(packet_id, func)\n",
        "\n",
        "        return self._net._sim.get_packet(packet_id)\n",
        "\n",
        "    def consume_packet(self, packet: Union[Packet, DeferredPacket]) -> Any:\n",
        "        \"\"\"\n",
        "        Consume a packet and return its value.\n",
        "\n",
        "        Removes the packet from the network and returns the stored value.\n",
        "        If the packet has a value function, it is called.\n",
        "        \"\"\"\n",
        "        if isinstance(packet, DeferredPacket):\n",
        "            if not packet.is_resolved:\n",
        "                raise ValueError(\"Cannot consume an unresolved deferred packet\")\n",
        "            packet_id = packet.id\n",
        "        else:\n",
        "            packet_id = packet.id\n",
        "\n",
        "        # Get the value (this calls value functions if needed)\n",
        "        value = self._net._value_store.consume(packet_id)\n",
        "        self._consumed_values[packet_id] = value\n",
        "\n",
        "        if self._defer_net_actions and self._deferred_queue is not None:\n",
        "            # Defer the consume action\n",
        "            self._deferred_queue.consume_packet(packet, value)\n",
        "        else:\n",
        "            # Immediate mode: consume in NetSim\n",
        "            action = NetAction.consume_packet(packet_id)\n",
        "            self._net._sim.do_action(action)\n",
        "\n",
        "        return value\n",
        "\n",
        "    def load_output_port(self, port_name: str, packet: Union[Packet, DeferredPacket]) -> None:\n",
        "        \"\"\"\n",
        "        Load a packet into an output port.\n",
        "\n",
        "        The packet must have been created in this epoch.\n",
        "        \"\"\"\n",
        "        if self._defer_net_actions and self._deferred_queue is not None:\n",
        "            self._deferred_queue.load_output_port(port_name, packet)\n",
        "            return\n",
        "\n",
        "        # Immediate mode\n",
        "        if isinstance(packet, DeferredPacket):\n",
        "            if not packet.is_resolved:\n",
        "                raise ValueError(\"Cannot load an unresolved deferred packet\")\n",
        "            packet_id = packet.id\n",
        "        else:\n",
        "            packet_id = packet.id\n",
        "\n",
        "        action = NetAction.load_packet_into_output_port(packet_id, port_name)\n",
        "        self._net._sim.do_action(action)\n",
        "\n",
        "    def send_output_salvo(self, salvo_condition_name: str) -> None:\n",
        "        \"\"\"\n",
        "        Send packets from output ports via a salvo condition.\n",
        "\n",
        "        The salvo condition must be satisfied for sending to succeed.\n",
        "        \"\"\"\n",
        "        if self._defer_net_actions and self._deferred_queue is not None:\n",
        "            self._deferred_queue.send_output_salvo(salvo_condition_name)\n",
        "            return\n",
        "\n",
        "        # Immediate mode\n",
        "        action = NetAction.send_output_salvo(self._epoch_id, salvo_condition_name)\n",
        "        self._net._sim.do_action(action)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Packet Operations (Async)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    async def async_consume_packet(self, packet: Union[Packet, DeferredPacket]) -> Any:\n",
        "        \"\"\"\n",
        "        Async version of consume_packet.\n",
        "\n",
        "        Supports async value functions.\n",
        "        \"\"\"\n",
        "        if isinstance(packet, DeferredPacket):\n",
        "            if not packet.is_resolved:\n",
        "                raise ValueError(\"Cannot consume an unresolved deferred packet\")\n",
        "            packet_id = packet.id\n",
        "        else:\n",
        "            packet_id = packet.id\n",
        "\n",
        "        # Get the value (async to support async value functions)\n",
        "        value = await self._net._value_store.async_consume(packet_id)\n",
        "        self._consumed_values[packet_id] = value\n",
        "\n",
        "        if self._defer_net_actions and self._deferred_queue is not None:\n",
        "            self._deferred_queue.consume_packet(packet, value)\n",
        "        else:\n",
        "            action = NetAction.consume_packet(packet_id)\n",
        "            self._net._sim.do_action(action)\n",
        "\n",
        "        return value\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Epoch Control\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def cancel_epoch(self) -> None:\n",
        "        \"\"\"\n",
        "        Cancel the current epoch.\n",
        "\n",
        "        Raises EpochCancelled exception which should not be caught by the node.\n",
        "        \"\"\"\n",
        "        raise EpochCancelled(self._node_name, self._epoch_id)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Internal Methods\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _get_deferred_queue(self) -> Optional[DeferredActionQueue]:\n",
        "        \"\"\"Get the deferred action queue (for internal use).\"\"\"\n",
        "        return self._deferred_queue\n",
        "\n",
        "    def _get_consumed_values(self) -> dict[str, Any]:\n",
        "        \"\"\"Get the consumed values (for failure context).\"\"\"\n",
        "        return self._consumed_values.copy()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Failure Context\n",
        "\n",
        "The `NodeFailureContext` is passed to the `exec_failed_node_func` callback\n",
        "after a failed execution attempt."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "class NodeFailureContext:\n",
        "    \"\"\"\n",
        "    Context passed to node failure handlers after execution failure.\n",
        "\n",
        "    Provides access to retry information, input packets, and consumed values.\n",
        "    Does not provide packet operations (execution has already failed).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        epoch_id: str,\n",
        "        node_name: str,\n",
        "        retry_count: int,\n",
        "        retry_timestamps: List[datetime],\n",
        "        retry_exceptions: List[Exception],\n",
        "        input_salvo: dict[str, list[Packet]],\n",
        "        packet_values: dict[str, Any],\n",
        "        exception: Exception,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the failure context.\n",
        "\n",
        "        Args:\n",
        "            epoch_id: ID of the failed epoch\n",
        "            node_name: Name of the node that failed\n",
        "            retry_count: Current retry attempt (0 = first attempt)\n",
        "            retry_timestamps: Timestamps of all retry attempts including current\n",
        "            retry_exceptions: Exceptions from all retries including current\n",
        "            input_salvo: The input packets that triggered this epoch\n",
        "            packet_values: Values that were consumed during execution\n",
        "            exception: The exception that caused the failure\n",
        "        \"\"\"\n",
        "        self._epoch_id = epoch_id\n",
        "        self._node_name = node_name\n",
        "        self._retry_count = retry_count\n",
        "        self._retry_timestamps = retry_timestamps\n",
        "        self._retry_exceptions = retry_exceptions\n",
        "        self._input_salvo = input_salvo\n",
        "        self._packet_values = packet_values\n",
        "        self._exception = exception\n",
        "\n",
        "    @property\n",
        "    def epoch_id(self) -> str:\n",
        "        \"\"\"The ID of the failed epoch.\"\"\"\n",
        "        return self._epoch_id\n",
        "\n",
        "    @property\n",
        "    def node_name(self) -> str:\n",
        "        \"\"\"The name of the node that failed.\"\"\"\n",
        "        return self._node_name\n",
        "\n",
        "    @property\n",
        "    def retry_count(self) -> int:\n",
        "        \"\"\"Current retry attempt (0 = first attempt).\"\"\"\n",
        "        return self._retry_count\n",
        "\n",
        "    @property\n",
        "    def retry_timestamps(self) -> List[datetime]:\n",
        "        \"\"\"Timestamps of all retry attempts including current.\"\"\"\n",
        "        return self._retry_timestamps.copy()\n",
        "\n",
        "    @property\n",
        "    def retry_exceptions(self) -> List[Exception]:\n",
        "        \"\"\"Exceptions from all retries including current.\"\"\"\n",
        "        return self._retry_exceptions.copy()\n",
        "\n",
        "    @property\n",
        "    def input_salvo(self) -> dict[str, list[Packet]]:\n",
        "        \"\"\"The input packets that triggered this epoch.\"\"\"\n",
        "        return self._input_salvo.copy()\n",
        "\n",
        "    @property\n",
        "    def packet_values(self) -> dict[str, Any]:\n",
        "        \"\"\"Values that were consumed during execution.\"\"\"\n",
        "        return self._packet_values.copy()\n",
        "\n",
        "    @property\n",
        "    def exception(self) -> Exception:\n",
        "        \"\"\"The exception that caused the failure.\"\"\"\n",
        "        return self._exception"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deferred Actions Commit/Discard\n",
        "\n",
        "Helper functions for committing or discarding deferred actions."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def _commit_deferred_actions(\n",
        "    net: \"Net\",\n",
        "    epoch_id: str,\n",
        "    queue: DeferredActionQueue,\n",
        ") -> dict[str, Packet]:\n",
        "    \"\"\"\n",
        "    Commit all deferred actions to NetSim.\n",
        "\n",
        "    Returns a mapping from deferred_id to real Packet.\n",
        "    \"\"\"\n",
        "    # Map from deferred_id to real packet\n",
        "    resolved_packets: dict[str, Packet] = {}\n",
        "\n",
        "    for action in queue.actions:\n",
        "        if action.action_type == DeferredActionType.CREATE_PACKET:\n",
        "            # Create the packet\n",
        "            net_action = NetAction.create_packet(epoch_id)\n",
        "            events = net._sim.do_action(net_action)\n",
        "\n",
        "            # Get the packet ID\n",
        "            packet_id = None\n",
        "            for event in events:\n",
        "                if hasattr(event, 'packet_id'):\n",
        "                    packet_id = event.packet_id\n",
        "                    break\n",
        "\n",
        "            if packet_id is None:\n",
        "                raise RuntimeError(\"Failed to get packet ID from create_packet action\")\n",
        "\n",
        "            # Store the value\n",
        "            net._value_store.store_value(packet_id, action.value)\n",
        "\n",
        "            # Resolve the deferred packet\n",
        "            real_packet = net._sim.get_packet(packet_id)\n",
        "            if action.deferred_packet is not None:\n",
        "                action.deferred_packet._resolve(real_packet)\n",
        "                resolved_packets[action.deferred_packet.deferred_id] = real_packet\n",
        "\n",
        "        elif action.action_type == DeferredActionType.CREATE_PACKET_FROM_FUNC:\n",
        "            # Create the packet\n",
        "            net_action = NetAction.create_packet(epoch_id)\n",
        "            events = net._sim.do_action(net_action)\n",
        "\n",
        "            # Get the packet ID\n",
        "            packet_id = None\n",
        "            for event in events:\n",
        "                if hasattr(event, 'packet_id'):\n",
        "                    packet_id = event.packet_id\n",
        "                    break\n",
        "\n",
        "            if packet_id is None:\n",
        "                raise RuntimeError(\"Failed to get packet ID from create_packet action\")\n",
        "\n",
        "            # Store the value function\n",
        "            net._value_store.store_value_func(packet_id, action.value_func)\n",
        "\n",
        "            # Resolve the deferred packet\n",
        "            real_packet = net._sim.get_packet(packet_id)\n",
        "            if action.deferred_packet is not None:\n",
        "                action.deferred_packet._resolve(real_packet)\n",
        "                resolved_packets[action.deferred_packet.deferred_id] = real_packet\n",
        "\n",
        "        elif action.action_type == DeferredActionType.CONSUME_PACKET:\n",
        "            # Consume was already done for value retrieval, just commit to NetSim\n",
        "            packet = action.packet\n",
        "            if isinstance(packet, DeferredPacket):\n",
        "                if not packet.is_resolved:\n",
        "                    raise RuntimeError(\"Trying to consume unresolved deferred packet on commit\")\n",
        "                packet_id = packet.id\n",
        "            else:\n",
        "                packet_id = packet.id\n",
        "\n",
        "            net_action = NetAction.consume_packet(packet_id)\n",
        "            net._sim.do_action(net_action)\n",
        "\n",
        "        elif action.action_type == DeferredActionType.LOAD_OUTPUT_PORT:\n",
        "            packet = action.packet\n",
        "            if isinstance(packet, DeferredPacket):\n",
        "                if not packet.is_resolved:\n",
        "                    raise RuntimeError(\"Trying to load unresolved deferred packet on commit\")\n",
        "                packet_id = packet.id\n",
        "            else:\n",
        "                packet_id = packet.id\n",
        "\n",
        "            net_action = NetAction.load_packet_into_output_port(packet_id, action.port_name)\n",
        "            net._sim.do_action(net_action)\n",
        "\n",
        "        elif action.action_type == DeferredActionType.SEND_OUTPUT_SALVO:\n",
        "            net_action = NetAction.send_output_salvo(epoch_id, action.salvo_condition_name)\n",
        "            net._sim.do_action(net_action)\n",
        "\n",
        "    return resolved_packets\n",
        "\n",
        "\n",
        "def _unconsume_packets_for_retry(\n",
        "    net: \"Net\",\n",
        "    consumed_values: dict[str, Any],\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Restore consumed packet values for retry.\n",
        "\n",
        "    Called when an epoch fails and will be retried.\n",
        "    \"\"\"\n",
        "    for packet_id, value in consumed_values.items():\n",
        "        net._value_store.unconsume(packet_id, value)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple graph for testing\n",
        "from netrun_sim import Node, Port, SalvoCondition, SalvoConditionTerm, PortState, MaxSalvos\n",
        "\n",
        "# Simple two-node graph: Source -> Sink\n",
        "source_node = Node(\n",
        "    name=\"Source\",\n",
        "    out_ports={\"out\": Port()},\n",
        "    out_salvo_conditions={\n",
        "        \"send\": SalvoCondition(\n",
        "            MaxSalvos.infinite(),\n",
        "            \"out\",\n",
        "            SalvoConditionTerm.port(\"out\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "sink_node = Node(\n",
        "    name=\"Sink\",\n",
        "    in_ports={\"in\": Port()},\n",
        "    in_salvo_conditions={\n",
        "        \"receive\": SalvoCondition(\n",
        "            MaxSalvos.finite(1),\n",
        "            \"in\",\n",
        "            SalvoConditionTerm.port(\"in\", PortState.non_empty())\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "edges = [\n",
        "    Edge(\n",
        "        PortRef(\"Source\", PortType.Output, \"out\"),\n",
        "        PortRef(\"Sink\", PortType.Input, \"in\")\n",
        "    )\n",
        "]\n",
        "\n",
        "graph = Graph([source_node, sink_node], edges)\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Net\n",
        "net = Net(\n",
        "    graph,\n",
        "    consumed_packet_storage=True,\n",
        "    consumed_packet_storage_limit=100,\n",
        ")\n",
        "\n",
        "# Define execution functions\n",
        "def source_exec(ctx, packets):\n",
        "    print(\"Source executing\")\n",
        "\n",
        "def sink_exec(ctx, packets):\n",
        "    print(\"Sink executing\")\n",
        "\n",
        "# Set execution functions\n",
        "net.set_node_exec(\"Source\", source_exec)\n",
        "net.set_node_exec(\"Sink\", sink_exec)\n",
        "\n",
        "# Set configuration\n",
        "net.set_node_config(\"Sink\", retries=3, defer_net_actions=True)\n",
        "\n",
        "print(f\"Source config: {net.get_node_config('Source')}\")\n",
        "print(f\"Sink config: {net.get_node_config('Sink')}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the value store\n",
        "store = PacketValueStore(consumed_storage=True, consumed_storage_limit=5)\n",
        "\n",
        "# Store direct values\n",
        "store.store_value(\"packet-1\", {\"data\": \"hello\"})\n",
        "store.store_value(\"packet-2\", [1, 2, 3])\n",
        "\n",
        "# Store a value function\n",
        "call_count = 0\n",
        "def lazy_value():\n",
        "    global call_count\n",
        "    call_count += 1\n",
        "    return f\"computed-{call_count}\"\n",
        "\n",
        "store.store_value_func(\"packet-3\", lazy_value)\n",
        "\n",
        "# Get values\n",
        "print(f\"packet-1: {store.get_value('packet-1')}\")\n",
        "print(f\"packet-3 (first call): {store.get_value('packet-3')}\")\n",
        "print(f\"packet-3 (second call): {store.get_value('packet-3')}\")  # Called again\n",
        "\n",
        "# Consume\n",
        "value = store.consume(\"packet-2\")\n",
        "print(f\"Consumed packet-2: {value}\")\n",
        "print(f\"packet-2 in consumed storage: {store.get_consumed_value('packet-2')}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Test error types\n",
        "try:\n",
        "    raise PacketTypeMismatch(\"pkt-123\", \"DataFrame\", \"dict\", \"input_port\")\n",
        "except PacketTypeMismatch as e:\n",
        "    print(f\"Caught: {e}\")\n",
        "\n",
        "try:\n",
        "    raise EpochCancelled(\"MyNode\", \"epoch-456\")\n",
        "except EpochCancelled as e:\n",
        "    print(f\"Caught: {e}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
