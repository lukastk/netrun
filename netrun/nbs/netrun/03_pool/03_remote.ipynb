{
  "cells": [
    {
      "cell_type": "code",
      "source": "#|default_exp pool.remote",
      "metadata": {},
      "id": "cell0",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|hide\nfrom nblite import nbl_export; nbl_export();",
      "metadata": {},
      "id": "cell1",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Remote Process Pool\n\nA pool of workers running on a remote server. The client connects via\nWebSocket and requests a pool with specific configuration. The server\ncreates a MultiprocessPool and routes messages.\n\n## Architecture\n\n```\nClient                          Server\n  \u2502                               \u2502\n  \u2502  \u2500\u2500 WebSocket \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502\n  \u2502                               \u2502\n  \u2502  send(worker_id, key, data)   \u2502   MultiprocessPool\n  \u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba   \u2502   \u251c\u2500\u2500 Process 0\n  \u2502                               \u2502   \u2502   \u251c\u2500\u2500 Thread 0\n  \u2502                               \u2502   \u2502   \u2514\u2500\u2500 Thread 1\n  \u2502  \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502   \u2514\u2500\u2500 Process 1\n  \u2502  recv() \u2192 WorkerMessage       \u2502       \u251c\u2500\u2500 Thread 2\n  \u2502                               \u2502       \u2514\u2500\u2500 Thread 3\n```\n\n## Usage\n\n### Server\n\n```python\nfrom netrun.pool.remote import RemotePoolServer\n\ndef my_worker(channel, worker_id):\n    while True:\n        key, data = channel.recv()\n        channel.send(\"result\", data * 2)\n\nserver = RemotePoolServer()\nserver.register_worker(\"my_worker\", my_worker)\nawait server.serve(\"0.0.0.0\", 8080)\n```\n\n### Client\n\n```python\nfrom netrun.pool.remote import RemotePoolClient\n\nasync with RemotePoolClient(\"ws://server:8080\") as client:\n    await client.create_pool(\n        worker_name=\"my_worker\",\n        num_processes=2,\n        threads_per_process=2,\n    )\n\n    await client.send(worker_id=0, key=\"task\", data=10)\n    msg = await client.recv()\n```",
      "metadata": {},
      "id": "cell2"
    },
    {
      "cell_type": "code",
      "source": "#|export\nimport asyncio\nfrom typing import Any\nfrom contextlib import asynccontextmanager\n\nfrom netrun.rpc.base import ChannelClosed, RecvTimeout\nfrom netrun.rpc.remote import (\n    WebSocketChannel,\n    serve_background,\n)\nfrom netrun.pool.base import (\n    WorkerId,\n    WorkerFn,\n    WorkerMessage,\n    PoolError,\n    PoolNotStarted,\n    WorkerException,\n    WorkerCrashed,\n)\nfrom netrun.pool.multiprocess import MultiprocessPool, OutputBuffer",
      "metadata": {},
      "id": "cell3",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## RemotePool Keys\n\nKeys for communication between client and server.\nDownstream: client \u2192 server, Upstream: server \u2192 client",
      "metadata": {},
      "id": "cell4"
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Downstream: client \u2192 server\nRP_DOWN_CREATE_POOL = \"__pool-rp-down:create_pool\"\n\"\"\"Client requests pool creation. Data: {worker_name, num_processes, threads_per_process}\"\"\"",
      "metadata": {},
      "id": "cell5",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Client requests pool creation. Data: {worker_name, num_processes, threads_per_process}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_DOWN_SEND = \"__pool-rp-down:send\"\n\"\"\"Client sends to worker. Data: {worker_id, key, data}\"\"\"",
      "metadata": {},
      "id": "cell6",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Client sends to worker. Data: {worker_id, key, data}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_DOWN_BROADCAST = \"__pool-rp-down:broadcast\"\n\"\"\"Client broadcasts to all. Data: {key, data}\"\"\"",
      "metadata": {},
      "id": "cell7",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Client broadcasts to all. Data: {key, data}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_DOWN_CLOSE = \"__pool-rp-down:close\"\n\"\"\"Client requests pool close.\"\"\"",
      "metadata": {},
      "id": "cell8",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Client requests pool close.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_DOWN_FLUSH_STDOUT = \"__pool-rp-down:flush_stdout\"\n\"\"\"Client requests stdout buffer from a process. Data: {process_idx}\"\"\"",
      "metadata": {},
      "id": "cell9",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Client requests stdout buffer from a process. Data: {process_idx}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_DOWN_FLUSH_ALL_STDOUT = \"__pool-rp-down:flush_all_stdout\"\n\"\"\"Client requests stdout buffers from all processes.\"\"\"",
      "metadata": {},
      "id": "cell10",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Client requests stdout buffers from all processes.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\n# Upstream: server \u2192 client\nRP_UP_POOL_CREATED = \"__pool-rp-up:pool_created\"\n\"\"\"Server confirms pool created. Data: {num_workers}\"\"\"",
      "metadata": {},
      "id": "cell11",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Server confirms pool created. Data: {num_workers}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_UP_RECV = \"__pool-rp-up:recv\"\n\"\"\"Server forwards worker response. Data: {worker_id, key, data}\"\"\"",
      "metadata": {},
      "id": "cell12",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Server forwards worker response. Data: {worker_id, key, data}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_UP_ERROR_EXCEPTION = \"__pool-rp-up:error-exception\"\n\"\"\"Server-side exception. Data: exception object or error dict.\"\"\"",
      "metadata": {},
      "id": "cell13",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Server-side exception. Data: exception object or error dict.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_UP_ERROR_POOL_FAILED = \"__pool-rp-up:error-pool_failed\"\n\"\"\"Server failed to create/manage pool. Data: error message.\"\"\"",
      "metadata": {},
      "id": "cell14",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Server failed to create/manage pool. Data: error message.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|export\nRP_UP_STDOUT_BUFFER = \"__pool-rp-up:stdout_buffer\"\n\"\"\"Server sends stdout buffer. Data: {process_idx, buffer} or {buffers}\"\"\"",
      "metadata": {},
      "id": "cell15",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "'Server sends stdout buffer. Data: {process_idx, buffer} or {buffers}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## RemotePoolServer",
      "metadata": {},
      "id": "cell16"
    },
    {
      "cell_type": "code",
      "source": "#|export\nclass RemotePoolServer:\n    \"\"\"Server that hosts remote worker pools.\n\n    Clients connect, request a pool configuration, and the server\n    creates a MultiprocessPool to handle their requests.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Create a remote pool server.\"\"\"\n        self._workers: dict[str, WorkerFn] = {}\n        self._running = False\n\n    def register_worker(self, name: str, worker_fn: WorkerFn) -> None:\n        \"\"\"Register a worker function by name.\n\n        Args:\n            name: Name clients will use to request this worker\n            worker_fn: The worker function (must be importable for multiprocessing)\n        \"\"\"\n        self._workers[name] = worker_fn\n\n    @property\n    def registered_workers(self) -> list[str]:\n        \"\"\"List of registered worker names.\"\"\"\n        return list(self._workers.keys())\n\n    async def serve(self, host: str = \"0.0.0.0\", port: int = 8080) -> None:\n        \"\"\"Start the server and handle connections.\n\n        This blocks until the server is stopped.\n\n        Args:\n            host: Host to bind to\n            port: Port to listen on\n        \"\"\"\n        from netrun.rpc.remote import serve\n\n        async def handle_client(channel: WebSocketChannel):\n            await self._handle_client(channel)\n\n        await serve(handle_client, host, port)\n\n    @asynccontextmanager\n    async def serve_background(self, host: str = \"0.0.0.0\", port: int = 8080):\n        \"\"\"Start the server in the background.\n\n        Args:\n            host: Host to bind to\n            port: Port to listen on\n\n        Yields:\n            The server object\n        \"\"\"\n        async def handle_client(channel: WebSocketChannel):\n            await self._handle_client(channel)\n\n        async with serve_background(handle_client, host, port) as server:\n            yield server\n\n    async def _handle_client(self, channel: WebSocketChannel) -> None:\n        \"\"\"Handle a single client connection.\"\"\"\n        pool: MultiprocessPool | None = None\n        forward_task: asyncio.Task | None = None\n\n        try:\n            while True:\n                key, data = await channel.recv()\n\n                if key == RP_DOWN_CREATE_POOL:\n                    # Create pool\n                    worker_name = data[\"worker_name\"]\n                    num_processes = data[\"num_processes\"]\n                    threads_per_process = data.get(\"threads_per_process\", 1)\n                    redirect_output = data.get(\"redirect_output\", True)\n                    buffer_output = data.get(\"buffer_output\", True)\n\n                    if worker_name not in self._workers:\n                        await channel.send(RP_UP_ERROR_POOL_FAILED, f\"Unknown worker: {worker_name}\")\n                        continue\n\n                    # Clean up existing pool and forward task if any\n                    if forward_task is not None:\n                        forward_task.cancel()\n                        try:\n                            await forward_task\n                        except asyncio.CancelledError:\n                            pass\n                        forward_task = None\n\n                    if pool is not None:\n                        await pool.close()\n\n                    pool = MultiprocessPool(\n                        worker_fn=self._workers[worker_name],\n                        num_processes=num_processes,\n                        threads_per_process=threads_per_process,\n                        redirect_output=redirect_output,\n                        buffer_output=buffer_output,\n                    )\n                    await pool.start()\n\n                    await channel.send(RP_UP_POOL_CREATED, {\n                        \"num_workers\": pool.num_workers,\n                        \"num_processes\": pool.num_processes,\n                        \"threads_per_process\": pool.threads_per_process,\n                        \"redirect_output\": redirect_output,\n                        \"buffer_output\": buffer_output,\n                    })\n\n                    # Start forwarding responses from pool to client\n                    forward_task = asyncio.create_task(self._forward_responses(pool, channel))\n\n                elif key == RP_DOWN_SEND:\n                    if pool is None:\n                        await channel.send(RP_UP_ERROR_POOL_FAILED, \"No pool created\")\n                        continue\n\n                    worker_id = data[\"worker_id\"]\n                    msg_key = data[\"key\"]\n                    msg_data = data[\"data\"]\n                    await pool.send(worker_id, msg_key, msg_data)\n\n                elif key == RP_DOWN_BROADCAST:\n                    if pool is None:\n                        await channel.send(RP_UP_ERROR_POOL_FAILED, \"No pool created\")\n                        continue\n\n                    msg_key = data[\"key\"]\n                    msg_data = data[\"data\"]\n                    await pool.broadcast(msg_key, msg_data)\n\n                elif key == RP_DOWN_FLUSH_STDOUT:\n                    if pool is None:\n                        await channel.send(RP_UP_ERROR_POOL_FAILED, \"No pool created\")\n                        continue\n\n                    process_idx = data[\"process_idx\"]\n                    buffer = await pool.flush_stdout(process_idx)\n                    # Convert datetime to ISO format for JSON serialization\n                    serializable_buffer = [\n                        (ts.isoformat(), is_stdout, text)\n                        for ts, is_stdout, text in buffer\n                    ]\n                    await channel.send(RP_UP_STDOUT_BUFFER, {\n                        \"process_idx\": process_idx,\n                        \"buffer\": serializable_buffer,\n                    })\n\n                elif key == RP_DOWN_FLUSH_ALL_STDOUT:\n                    if pool is None:\n                        await channel.send(RP_UP_ERROR_POOL_FAILED, \"No pool created\")\n                        continue\n\n                    buffers = await pool.flush_all_stdout()\n                    # Convert datetime to ISO format for JSON serialization\n                    serializable_buffers = {\n                        str(idx): [\n                            (ts.isoformat(), is_stdout, text)\n                            for ts, is_stdout, text in buffer\n                        ]\n                        for idx, buffer in buffers.items()\n                    }\n                    await channel.send(RP_UP_STDOUT_BUFFER, {\n                        \"buffers\": serializable_buffers,\n                    })\n\n                elif key == RP_DOWN_CLOSE:\n                    break\n\n        except ChannelClosed:\n            pass\n        finally:\n            # Cancel forward task first\n            if forward_task is not None:\n                forward_task.cancel()\n                try:\n                    await forward_task\n                except asyncio.CancelledError:\n                    pass\n\n            if pool is not None:\n                await pool.close()\n\n    async def _forward_responses(self, pool: MultiprocessPool, channel: WebSocketChannel) -> None:\n        \"\"\"Forward responses from pool workers to the client.\"\"\"\n        try:\n            while pool.is_running and not channel.is_closed:\n                try:\n                    # Use a timeout so we can periodically check if we should stop\n                    msg = await pool.recv(timeout=0.5)\n                    await channel.send(RP_UP_RECV, {\n                        \"worker_id\": msg.worker_id,\n                        \"key\": msg.key,\n                        \"data\": msg.data,\n                    })\n                except RecvTimeout:\n                    continue\n                except (WorkerException, WorkerCrashed) as e:\n                    # Forward worker errors to client\n                    if isinstance(e, WorkerException):\n                        error_data = {\n                            \"worker_id\": e.worker_id,\n                            \"type\": type(e.original_exception).__name__ if isinstance(e.original_exception, Exception) else e.original_exception.get(\"type\", \"Exception\"),\n                            \"message\": str(e.original_exception) if isinstance(e.original_exception, Exception) else e.original_exception.get(\"message\", \"\"),\n                        }\n                    else:\n                        error_data = {\n                            \"worker_id\": e.worker_id,\n                            \"type\": \"WorkerCrashed\",\n                            \"message\": str(e),\n                            \"details\": e.details,\n                        }\n                    await channel.send(RP_UP_ERROR_EXCEPTION, error_data)\n                except ChannelClosed:\n                    break\n        except asyncio.CancelledError:\n            raise  # Re-raise to properly signal cancellation\n        except Exception:\n            pass",
      "metadata": {},
      "id": "cell17",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## RemotePoolClient",
      "metadata": {},
      "id": "cell18"
    },
    {
      "cell_type": "code",
      "source": "#|export\nclass RemotePoolClient:\n    \"\"\"Client for connecting to a remote pool server.\n\n    Provides the same interface as local pools (send, recv, etc.)\n    but workers run on the remote server.\n    \"\"\"\n\n    def __init__(self, url: str):\n        \"\"\"Create a client.\n\n        Args:\n            url: WebSocket URL of the server (e.g., \"ws://server:8080\")\n        \"\"\"\n        self._url = url\n        self._channel: WebSocketChannel | None = None\n        self._num_workers = 0\n        self._num_processes = 0\n        self._threads_per_process = 0\n        self._redirect_output = True\n        self._buffer_output = True\n        self._running = False\n        self._recv_queue: asyncio.Queue = asyncio.Queue()\n        self._stdout_queue: asyncio.Queue = asyncio.Queue()\n        self._recv_task: asyncio.Task | None = None\n\n    @property\n    def num_workers(self) -> int:\n        \"\"\"Total number of workers in the remote pool.\"\"\"\n        return self._num_workers\n\n    @property\n    def num_processes(self) -> int:\n        \"\"\"Number of processes on the server.\"\"\"\n        return self._num_processes\n\n    @property\n    def threads_per_process(self) -> int:\n        \"\"\"Number of threads per process.\"\"\"\n        return self._threads_per_process\n\n    @property\n    def is_running(self) -> bool:\n        \"\"\"Whether the client is connected and pool is created.\"\"\"\n        return self._running\n\n    async def connect(self) -> None:\n        \"\"\"Connect to the server.\"\"\"\n        from netrun.rpc.remote import connect_channel\n        self._channel = await connect_channel(self._url)\n\n    async def create_pool(\n        self,\n        worker_name: str,\n        num_processes: int,\n        threads_per_process: int = 1,\n        redirect_output: bool = True,\n        buffer_output: bool = True,\n    ) -> None:\n        \"\"\"Create a pool on the server.\n\n        Args:\n            worker_name: Name of registered worker function on server\n            num_processes: Number of processes\n            threads_per_process: Threads per process\n            redirect_output: If True, redirect subprocess stdout/stderr\n            buffer_output: If True, buffer redirected output (if redirect_output is True)\n        \"\"\"\n        if self._channel is None:\n            raise PoolNotStarted(\"Not connected to server\")\n\n        await self._channel.send(RP_DOWN_CREATE_POOL, {\n            \"worker_name\": worker_name,\n            \"num_processes\": num_processes,\n            \"threads_per_process\": threads_per_process,\n            \"redirect_output\": redirect_output,\n            \"buffer_output\": buffer_output,\n        })\n\n        # Wait for response\n        key, data = await self._channel.recv(timeout=None)\n\n        if key == RP_UP_ERROR_POOL_FAILED:\n            raise PoolError(f\"Server error: {data}\")\n\n        if key != RP_UP_POOL_CREATED:\n            raise PoolError(f\"Unexpected response: {key}\")\n\n        self._num_workers = data[\"num_workers\"]\n        self._num_processes = data[\"num_processes\"]\n        self._threads_per_process = data[\"threads_per_process\"]\n        self._redirect_output = data.get(\"redirect_output\", True)\n        self._buffer_output = data.get(\"buffer_output\", True)\n        self._running = True\n\n        # Start receiving messages from server\n        self._recv_task = asyncio.create_task(self._receive_loop())\n\n    async def _receive_loop(self) -> None:\n        \"\"\"Receive messages from server and queue them.\"\"\"\n        try:\n            while self._running and self._channel and not self._channel.is_closed:\n                try:\n                    key, data = await self._channel.recv(timeout=None)\n                    if key == RP_UP_RECV:\n                        await self._recv_queue.put((\"msg\", data))\n                    elif key == RP_UP_ERROR_EXCEPTION:\n                        # Queue error so it can be raised in recv()\n                        await self._recv_queue.put((\"error\", data))\n                    elif key == RP_UP_ERROR_POOL_FAILED:\n                        # Queue pool failure error\n                        await self._recv_queue.put((\"pool_error\", data))\n                    elif key == RP_UP_STDOUT_BUFFER:\n                        # Queue stdout buffer for flush methods\n                        await self._stdout_queue.put(data)\n                except ChannelClosed:\n                    break\n        except Exception:\n            pass\n\n    async def close(self, timeout: float | None = None) -> None:\n        \"\"\"Close the connection and remote pool.\n\n        Args:\n            timeout: Not used for RemotePoolClient (included for protocol compatibility).\n        \"\"\"\n        self._running = False\n\n        if self._recv_task and not self._recv_task.done():\n            self._recv_task.cancel()\n            try:\n                await self._recv_task\n            except asyncio.CancelledError:\n                pass\n\n        if self._channel and not self._channel.is_closed:\n            try:\n                await self._channel.send(RP_DOWN_CLOSE, None)\n            except Exception:\n                pass\n            await self._channel.close()\n\n        self._channel = None\n\n    async def send(self, worker_id: WorkerId, key: str, data: Any) -> None:\n        \"\"\"Send a message to a specific worker on the server.\"\"\"\n        if not self._running or self._channel is None:\n            raise PoolNotStarted(\"Pool not created\")\n\n        if worker_id < 0 or worker_id >= self._num_workers:\n            raise ValueError(f\"worker_id {worker_id} out of range [0, {self._num_workers})\")\n\n        await self._channel.send(RP_DOWN_SEND, {\n            \"worker_id\": worker_id,\n            \"key\": key,\n            \"data\": data,\n        })\n\n    async def recv(self, timeout: float | None = None) -> WorkerMessage:\n        \"\"\"Receive a message from any worker.\n\n        Raises:\n            WorkerException: If the worker raised an exception\n            WorkerCrashed: If the worker died unexpectedly\n            PoolError: If the server reported a pool error\n            RecvTimeout: If this recv() call times out\n        \"\"\"\n        if not self._running:\n            raise PoolNotStarted(\"Pool not created\")\n\n        try:\n            if timeout is None:\n                item = await self._recv_queue.get()\n            else:\n                item = await asyncio.wait_for(\n                    self._recv_queue.get(),\n                    timeout=timeout,\n                )\n        except TimeoutError:\n            raise RecvTimeout(f\"Receive timed out after {timeout}s\")\n\n        msg_type, data = item\n        if msg_type == \"error\":\n            # Raise WorkerException or WorkerCrashed based on error type\n            worker_id = data.get(\"worker_id\", -1)\n            if data.get(\"type\") == \"WorkerCrashed\":\n                raise WorkerCrashed(worker_id, data.get(\"details\", {\"reason\": data.get(\"message\", \"unknown\")}))\n            else:\n                raise WorkerException(worker_id, data)\n        elif msg_type == \"pool_error\":\n            raise PoolError(f\"Server error: {data}\")\n\n        return WorkerMessage(\n            worker_id=data[\"worker_id\"],\n            key=data[\"key\"],\n            data=data[\"data\"],\n        )\n\n    async def try_recv(self) -> WorkerMessage | None:\n        \"\"\"Non-blocking receive from any worker.\n\n        Raises:\n            WorkerException: If the worker raised an exception\n            WorkerCrashed: If the worker died unexpectedly\n            PoolError: If the server reported a pool error\n        \"\"\"\n        if not self._running:\n            raise PoolNotStarted(\"Pool not created\")\n\n        try:\n            item = self._recv_queue.get_nowait()\n        except asyncio.QueueEmpty:\n            return None\n\n        msg_type, data = item\n        if msg_type == \"error\":\n            worker_id = data.get(\"worker_id\", -1)\n            if data.get(\"type\") == \"WorkerCrashed\":\n                raise WorkerCrashed(worker_id, data.get(\"details\", {\"reason\": data.get(\"message\", \"unknown\")}))\n            else:\n                raise WorkerException(worker_id, data)\n        elif msg_type == \"pool_error\":\n            raise PoolError(f\"Server error: {data}\")\n\n        return WorkerMessage(\n            worker_id=data[\"worker_id\"],\n            key=data[\"key\"],\n            data=data[\"data\"],\n        )\n\n    async def broadcast(self, key: str, data: Any) -> None:\n        \"\"\"Send a message to all workers.\"\"\"\n        if not self._running or self._channel is None:\n            raise PoolNotStarted(\"Pool not created\")\n\n        await self._channel.send(RP_DOWN_BROADCAST, {\n            \"key\": key,\n            \"data\": data,\n        })\n\n    async def flush_stdout(self, process_idx: int, timeout: float = 5.0) -> OutputBuffer:\n        \"\"\"Flush and return the stdout buffer from a specific subprocess.\n\n        Args:\n            process_idx: Index of the subprocess (0 to num_processes-1)\n            timeout: Timeout in seconds for waiting for the response\n\n        Returns:\n            List of (timestamp, is_stdout, text) tuples. is_stdout is True for\n            stdout, False for stderr.\n\n        Raises:\n            PoolNotStarted: If the pool is not running\n            ValueError: If process_idx is out of range\n        \"\"\"\n        if not self._running or self._channel is None:\n            raise PoolNotStarted(\"Pool not created\")\n\n        if process_idx < 0 or process_idx >= self._num_processes:\n            raise ValueError(f\"process_idx {process_idx} out of range [0, {self._num_processes})\")\n\n        await self._channel.send(RP_DOWN_FLUSH_STDOUT, {\"process_idx\": process_idx})\n\n        # Wait for response\n        import datetime\n        try:\n            data = await asyncio.wait_for(self._stdout_queue.get(), timeout=timeout)\n        except TimeoutError:\n            raise RecvTimeout(f\"Flush stdout timed out after {timeout}s\")\n\n        # Convert ISO format back to datetime\n        buffer: OutputBuffer = [\n            (datetime.datetime.fromisoformat(ts), is_stdout, text)\n            for ts, is_stdout, text in data[\"buffer\"]\n        ]\n        return buffer\n\n    async def flush_all_stdout(self, timeout: float = 5.0) -> dict[int, OutputBuffer]:\n        \"\"\"Flush and return stdout buffers from all subprocesses.\n\n        Args:\n            timeout: Timeout in seconds for waiting for the response\n\n        Returns:\n            Dict mapping process index to list of (timestamp, is_stdout, text) tuples.\n\n        Raises:\n            PoolNotStarted: If the pool is not running\n        \"\"\"\n        if not self._running or self._channel is None:\n            raise PoolNotStarted(\"Pool not created\")\n\n        await self._channel.send(RP_DOWN_FLUSH_ALL_STDOUT, {})\n\n        # Wait for response\n        import datetime\n        try:\n            data = await asyncio.wait_for(self._stdout_queue.get(), timeout=timeout)\n        except TimeoutError:\n            raise RecvTimeout(f\"Flush all stdout timed out after {timeout}s\")\n\n        # Convert ISO format back to datetime\n        result: dict[int, OutputBuffer] = {}\n        for idx_str, buffer in data[\"buffers\"].items():\n            result[int(idx_str)] = [\n                (datetime.datetime.fromisoformat(ts), is_stdout, text)\n                for ts, is_stdout, text in buffer\n            ]\n        return result\n\n    async def __aenter__(self) -> \"RemotePoolClient\":\n        \"\"\"Context manager entry - connects to server.\"\"\"\n        await self.connect()\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:\n        \"\"\"Context manager exit - closes connection.\"\"\"\n        await self.close()",
      "metadata": {},
      "id": "cell19",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Example\n\nDemonstrates a server and client communicating.",
      "metadata": {},
      "id": "cell20"
    },
    {
      "cell_type": "code",
      "source": "import tempfile\nimport sys\nfrom pathlib import Path\n\n# Create temp module with worker function\n_temp_dir = tempfile.mkdtemp(prefix=\"remote_pool_example_\")\n_worker_code = '''\n\"\"\"Worker for remote pool example.\"\"\"\nfrom netrun.rpc.base import ChannelClosed\n\ndef remote_echo_worker(channel, worker_id):\n    \"\"\"Echo worker for remote pool.\"\"\"\n    import os\n    print(f\"[Remote Worker {worker_id}] Started in process {os.getpid()}\")\n    try:\n        while True:\n            key, data = channel.recv()\n            print(f\"[Remote Worker {worker_id}] Received: {key}={data}\")\n            channel.send(f\"echo:{key}\", {\"worker_id\": worker_id, \"data\": data})\n    except ChannelClosed:\n        print(f\"[Remote Worker {worker_id}] Stopping\")\n'''\n\n_worker_path = Path(_temp_dir) / \"remote_workers.py\"\n_worker_path.write_text(_worker_code)\nprint(f\"Created worker module at: {_worker_path}\")\n\nif _temp_dir not in sys.path:\n    sys.path.insert(0, _temp_dir)",
      "metadata": {},
      "id": "cell21",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created worker module at: /var/folders/gc/wx3wyw4538vdtn_n2dyjn80m0000gn/T/remote_pool_example_iuix2pl6/remote_workers.py\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from remote_workers import remote_echo_worker\n# Import from installed module to avoid pickling issues with __main__\nfrom netrun.pool.remote import RemotePoolServer as _RemotePoolServer\nfrom netrun.pool.remote import RemotePoolClient as _RemotePoolClient\n\nasync def example_remote_pool():\n    \"\"\"Example: remote pool server and client.\"\"\"\n    print(\"=\" * 50)\n    print(\"Example: Remote Pool\")\n    print(\"=\" * 50)\n\n    # Create server\n    server = _RemotePoolServer()\n    server.register_worker(\"echo\", remote_echo_worker)\n\n    async with server.serve_background(\"127.0.0.1\", 19999):\n        print(\"[Main] Server started\")\n\n        # Connect client\n        async with _RemotePoolClient(\"ws://127.0.0.1:19999\") as client:\n            print(\"[Main] Client connected\")\n\n            # Create pool\n            await client.create_pool(\n                worker_name=\"echo\",\n                num_processes=2,\n                threads_per_process=2,\n            )\n            print(f\"[Main] Pool created with {client.num_workers} workers\")\n\n            # Send to each worker\n            for worker_id in range(client.num_workers):\n                await client.send(worker_id, \"hello\", f\"message-{worker_id}\")\n\n            # Receive responses\n            for _ in range(client.num_workers):\n                msg = await client.recv(timeout=10.0)\n                print(f\"[Main] Got from worker {msg.worker_id}: {msg.key}={msg.data}\")\n\n    print(\"Done!\\n\")\n\nawait example_remote_pool()",
      "metadata": {},
      "id": "cell22",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Example: Remote Pool\n",
            "==================================================\n",
            "[Main] Server started\n",
            "[Main] Client connected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Main] Pool created with 4 workers\n",
            "[Main] Got from worker 0: echo:hello={'worker_id': 0, 'data': 'message-0'}\n",
            "[Main] Got from worker 1: echo:hello={'worker_id': 1, 'data': 'message-1'}\n",
            "[Main] Got from worker 2: echo:hello={'worker_id': 2, 'data': 'message-2'}\n",
            "[Main] Got from worker 3: echo:hello={'worker_id': 3, 'data': 'message-3'}\n",
            "Done!\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Clean up\nimport shutil\nshutil.rmtree(_temp_dir, ignore_errors=True)\nprint(f\"Cleaned up: {_temp_dir}\")",
      "metadata": {},
      "id": "cell23",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned up: /var/folders/gc/wx3wyw4538vdtn_n2dyjn80m0000gn/T/remote_pool_example_iuix2pl6\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "nblite_source_hash": "44a4dc51823d386d6a43525f05a2db621d5e0c9db4af3164cce53a91ec75c007"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
