{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DSL Format\n",
        "\n",
        "TOML-based serialization for netrun Nets.\n",
        "\n",
        "This module provides:\n",
        "- Salvo condition expression parser\n",
        "- TOML serialization and deserialization\n",
        "- Helper functions for import path resolution"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|default_exp dsl"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|hide\n",
        "from nblite import nbl_export, show_doc; nbl_export();"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "import re\n",
        "import importlib\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import tomllib\n",
        "except ImportError:\n",
        "    import tomli as tomllib\n",
        "\n",
        "import tomlkit\n",
        "\n",
        "from netrun_sim import (\n",
        "    Graph, Node, Edge, Port, PortType, PortRef,\n",
        "    PortSlotSpec, PortState, PacketCount,\n",
        "    MaxSalvos, SalvoCondition, SalvoConditionTerm,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvo Condition Expression Parser\n",
        "\n",
        "Parses expressions like `nonempty(port)` and `count(port) >= 5` into `SalvoConditionTerm` objects."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "class ExpressionParseError(Exception):\n",
        "    \"\"\"Error parsing a salvo condition expression.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Token:\n",
        "    \"\"\"A token from the expression lexer.\"\"\"\n",
        "    type: str\n",
        "    value: str\n",
        "    position: int\n",
        "\n",
        "\n",
        "class ExpressionLexer:\n",
        "    \"\"\"Lexer for salvo condition expressions.\"\"\"\n",
        "\n",
        "    # Token patterns\n",
        "    PATTERNS = [\n",
        "        (r'\\s+', None),  # Whitespace (skip)\n",
        "        (r'nonempty', 'NONEMPTY'),\n",
        "        (r'empty', 'EMPTY'),\n",
        "        (r'full', 'FULL'),\n",
        "        (r'count', 'COUNT'),\n",
        "        (r'and', 'AND'),\n",
        "        (r'or', 'OR'),\n",
        "        (r'not', 'NOT'),\n",
        "        (r'>=', 'GTE'),\n",
        "        (r'<=', 'LTE'),\n",
        "        (r'==', 'EQ'),\n",
        "        (r'!=', 'NEQ'),\n",
        "        (r'>', 'GT'),\n",
        "        (r'<', 'LT'),\n",
        "        (r'\\(', 'LPAREN'),\n",
        "        (r'\\)', 'RPAREN'),\n",
        "        (r'\\d+', 'NUMBER'),\n",
        "        (r'[a-zA-Z_][a-zA-Z0-9_]*', 'IDENT'),\n",
        "    ]\n",
        "\n",
        "    def __init__(self, text: str):\n",
        "        self.text = text\n",
        "        self.pos = 0\n",
        "        self.tokens: List[Token] = []\n",
        "\n",
        "    def tokenize(self) -> List[Token]:\n",
        "        \"\"\"Tokenize the input text.\"\"\"\n",
        "        while self.pos < len(self.text):\n",
        "            match = None\n",
        "            for pattern, token_type in self.PATTERNS:\n",
        "                regex = re.compile(pattern)\n",
        "                match = regex.match(self.text, self.pos)\n",
        "                if match:\n",
        "                    if token_type is not None:\n",
        "                        self.tokens.append(Token(token_type, match.group(), self.pos))\n",
        "                    self.pos = match.end()\n",
        "                    break\n",
        "\n",
        "            if not match:\n",
        "                raise ExpressionParseError(\n",
        "                    f\"Unexpected character at position {self.pos}: '{self.text[self.pos]}'\"\n",
        "                )\n",
        "\n",
        "        return self.tokens\n",
        "\n",
        "\n",
        "class ExpressionParser:\n",
        "    \"\"\"\n",
        "    Parser for salvo condition expressions.\n",
        "\n",
        "    Grammar:\n",
        "        expr     -> or_expr\n",
        "        or_expr  -> and_expr ('or' and_expr)*\n",
        "        and_expr -> not_expr ('and' not_expr)*\n",
        "        not_expr -> 'not' not_expr | primary\n",
        "        primary  -> func_call | '(' expr ')'\n",
        "        func_call -> ('nonempty' | 'empty' | 'full') '(' IDENT ')'\n",
        "                   | 'count' '(' IDENT ')' comparison NUMBER\n",
        "        comparison -> '>=' | '<=' | '==' | '!=' | '>' | '<'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tokens: List[Token]):\n",
        "        self.tokens = tokens\n",
        "        self.pos = 0\n",
        "\n",
        "    def parse(self) -> SalvoConditionTerm:\n",
        "        \"\"\"Parse the tokens into a SalvoConditionTerm.\"\"\"\n",
        "        if not self.tokens:\n",
        "            raise ExpressionParseError(\"Empty expression\")\n",
        "        result = self._parse_or_expr()\n",
        "        if self.pos < len(self.tokens):\n",
        "            raise ExpressionParseError(\n",
        "                f\"Unexpected token: {self.tokens[self.pos].value}\"\n",
        "            )\n",
        "        return result\n",
        "\n",
        "    def _current_token(self) -> Optional[Token]:\n",
        "        if self.pos < len(self.tokens):\n",
        "            return self.tokens[self.pos]\n",
        "        return None\n",
        "\n",
        "    def _consume(self, expected_type: str) -> Token:\n",
        "        token = self._current_token()\n",
        "        if token is None:\n",
        "            raise ExpressionParseError(f\"Expected {expected_type}, got end of input\")\n",
        "        if token.type != expected_type:\n",
        "            raise ExpressionParseError(\n",
        "                f\"Expected {expected_type}, got {token.type} at position {token.position}\"\n",
        "            )\n",
        "        self.pos += 1\n",
        "        return token\n",
        "\n",
        "    def _match(self, *types: str) -> bool:\n",
        "        token = self._current_token()\n",
        "        return token is not None and token.type in types\n",
        "\n",
        "    def _parse_or_expr(self) -> SalvoConditionTerm:\n",
        "        left = self._parse_and_expr()\n",
        "        while self._match('OR'):\n",
        "            self.pos += 1  # consume 'or'\n",
        "            right = self._parse_and_expr()\n",
        "            left = SalvoConditionTerm.or_([left, right])\n",
        "        return left\n",
        "\n",
        "    def _parse_and_expr(self) -> SalvoConditionTerm:\n",
        "        left = self._parse_not_expr()\n",
        "        while self._match('AND'):\n",
        "            self.pos += 1  # consume 'and'\n",
        "            right = self._parse_not_expr()\n",
        "            left = SalvoConditionTerm.and_([left, right])\n",
        "        return left\n",
        "\n",
        "    def _parse_not_expr(self) -> SalvoConditionTerm:\n",
        "        if self._match('NOT'):\n",
        "            self.pos += 1  # consume 'not'\n",
        "            expr = self._parse_not_expr()\n",
        "            return SalvoConditionTerm.not_(expr)\n",
        "        return self._parse_primary()\n",
        "\n",
        "    def _parse_primary(self) -> SalvoConditionTerm:\n",
        "        token = self._current_token()\n",
        "        if token is None:\n",
        "            raise ExpressionParseError(\"Unexpected end of expression\")\n",
        "\n",
        "        if token.type == 'LPAREN':\n",
        "            self.pos += 1  # consume '('\n",
        "            expr = self._parse_or_expr()\n",
        "            self._consume('RPAREN')\n",
        "            return expr\n",
        "\n",
        "        if token.type in ('NONEMPTY', 'EMPTY', 'FULL'):\n",
        "            return self._parse_simple_func()\n",
        "\n",
        "        if token.type == 'COUNT':\n",
        "            return self._parse_count_func()\n",
        "\n",
        "        raise ExpressionParseError(\n",
        "            f\"Unexpected token: {token.value} at position {token.position}\"\n",
        "        )\n",
        "\n",
        "    def _parse_simple_func(self) -> SalvoConditionTerm:\n",
        "        \"\"\"Parse nonempty(port), empty(port), full(port).\"\"\"\n",
        "        func_token = self._current_token()\n",
        "        self.pos += 1  # consume function name\n",
        "        self._consume('LPAREN')\n",
        "        port_token = self._consume('IDENT')\n",
        "        self._consume('RPAREN')\n",
        "\n",
        "        port_name = port_token.value\n",
        "\n",
        "        if func_token.type == 'NONEMPTY':\n",
        "            return SalvoConditionTerm.port(port_name, PortState.non_empty())\n",
        "        elif func_token.type == 'EMPTY':\n",
        "            return SalvoConditionTerm.port(port_name, PortState.empty())\n",
        "        elif func_token.type == 'FULL':\n",
        "            return SalvoConditionTerm.port(port_name, PortState.full())\n",
        "        else:\n",
        "            raise ExpressionParseError(f\"Unknown function: {func_token.value}\")\n",
        "\n",
        "    def _parse_count_func(self) -> SalvoConditionTerm:\n",
        "        \"\"\"Parse count(port) >= N style expressions.\"\"\"\n",
        "        self.pos += 1  # consume 'count'\n",
        "        self._consume('LPAREN')\n",
        "        port_token = self._consume('IDENT')\n",
        "        self._consume('RPAREN')\n",
        "\n",
        "        port_name = port_token.value\n",
        "\n",
        "        # Parse comparison operator\n",
        "        op_token = self._current_token()\n",
        "        if op_token is None or op_token.type not in ('GTE', 'LTE', 'EQ', 'NEQ', 'GT', 'LT'):\n",
        "            raise ExpressionParseError(\"Expected comparison operator after count()\")\n",
        "        self.pos += 1\n",
        "\n",
        "        # Parse number\n",
        "        num_token = self._consume('NUMBER')\n",
        "        count = int(num_token.value)\n",
        "\n",
        "        # Create the appropriate PortState\n",
        "        if op_token.type == 'GTE':\n",
        "            state = PortState.equals_or_greater_than(count)\n",
        "        elif op_token.type == 'LTE':\n",
        "            state = PortState.equals_or_less_than(count)\n",
        "        elif op_token.type == 'EQ':\n",
        "            state = PortState.equals(count)\n",
        "        elif op_token.type == 'GT':\n",
        "            state = PortState.greater_than(count)\n",
        "        elif op_token.type == 'LT':\n",
        "            state = PortState.less_than(count)\n",
        "        elif op_token.type == 'NEQ':\n",
        "            # not equal is tricky - use not(equals(n))\n",
        "            return SalvoConditionTerm.not_(\n",
        "                SalvoConditionTerm.port(port_name, PortState.equals(count))\n",
        "            )\n",
        "        else:\n",
        "            raise ExpressionParseError(f\"Unknown comparison: {op_token.type}\")\n",
        "\n",
        "        return SalvoConditionTerm.port(port_name, state)\n",
        "\n",
        "\n",
        "def parse_salvo_condition_expr(expr: str) -> SalvoConditionTerm:\n",
        "    \"\"\"\n",
        "    Parse a salvo condition expression into a SalvoConditionTerm.\n",
        "\n",
        "    Examples:\n",
        "        \"nonempty(in)\" -> SalvoConditionTerm.port(\"in\", PortState.non_empty())\n",
        "        \"count(in) >= 5\" -> SalvoConditionTerm.port(\"in\", PortState.at_least(5))\n",
        "        \"nonempty(a) and nonempty(b)\" -> SalvoConditionTerm.and_term(...)\n",
        "\n",
        "    Args:\n",
        "        expr: The expression string\n",
        "\n",
        "    Returns:\n",
        "        A SalvoConditionTerm representing the expression\n",
        "\n",
        "    Raises:\n",
        "        ExpressionParseError: If the expression is invalid\n",
        "    \"\"\"\n",
        "    lexer = ExpressionLexer(expr)\n",
        "    tokens = lexer.tokenize()\n",
        "    parser = ExpressionParser(tokens)\n",
        "    return parser.parse()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOML Serialization Helpers"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def resolve_import_path(path: str) -> Any:\n",
        "    \"\"\"\n",
        "    Resolve a dotted import path to an object.\n",
        "\n",
        "    Example: \"my_module.my_func\" -> my_func\n",
        "\n",
        "    Args:\n",
        "        path: Dotted import path like \"module.submodule.object\"\n",
        "\n",
        "    Returns:\n",
        "        The resolved object\n",
        "\n",
        "    Raises:\n",
        "        ImportError: If the module or object cannot be found\n",
        "    \"\"\"\n",
        "    parts = path.rsplit('.', 1)\n",
        "    if len(parts) == 1:\n",
        "        # Just a module name\n",
        "        return importlib.import_module(parts[0])\n",
        "    module_path, obj_name = parts\n",
        "    module = importlib.import_module(module_path)\n",
        "    return getattr(module, obj_name)\n",
        "\n",
        "\n",
        "def get_import_path(obj: Any) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Get the import path for an object.\n",
        "\n",
        "    Args:\n",
        "        obj: Any Python object (function, class, etc.)\n",
        "\n",
        "    Returns:\n",
        "        Import path like \"module.submodule.object\" or None if not resolvable\n",
        "    \"\"\"\n",
        "    if hasattr(obj, '__module__') and hasattr(obj, '__name__'):\n",
        "        return f\"{obj.__module__}.{obj.__name__}\"\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Port State Serialization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def port_state_to_expr(state) -> str:\n",
        "    \"\"\"Convert a PortState to an expression string fragment.\n",
        "\n",
        "    Args:\n",
        "        state: Either PortState enum (Empty, Full, NonEmpty, NonFull) or\n",
        "               PortStateNumeric (equals, less_than, etc.)\n",
        "\n",
        "    Returns:\n",
        "        String representation suitable for TOML 'when' expressions\n",
        "    \"\"\"\n",
        "    # Check if it's a PortStateNumeric by class name\n",
        "    if type(state).__name__ == \"PortStateNumeric\":\n",
        "        kind = state.kind\n",
        "        value = state.value\n",
        "        if kind == \"equals\":\n",
        "            return f\"=={value}\"\n",
        "        elif kind == \"less_than\":\n",
        "            return f\"<{value}\"\n",
        "        elif kind == \"greater_than\":\n",
        "            return f\">{value}\"\n",
        "        elif kind == \"equals_or_less_than\":\n",
        "            return f\"<={value}\"\n",
        "        elif kind == \"equals_or_greater_than\":\n",
        "            return f\">={value}\"\n",
        "        else:\n",
        "            return \"nonempty\"\n",
        "\n",
        "    # It's a PortState enum\n",
        "    if state == PortState.Empty:\n",
        "        return \"empty\"\n",
        "    elif state == PortState.Full:\n",
        "        return \"full\"\n",
        "    elif state == PortState.NonEmpty:\n",
        "        return \"nonempty\"\n",
        "    elif state == PortState.NonFull:\n",
        "        return \"nonfull\"\n",
        "    else:\n",
        "        return \"nonempty\"\n",
        "\n",
        "\n",
        "def salvo_term_to_expr(term: SalvoConditionTerm) -> str:\n",
        "    \"\"\"\n",
        "    Convert a SalvoConditionTerm back to an expression string.\n",
        "\n",
        "    Args:\n",
        "        term: The SalvoConditionTerm to convert\n",
        "\n",
        "    Returns:\n",
        "        Expression string suitable for TOML 'when' field\n",
        "    \"\"\"\n",
        "    kind = term.kind\n",
        "\n",
        "    if kind == \"Port\":\n",
        "        port_name = term.get_port_name()\n",
        "        state = term.get_port_state()\n",
        "        state_expr = port_state_to_expr(state)\n",
        "        return f\"{state_expr}({port_name})\"\n",
        "\n",
        "    elif kind == \"And\":\n",
        "        sub_terms = term.get_terms()\n",
        "        sub_exprs = [salvo_term_to_expr(t) for t in sub_terms]\n",
        "        return \" and \".join(sub_exprs)\n",
        "\n",
        "    elif kind == \"Or\":\n",
        "        sub_terms = term.get_terms()\n",
        "        sub_exprs = [salvo_term_to_expr(t) for t in sub_terms]\n",
        "        return \" or \".join(f\"({e})\" for e in sub_exprs)\n",
        "\n",
        "    elif kind == \"Not\":\n",
        "        inner = term.get_inner()\n",
        "        inner_expr = salvo_term_to_expr(inner)\n",
        "        return f\"not({inner_expr})\"\n",
        "\n",
        "    else:\n",
        "        return \"nonempty(port)\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions for Serialization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def _is_port_slots_finite(slots_spec) -> bool:\n",
        "    \"\"\"Check if a PortSlotSpec is finite.\n",
        "\n",
        "    Args:\n",
        "        slots_spec: Either PortSlotSpec.Infinite or PortSlotSpecFinite\n",
        "\n",
        "    Returns:\n",
        "        True if finite, False if infinite\n",
        "    \"\"\"\n",
        "    # Check class name to avoid confusion with similarly named attributes\n",
        "    return type(slots_spec).__name__ == \"PortSlotSpecFinite\"\n",
        "\n",
        "\n",
        "def _get_port_slots_count(slots_spec) -> int:\n",
        "    \"\"\"Extract the count from a finite PortSlotSpec.\n",
        "\n",
        "    Args:\n",
        "        slots_spec: A PortSlotSpecFinite instance\n",
        "\n",
        "    Returns:\n",
        "        The capacity value\n",
        "    \"\"\"\n",
        "    if type(slots_spec).__name__ == \"PortSlotSpecFinite\":\n",
        "        return slots_spec.capacity\n",
        "    raise ValueError(f\"Cannot extract count from non-finite PortSlotSpec: {slots_spec}\")\n",
        "\n",
        "\n",
        "def _is_max_salvos_infinite(max_salvos) -> bool:\n",
        "    \"\"\"Check if a MaxSalvos is infinite.\n",
        "\n",
        "    Args:\n",
        "        max_salvos: Either MaxSalvos.Infinite or MaxSalvosFinite\n",
        "\n",
        "    Returns:\n",
        "        True if infinite, False if finite\n",
        "    \"\"\"\n",
        "    # Check class name to avoid confusion with similarly named attributes\n",
        "    return type(max_salvos).__name__ != \"MaxSalvosFinite\"\n",
        "\n",
        "\n",
        "def _get_max_salvos_count(max_salvos) -> int:\n",
        "    \"\"\"Extract the count from a finite MaxSalvos.\n",
        "\n",
        "    Args:\n",
        "        max_salvos: A MaxSalvosFinite instance\n",
        "\n",
        "    Returns:\n",
        "        The max value\n",
        "    \"\"\"\n",
        "    if type(max_salvos).__name__ == \"MaxSalvosFinite\":\n",
        "        return max_salvos.max\n",
        "    raise ValueError(f\"Cannot extract count from non-finite MaxSalvos: {max_salvos}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Serialization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def port_to_dict(port: Port) -> Dict[str, Any]:\n",
        "    \"\"\"Convert a Port to a dictionary for TOML serialization.\"\"\"\n",
        "    result = {}\n",
        "    slots = port.slots_spec\n",
        "    if _is_port_slots_finite(slots):\n",
        "        result[\"slots\"] = _get_port_slots_count(slots)\n",
        "    # If infinite, we don't include slots (it's the default)\n",
        "    return result\n",
        "\n",
        "\n",
        "def dict_to_port(data: Union[Dict, None]) -> Port:\n",
        "    \"\"\"Convert a dictionary to a Port.\"\"\"\n",
        "    if data is None or not data:\n",
        "        return Port()  # Default port\n",
        "\n",
        "    slots = data.get(\"slots\")\n",
        "    if slots is not None:\n",
        "        return Port(PortSlotSpec.finite(slots))\n",
        "    return Port()\n",
        "\n",
        "\n",
        "def node_to_dict(node: Node) -> Dict[str, Any]:\n",
        "    \"\"\"Convert a Node to a dictionary for TOML serialization.\"\"\"\n",
        "    result = {\"name\": node.name}\n",
        "\n",
        "    # Input ports\n",
        "    if node.in_ports:\n",
        "        in_ports = {}\n",
        "        for name, port in node.in_ports.items():\n",
        "            port_dict = port_to_dict(port)\n",
        "            if port_dict:\n",
        "                in_ports[name] = port_dict\n",
        "            else:\n",
        "                in_ports[name] = {}\n",
        "        if in_ports:\n",
        "            result[\"in_ports\"] = in_ports\n",
        "\n",
        "    # Output ports\n",
        "    if node.out_ports:\n",
        "        out_ports = {}\n",
        "        for name, port in node.out_ports.items():\n",
        "            port_dict = port_to_dict(port)\n",
        "            if port_dict:\n",
        "                out_ports[name] = port_dict\n",
        "            else:\n",
        "                out_ports[name] = {}\n",
        "        if out_ports:\n",
        "            result[\"out_ports\"] = out_ports\n",
        "\n",
        "    # Input salvo conditions\n",
        "    if node.in_salvo_conditions:\n",
        "        in_salvos = {}\n",
        "        for name, cond in node.in_salvo_conditions.items():\n",
        "            in_salvos[name] = salvo_condition_to_dict(cond)\n",
        "        result[\"in_salvo_conditions\"] = in_salvos\n",
        "\n",
        "    # Output salvo conditions\n",
        "    if node.out_salvo_conditions:\n",
        "        out_salvos = {}\n",
        "        for name, cond in node.out_salvo_conditions.items():\n",
        "            out_salvos[name] = salvo_condition_to_dict(cond)\n",
        "        result[\"out_salvo_conditions\"] = out_salvos\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def _packet_count_to_value(pc) -> Union[str, int]:\n",
        "    \"\"\"Convert a PacketCount to a serializable value.\n",
        "\n",
        "    Args:\n",
        "        pc: Either PacketCount.All or PacketCountN\n",
        "\n",
        "    Returns:\n",
        "        \"all\" for PacketCount.All, or the integer count for PacketCountN\n",
        "    \"\"\"\n",
        "    # Check if it's PacketCountN by checking the class name\n",
        "    # (hasattr check can be misleading due to method names like .count())\n",
        "    class_name = type(pc).__name__\n",
        "    if class_name == \"PacketCountN\":\n",
        "        return pc.count\n",
        "    # It's PacketCount.All or another variant\n",
        "    return \"all\"\n",
        "\n",
        "\n",
        "def _ports_to_serializable(ports) -> Union[str, Dict[str, Any]]:\n",
        "    \"\"\"Convert ports specification to a serializable format.\"\"\"\n",
        "    if isinstance(ports, str):\n",
        "        return ports\n",
        "    if isinstance(ports, dict):\n",
        "        # Convert PacketCount values to strings/ints\n",
        "        result = {}\n",
        "        for port_name, packet_count in ports.items():\n",
        "            result[port_name] = _packet_count_to_value(packet_count)\n",
        "        # If there's only one port with \"all\", simplify to just the port name\n",
        "        if len(result) == 1 and list(result.values())[0] == \"all\":\n",
        "            return list(result.keys())[0]\n",
        "        return result\n",
        "    return str(ports)\n",
        "\n",
        "\n",
        "def salvo_condition_to_dict(cond: SalvoCondition) -> Dict[str, Any]:\n",
        "    \"\"\"Convert a SalvoCondition to a dictionary.\"\"\"\n",
        "    result = {}\n",
        "\n",
        "    # Max salvos\n",
        "    max_salvos = cond.max_salvos\n",
        "    if _is_max_salvos_infinite(max_salvos):\n",
        "        result[\"max_salvos\"] = \"infinite\"\n",
        "    else:\n",
        "        result[\"max_salvos\"] = _get_max_salvos_count(max_salvos)\n",
        "\n",
        "    # Ports - convert to serializable format\n",
        "    ports_serialized = _ports_to_serializable(cond.ports)\n",
        "    result[\"ports\"] = ports_serialized\n",
        "\n",
        "    # Term (expression) - simplified for now\n",
        "    # Would need full introspection of SalvoConditionTerm to serialize properly\n",
        "    # For now, we store a placeholder based on the first port\n",
        "    if isinstance(ports_serialized, str):\n",
        "        result[\"when\"] = f\"nonempty({ports_serialized})\"\n",
        "    elif isinstance(ports_serialized, dict):\n",
        "        first_port = list(ports_serialized.keys())[0]\n",
        "        result[\"when\"] = f\"nonempty({first_port})\"\n",
        "    else:\n",
        "        result[\"when\"] = \"true\"\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def dict_to_salvo_condition(data: Dict[str, Any]) -> SalvoCondition:\n",
        "    \"\"\"Convert a dictionary to a SalvoCondition.\"\"\"\n",
        "    # Parse max_salvos\n",
        "    max_salvos_val = data.get(\"max_salvos\", \"infinite\")\n",
        "    if max_salvos_val == \"infinite\":\n",
        "        max_salvos = MaxSalvos.infinite()\n",
        "    else:\n",
        "        max_salvos = MaxSalvos.finite(int(max_salvos_val))\n",
        "\n",
        "    # Get ports\n",
        "    ports = data.get(\"ports\", \"\")\n",
        "\n",
        "    # Parse the when expression\n",
        "    when_expr = data.get(\"when\", \"\")\n",
        "    if when_expr:\n",
        "        term = parse_salvo_condition_expr(when_expr)\n",
        "    else:\n",
        "        # Default to non-empty check on the ports\n",
        "        term = SalvoConditionTerm.port(ports, PortState.non_empty())\n",
        "\n",
        "    return SalvoCondition(max_salvos, ports, term)\n",
        "\n",
        "\n",
        "def dict_to_node(name: str, data: Dict[str, Any]) -> Node:\n",
        "    \"\"\"Convert a dictionary to a Node.\"\"\"\n",
        "    # Parse input ports\n",
        "    in_ports = {}\n",
        "    in_ports_data = data.get(\"in_ports\", {})\n",
        "    if isinstance(in_ports_data, list):\n",
        "        # Simple list of port names\n",
        "        for port_name in in_ports_data:\n",
        "            in_ports[port_name] = Port()\n",
        "    elif isinstance(in_ports_data, dict):\n",
        "        for port_name, port_data in in_ports_data.items():\n",
        "            in_ports[port_name] = dict_to_port(port_data)\n",
        "\n",
        "    # Parse output ports\n",
        "    out_ports = {}\n",
        "    out_ports_data = data.get(\"out_ports\", {})\n",
        "    if isinstance(out_ports_data, list):\n",
        "        for port_name in out_ports_data:\n",
        "            out_ports[port_name] = Port()\n",
        "    elif isinstance(out_ports_data, dict):\n",
        "        for port_name, port_data in out_ports_data.items():\n",
        "            out_ports[port_name] = dict_to_port(port_data)\n",
        "\n",
        "    # Parse input salvo conditions\n",
        "    in_salvo_conditions = {}\n",
        "    in_salvos_data = data.get(\"in_salvo_conditions\", {})\n",
        "    for cond_name, cond_data in in_salvos_data.items():\n",
        "        in_salvo_conditions[cond_name] = dict_to_salvo_condition(cond_data)\n",
        "\n",
        "    # Parse output salvo conditions\n",
        "    out_salvo_conditions = {}\n",
        "    out_salvos_data = data.get(\"out_salvo_conditions\", {})\n",
        "    for cond_name, cond_data in out_salvos_data.items():\n",
        "        out_salvo_conditions[cond_name] = dict_to_salvo_condition(cond_data)\n",
        "\n",
        "    return Node(\n",
        "        name=name,\n",
        "        in_ports=in_ports if in_ports else None,\n",
        "        out_ports=out_ports if out_ports else None,\n",
        "        in_salvo_conditions=in_salvo_conditions if in_salvo_conditions else None,\n",
        "        out_salvo_conditions=out_salvo_conditions if out_salvo_conditions else None,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edge Serialization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def edge_to_dict(edge: Edge) -> Dict[str, str]:\n",
        "    \"\"\"Convert an Edge to a dictionary.\"\"\"\n",
        "    source = edge.source\n",
        "    target = edge.target\n",
        "    return {\n",
        "        \"from\": f\"{source.node_name}.{source.port_name}\",\n",
        "        \"to\": f\"{target.node_name}.{target.port_name}\",\n",
        "    }\n",
        "\n",
        "\n",
        "def dict_to_edge(data: Dict[str, str]) -> Edge:\n",
        "    \"\"\"Convert a dictionary to an Edge.\"\"\"\n",
        "    from_str = data[\"from\"]\n",
        "    to_str = data[\"to\"]\n",
        "\n",
        "    # Parse \"NodeName.port_name\"\n",
        "    from_parts = from_str.rsplit('.', 1)\n",
        "    to_parts = to_str.rsplit('.', 1)\n",
        "\n",
        "    if len(from_parts) != 2 or len(to_parts) != 2:\n",
        "        raise ValueError(f\"Invalid edge format: {from_str} -> {to_str}\")\n",
        "\n",
        "    source = PortRef(from_parts[0], PortType.Output, from_parts[1])\n",
        "    target = PortRef(to_parts[0], PortType.Input, to_parts[1])\n",
        "\n",
        "    return Edge(source, target)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Serialization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def graph_to_dict(graph: Graph) -> Dict[str, Any]:\n",
        "    \"\"\"Convert a Graph to a dictionary for TOML serialization.\"\"\"\n",
        "    result = {}\n",
        "\n",
        "    # Nodes - graph.nodes() returns a dict of node_name -> Node\n",
        "    nodes_dict = {}\n",
        "    graph_nodes = graph.nodes()\n",
        "    for node_name, node in graph_nodes.items():\n",
        "        node_dict = node_to_dict(node)\n",
        "        # Remove 'name' since it's the key\n",
        "        node_dict.pop('name', None)\n",
        "        nodes_dict[node_name] = node_dict\n",
        "    result[\"nodes\"] = nodes_dict\n",
        "\n",
        "    # Edges\n",
        "    edges_list = []\n",
        "    for edge in graph.edges():\n",
        "        edges_list.append(edge_to_dict(edge))\n",
        "    result[\"edges\"] = edges_list\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def dict_to_graph(data: Dict[str, Any]) -> Graph:\n",
        "    \"\"\"Convert a dictionary to a Graph.\"\"\"\n",
        "    # Parse nodes\n",
        "    nodes = []\n",
        "    nodes_data = data.get(\"nodes\", {})\n",
        "    for node_name, node_data in nodes_data.items():\n",
        "        nodes.append(dict_to_node(node_name, node_data))\n",
        "\n",
        "    # Parse edges\n",
        "    edges = []\n",
        "    edges_data = data.get(\"edges\", [])\n",
        "    for edge_data in edges_data:\n",
        "        edges.append(dict_to_edge(edge_data))\n",
        "\n",
        "    return Graph(nodes, edges)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Net Configuration Serialization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "@dataclass\n",
        "class NetDSLConfig:\n",
        "    \"\"\"Configuration extracted from DSL for Net construction.\"\"\"\n",
        "    graph: Graph\n",
        "    on_error: str = \"continue\"\n",
        "    consumed_packet_storage: bool = False\n",
        "    consumed_storage_limit: Optional[int] = None\n",
        "    history_file: Optional[str] = None\n",
        "    history_max_size: int = 10000\n",
        "    history_chunk_size: int = 100\n",
        "    thread_pools: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n",
        "    process_pools: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n",
        "    node_configs: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n",
        "    node_exec_paths: Dict[str, Dict[str, str]] = field(default_factory=dict)\n",
        "    node_factories: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n",
        "    port_types: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n",
        "    meta: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "\n",
        "def parse_toml_string(toml_str: str) -> NetDSLConfig:\n",
        "    \"\"\"\n",
        "    Parse a TOML string into a NetDSLConfig.\n",
        "\n",
        "    Args:\n",
        "        toml_str: TOML configuration string\n",
        "\n",
        "    Returns:\n",
        "        NetDSLConfig with parsed configuration\n",
        "    \"\"\"\n",
        "    data = tomllib.loads(toml_str)\n",
        "    return _parse_toml_data(data)\n",
        "\n",
        "\n",
        "def parse_toml_file(path: Union[str, Path]) -> NetDSLConfig:\n",
        "    \"\"\"\n",
        "    Parse a TOML file into a NetDSLConfig.\n",
        "\n",
        "    Args:\n",
        "        path: Path to the TOML file\n",
        "\n",
        "    Returns:\n",
        "        NetDSLConfig with parsed configuration\n",
        "    \"\"\"\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "        data = tomllib.load(f)\n",
        "    return _parse_toml_data(data)\n",
        "\n",
        "\n",
        "def _parse_toml_data(data: Dict[str, Any]) -> NetDSLConfig:\n",
        "    \"\"\"Parse TOML data into NetDSLConfig.\"\"\"\n",
        "    # Parse graph\n",
        "    graph = dict_to_graph(data)\n",
        "\n",
        "    # Parse net-level config\n",
        "    net_config = data.get(\"net\", {})\n",
        "\n",
        "    config = NetDSLConfig(\n",
        "        graph=graph,\n",
        "        on_error=net_config.get(\"on_error\", \"continue\"),\n",
        "        consumed_packet_storage=net_config.get(\"consumed_packet_storage\", False),\n",
        "        consumed_storage_limit=net_config.get(\"consumed_storage_limit\"),\n",
        "        history_file=net_config.get(\"history_file\"),\n",
        "        history_max_size=net_config.get(\"history_max_size\", 10000),\n",
        "        history_chunk_size=net_config.get(\"history_chunk_size\", 100),\n",
        "        thread_pools=net_config.get(\"thread_pools\", {}),\n",
        "        process_pools=net_config.get(\"process_pools\", {}),\n",
        "        meta=net_config.get(\"meta\", {}),\n",
        "    )\n",
        "\n",
        "    # Parse node-specific configs\n",
        "    nodes_data = data.get(\"nodes\", {})\n",
        "    for node_name, node_data in nodes_data.items():\n",
        "        # Node options\n",
        "        options = node_data.get(\"options\", {})\n",
        "        if options:\n",
        "            config.node_configs[node_name] = options\n",
        "\n",
        "        # Node exec functions\n",
        "        exec_paths = {}\n",
        "        if \"exec_node_func\" in node_data:\n",
        "            exec_paths[\"exec_func\"] = node_data[\"exec_node_func\"]\n",
        "        if \"start_node_func\" in node_data:\n",
        "            exec_paths[\"start_func\"] = node_data[\"start_node_func\"]\n",
        "        if \"stop_node_func\" in node_data:\n",
        "            exec_paths[\"stop_func\"] = node_data[\"stop_node_func\"]\n",
        "        if \"exec_failed_node_func\" in node_data:\n",
        "            exec_paths[\"failed_func\"] = node_data[\"exec_failed_node_func\"]\n",
        "        if exec_paths:\n",
        "            config.node_exec_paths[node_name] = exec_paths\n",
        "\n",
        "        # Port types\n",
        "        port_types = {}\n",
        "        in_ports_data = node_data.get(\"in_ports\", {})\n",
        "        if isinstance(in_ports_data, dict):\n",
        "            for port_name, port_data in in_ports_data.items():\n",
        "                if isinstance(port_data, dict) and \"type\" in port_data:\n",
        "                    port_types[f\"in.{port_name}\"] = port_data[\"type\"]\n",
        "        out_ports_data = node_data.get(\"out_ports\", {})\n",
        "        if isinstance(out_ports_data, dict):\n",
        "            for port_name, port_data in out_ports_data.items():\n",
        "                if isinstance(port_data, dict) and \"type\" in port_data:\n",
        "                    port_types[f\"out.{port_name}\"] = port_data[\"type\"]\n",
        "        if port_types:\n",
        "            config.port_types[node_name] = port_types\n",
        "\n",
        "        # Factory info\n",
        "        if \"factory\" in node_data:\n",
        "            factory_info = {\n",
        "                \"factory\": node_data[\"factory\"],\n",
        "            }\n",
        "            if \"factory_args\" in node_data:\n",
        "                factory_info[\"factory_args\"] = node_data[\"factory_args\"]\n",
        "            config.node_factories[node_name] = factory_info\n",
        "\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOML Generation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#|export\n",
        "def net_config_to_toml(config: NetDSLConfig) -> str:\n",
        "    \"\"\"\n",
        "    Convert a NetDSLConfig to a TOML string.\n",
        "\n",
        "    Args:\n",
        "        config: The configuration to serialize\n",
        "\n",
        "    Returns:\n",
        "        TOML string representation\n",
        "    \"\"\"\n",
        "    doc = tomlkit.document()\n",
        "\n",
        "    # Net-level config\n",
        "    net_table = tomlkit.table()\n",
        "    if config.on_error != \"continue\":\n",
        "        net_table[\"on_error\"] = config.on_error\n",
        "    if config.consumed_packet_storage:\n",
        "        net_table[\"consumed_packet_storage\"] = config.consumed_packet_storage\n",
        "    if config.consumed_storage_limit is not None:\n",
        "        net_table[\"consumed_storage_limit\"] = config.consumed_storage_limit\n",
        "    if config.history_file:\n",
        "        net_table[\"history_file\"] = config.history_file\n",
        "    if config.history_max_size is not None and config.history_max_size != 10000:\n",
        "        net_table[\"history_max_size\"] = config.history_max_size\n",
        "    if config.thread_pools:\n",
        "        pools_table = tomlkit.table()\n",
        "        for name, pool_config in config.thread_pools.items():\n",
        "            pools_table[name] = pool_config\n",
        "        net_table[\"thread_pools\"] = pools_table\n",
        "    if config.process_pools:\n",
        "        pools_table = tomlkit.table()\n",
        "        for name, pool_config in config.process_pools.items():\n",
        "            pools_table[name] = pool_config\n",
        "        net_table[\"process_pools\"] = pools_table\n",
        "    if config.meta:\n",
        "        net_table[\"meta\"] = config.meta\n",
        "\n",
        "    if net_table:\n",
        "        doc[\"net\"] = net_table\n",
        "\n",
        "    # Nodes\n",
        "    graph_dict = graph_to_dict(config.graph)\n",
        "    nodes_table = tomlkit.table()\n",
        "    for node_name, node_data in graph_dict.get(\"nodes\", {}).items():\n",
        "        node_table = tomlkit.table()\n",
        "\n",
        "        # Ports\n",
        "        if \"in_ports\" in node_data:\n",
        "            node_table[\"in_ports\"] = node_data[\"in_ports\"]\n",
        "        if \"out_ports\" in node_data:\n",
        "            node_table[\"out_ports\"] = node_data[\"out_ports\"]\n",
        "\n",
        "        # Salvo conditions\n",
        "        if \"in_salvo_conditions\" in node_data:\n",
        "            node_table[\"in_salvo_conditions\"] = node_data[\"in_salvo_conditions\"]\n",
        "        if \"out_salvo_conditions\" in node_data:\n",
        "            node_table[\"out_salvo_conditions\"] = node_data[\"out_salvo_conditions\"]\n",
        "\n",
        "        # Node options\n",
        "        if node_name in config.node_configs:\n",
        "            node_table[\"options\"] = config.node_configs[node_name]\n",
        "\n",
        "        # Exec paths\n",
        "        if node_name in config.node_exec_paths:\n",
        "            paths = config.node_exec_paths[node_name]\n",
        "            if \"exec_func\" in paths:\n",
        "                node_table[\"exec_node_func\"] = paths[\"exec_func\"]\n",
        "            if \"start_func\" in paths:\n",
        "                node_table[\"start_node_func\"] = paths[\"start_func\"]\n",
        "            if \"stop_func\" in paths:\n",
        "                node_table[\"stop_node_func\"] = paths[\"stop_func\"]\n",
        "            if \"failed_func\" in paths:\n",
        "                node_table[\"exec_failed_node_func\"] = paths[\"failed_func\"]\n",
        "\n",
        "        # Factory info\n",
        "        if node_name in config.node_factories:\n",
        "            factory_info = config.node_factories[node_name]\n",
        "            if \"factory\" in factory_info:\n",
        "                node_table[\"factory\"] = factory_info[\"factory\"]\n",
        "            if \"factory_args\" in factory_info:\n",
        "                node_table[\"factory_args\"] = factory_info[\"factory_args\"]\n",
        "\n",
        "        nodes_table[node_name] = node_table\n",
        "\n",
        "    doc[\"nodes\"] = nodes_table\n",
        "\n",
        "    # Edges\n",
        "    edges_array = tomlkit.array()\n",
        "    for edge_data in graph_dict.get(\"edges\", []):\n",
        "        edges_array.append(edge_data)\n",
        "    doc[\"edges\"] = edges_array\n",
        "\n",
        "    return tomlkit.dumps(doc)\n",
        "\n",
        "\n",
        "def save_toml_file(config: NetDSLConfig, path: Union[str, Path]) -> None:\n",
        "    \"\"\"\n",
        "    Save a NetDSLConfig to a TOML file.\n",
        "\n",
        "    Args:\n",
        "        config: The configuration to save\n",
        "        path: Path to write the TOML file\n",
        "    \"\"\"\n",
        "    path = Path(path)\n",
        "    toml_str = net_config_to_toml(config)\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(toml_str)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
