# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/netrun/03_pool/03_remote.ipynb

__all__ = ['RP_DOWN_BROADCAST', 'RP_DOWN_CLOSE', 'RP_DOWN_CREATE_POOL', 'RP_DOWN_FLUSH_ALL_STDOUT', 'RP_DOWN_FLUSH_STDOUT', 'RP_DOWN_SEND', 'RP_UP_ERROR_EXCEPTION', 'RP_UP_ERROR_POOL_FAILED', 'RP_UP_POOL_CREATED', 'RP_UP_RECV', 'RP_UP_STDOUT_BUFFER', 'RemotePoolClient', 'RemotePoolServer']

# %% nbs/netrun/03_pool/03_remote.ipynb 3
import asyncio
from typing import Any
from contextlib import asynccontextmanager

from ..rpc.base import ChannelClosed, RecvTimeout
from ..rpc.remote import (
    WebSocketChannel,
    serve_background,
)
from ..pool.base import (
    WorkerId,
    WorkerFn,
    WorkerMessage,
    PoolError,
    PoolNotStarted,
    WorkerException,
    WorkerCrashed,
)
from ..pool.multiprocess import MultiprocessPool, OutputBuffer

# %% nbs/netrun/03_pool/03_remote.ipynb 5
# Downstream: client → server
RP_DOWN_CREATE_POOL = "__pool-rp-down:create_pool"
"""Client requests pool creation. Data: {worker_name, num_processes, threads_per_process}"""

# %% nbs/netrun/03_pool/03_remote.ipynb 6
RP_DOWN_SEND = "__pool-rp-down:send"
"""Client sends to worker. Data: {worker_id, key, data}"""

# %% nbs/netrun/03_pool/03_remote.ipynb 7
RP_DOWN_BROADCAST = "__pool-rp-down:broadcast"
"""Client broadcasts to all. Data: {key, data}"""

# %% nbs/netrun/03_pool/03_remote.ipynb 8
RP_DOWN_CLOSE = "__pool-rp-down:close"
"""Client requests pool close."""

# %% nbs/netrun/03_pool/03_remote.ipynb 9
RP_DOWN_FLUSH_STDOUT = "__pool-rp-down:flush_stdout"
"""Client requests stdout buffer from a process. Data: {process_idx}"""

# %% nbs/netrun/03_pool/03_remote.ipynb 10
RP_DOWN_FLUSH_ALL_STDOUT = "__pool-rp-down:flush_all_stdout"
"""Client requests stdout buffers from all processes."""

# %% nbs/netrun/03_pool/03_remote.ipynb 11
# Upstream: server → client
RP_UP_POOL_CREATED = "__pool-rp-up:pool_created"
"""Server confirms pool created. Data: {num_workers}"""

# %% nbs/netrun/03_pool/03_remote.ipynb 12
RP_UP_RECV = "__pool-rp-up:recv"
"""Server forwards worker response. Data: {worker_id, key, data}"""

# %% nbs/netrun/03_pool/03_remote.ipynb 13
RP_UP_ERROR_EXCEPTION = "__pool-rp-up:error-exception"
"""Server-side exception. Data: exception object or error dict."""

# %% nbs/netrun/03_pool/03_remote.ipynb 14
RP_UP_ERROR_POOL_FAILED = "__pool-rp-up:error-pool_failed"
"""Server failed to create/manage pool. Data: error message."""

# %% nbs/netrun/03_pool/03_remote.ipynb 15
RP_UP_STDOUT_BUFFER = "__pool-rp-up:stdout_buffer"
"""Server sends stdout buffer. Data: {process_idx, buffer} or {buffers}"""

# %% nbs/netrun/03_pool/03_remote.ipynb 17
class RemotePoolServer:
    """Server that hosts remote worker pools.

    Clients connect, request a pool configuration, and the server
    creates a MultiprocessPool to handle their requests.
    """

    def __init__(self):
        """Create a remote pool server."""
        self._workers: dict[str, WorkerFn] = {}
        self._running = False

    def register_worker(self, name: str, worker_fn: WorkerFn) -> None:
        """Register a worker function by name.

        Args:
            name: Name clients will use to request this worker
            worker_fn: The worker function (must be importable for multiprocessing)
        """
        self._workers[name] = worker_fn

    @property
    def registered_workers(self) -> list[str]:
        """List of registered worker names."""
        return list(self._workers.keys())

    async def serve(self, host: str = "0.0.0.0", port: int = 8080) -> None:
        """Start the server and handle connections.

        This blocks until the server is stopped.

        Args:
            host: Host to bind to
            port: Port to listen on
        """
        from ..rpc.remote import serve

        async def handle_client(channel: WebSocketChannel):
            await self._handle_client(channel)

        await serve(handle_client, host, port)

    @asynccontextmanager
    async def serve_background(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the server in the background.

        Args:
            host: Host to bind to
            port: Port to listen on

        Yields:
            The server object
        """
        async def handle_client(channel: WebSocketChannel):
            await self._handle_client(channel)

        async with serve_background(handle_client, host, port) as server:
            yield server

    async def _handle_client(self, channel: WebSocketChannel) -> None:
        """Handle a single client connection."""
        pool: MultiprocessPool | None = None
        forward_task: asyncio.Task | None = None

        try:
            while True:
                key, data = await channel.recv()

                if key == RP_DOWN_CREATE_POOL:
                    # Create pool
                    worker_name = data["worker_name"]
                    num_processes = data["num_processes"]
                    threads_per_process = data.get("threads_per_process", 1)
                    redirect_output = data.get("redirect_output", True)
                    buffer_output = data.get("buffer_output", True)

                    if worker_name not in self._workers:
                        await channel.send(RP_UP_ERROR_POOL_FAILED, f"Unknown worker: {worker_name}")
                        continue

                    # Clean up existing pool and forward task if any
                    if forward_task is not None:
                        forward_task.cancel()
                        try:
                            await forward_task
                        except asyncio.CancelledError:
                            pass
                        forward_task = None

                    if pool is not None:
                        await pool.close()

                    pool = MultiprocessPool(
                        worker_fn=self._workers[worker_name],
                        num_processes=num_processes,
                        threads_per_process=threads_per_process,
                        redirect_output=redirect_output,
                        buffer_output=buffer_output,
                    )
                    await pool.start()

                    await channel.send(RP_UP_POOL_CREATED, {
                        "num_workers": pool.num_workers,
                        "num_processes": pool.num_processes,
                        "threads_per_process": pool.threads_per_process,
                        "redirect_output": redirect_output,
                        "buffer_output": buffer_output,
                    })

                    # Start forwarding responses from pool to client
                    forward_task = asyncio.create_task(self._forward_responses(pool, channel))

                elif key == RP_DOWN_SEND:
                    if pool is None:
                        await channel.send(RP_UP_ERROR_POOL_FAILED, "No pool created")
                        continue

                    worker_id = data["worker_id"]
                    msg_key = data["key"]
                    msg_data = data["data"]
                    await pool.send(worker_id, msg_key, msg_data)

                elif key == RP_DOWN_BROADCAST:
                    if pool is None:
                        await channel.send(RP_UP_ERROR_POOL_FAILED, "No pool created")
                        continue

                    msg_key = data["key"]
                    msg_data = data["data"]
                    await pool.broadcast(msg_key, msg_data)

                elif key == RP_DOWN_FLUSH_STDOUT:
                    if pool is None:
                        await channel.send(RP_UP_ERROR_POOL_FAILED, "No pool created")
                        continue

                    process_idx = data["process_idx"]
                    buffer = await pool.flush_stdout(process_idx)
                    # Convert datetime to ISO format for JSON serialization
                    serializable_buffer = [
                        (ts.isoformat(), is_stdout, text)
                        for ts, is_stdout, text in buffer
                    ]
                    await channel.send(RP_UP_STDOUT_BUFFER, {
                        "process_idx": process_idx,
                        "buffer": serializable_buffer,
                    })

                elif key == RP_DOWN_FLUSH_ALL_STDOUT:
                    if pool is None:
                        await channel.send(RP_UP_ERROR_POOL_FAILED, "No pool created")
                        continue

                    buffers = await pool.flush_all_stdout()
                    # Convert datetime to ISO format for JSON serialization
                    serializable_buffers = {
                        str(idx): [
                            (ts.isoformat(), is_stdout, text)
                            for ts, is_stdout, text in buffer
                        ]
                        for idx, buffer in buffers.items()
                    }
                    await channel.send(RP_UP_STDOUT_BUFFER, {
                        "buffers": serializable_buffers,
                    })

                elif key == RP_DOWN_CLOSE:
                    break

        except ChannelClosed:
            pass
        finally:
            # Cancel forward task first
            if forward_task is not None:
                forward_task.cancel()
                try:
                    await forward_task
                except asyncio.CancelledError:
                    pass

            if pool is not None:
                await pool.close()

    async def _forward_responses(self, pool: MultiprocessPool, channel: WebSocketChannel) -> None:
        """Forward responses from pool workers to the client."""
        try:
            while pool.is_running and not channel.is_closed:
                try:
                    # Use a timeout so we can periodically check if we should stop
                    msg = await pool.recv(timeout=0.5)
                    await channel.send(RP_UP_RECV, {
                        "worker_id": msg.worker_id,
                        "key": msg.key,
                        "data": msg.data,
                    })
                except RecvTimeout:
                    continue
                except (WorkerException, WorkerCrashed) as e:
                    # Forward worker errors to client
                    if isinstance(e, WorkerException):
                        error_data = {
                            "worker_id": e.worker_id,
                            "type": type(e.original_exception).__name__ if isinstance(e.original_exception, Exception) else e.original_exception.get("type", "Exception"),
                            "message": str(e.original_exception) if isinstance(e.original_exception, Exception) else e.original_exception.get("message", ""),
                        }
                    else:
                        error_data = {
                            "worker_id": e.worker_id,
                            "type": "WorkerCrashed",
                            "message": str(e),
                            "details": e.details,
                        }
                    await channel.send(RP_UP_ERROR_EXCEPTION, error_data)
                except ChannelClosed:
                    break
        except asyncio.CancelledError:
            raise  # Re-raise to properly signal cancellation
        except Exception:
            pass

# %% nbs/netrun/03_pool/03_remote.ipynb 19
class RemotePoolClient:
    """Client for connecting to a remote pool server.

    Provides the same interface as local pools (send, recv, etc.)
    but workers run on the remote server.
    """

    def __init__(self, url: str):
        """Create a client.

        Args:
            url: WebSocket URL of the server (e.g., "ws://server:8080")
        """
        self._url = url
        self._channel: WebSocketChannel | None = None
        self._num_workers = 0
        self._num_processes = 0
        self._threads_per_process = 0
        self._redirect_output = True
        self._buffer_output = True
        self._running = False
        self._recv_queue: asyncio.Queue = asyncio.Queue()
        self._stdout_queue: asyncio.Queue = asyncio.Queue()
        self._recv_task: asyncio.Task | None = None

    @property
    def num_workers(self) -> int:
        """Total number of workers in the remote pool."""
        return self._num_workers

    @property
    def num_processes(self) -> int:
        """Number of processes on the server."""
        return self._num_processes

    @property
    def threads_per_process(self) -> int:
        """Number of threads per process."""
        return self._threads_per_process

    @property
    def is_running(self) -> bool:
        """Whether the client is connected and pool is created."""
        return self._running

    async def connect(self) -> None:
        """Connect to the server."""
        from ..rpc.remote import connect_channel
        self._channel = await connect_channel(self._url)

    async def create_pool(
        self,
        worker_name: str,
        num_processes: int,
        threads_per_process: int = 1,
        redirect_output: bool = True,
        buffer_output: bool = True,
    ) -> None:
        """Create a pool on the server.

        Args:
            worker_name: Name of registered worker function on server
            num_processes: Number of processes
            threads_per_process: Threads per process
            redirect_output: If True, redirect subprocess stdout/stderr
            buffer_output: If True, buffer redirected output (if redirect_output is True)
        """
        if self._channel is None:
            raise PoolNotStarted("Not connected to server")

        await self._channel.send(RP_DOWN_CREATE_POOL, {
            "worker_name": worker_name,
            "num_processes": num_processes,
            "threads_per_process": threads_per_process,
            "redirect_output": redirect_output,
            "buffer_output": buffer_output,
        })

        # Wait for response
        key, data = await self._channel.recv(timeout=None)

        if key == RP_UP_ERROR_POOL_FAILED:
            raise PoolError(f"Server error: {data}")

        if key != RP_UP_POOL_CREATED:
            raise PoolError(f"Unexpected response: {key}")

        self._num_workers = data["num_workers"]
        self._num_processes = data["num_processes"]
        self._threads_per_process = data["threads_per_process"]
        self._redirect_output = data.get("redirect_output", True)
        self._buffer_output = data.get("buffer_output", True)
        self._running = True

        # Start receiving messages from server
        self._recv_task = asyncio.create_task(self._receive_loop())

    async def _receive_loop(self) -> None:
        """Receive messages from server and queue them."""
        try:
            while self._running and self._channel and not self._channel.is_closed:
                try:
                    key, data = await self._channel.recv(timeout=None)
                    if key == RP_UP_RECV:
                        await self._recv_queue.put(("msg", data))
                    elif key == RP_UP_ERROR_EXCEPTION:
                        # Queue error so it can be raised in recv()
                        await self._recv_queue.put(("error", data))
                    elif key == RP_UP_ERROR_POOL_FAILED:
                        # Queue pool failure error
                        await self._recv_queue.put(("pool_error", data))
                    elif key == RP_UP_STDOUT_BUFFER:
                        # Queue stdout buffer for flush methods
                        await self._stdout_queue.put(data)
                except ChannelClosed:
                    break
        except Exception:
            pass

    async def close(self, timeout: float | None = None) -> None:
        """Close the connection and remote pool.

        Args:
            timeout: Not used for RemotePoolClient (included for protocol compatibility).
        """
        self._running = False

        if self._recv_task and not self._recv_task.done():
            self._recv_task.cancel()
            try:
                await self._recv_task
            except asyncio.CancelledError:
                pass

        if self._channel and not self._channel.is_closed:
            try:
                await self._channel.send(RP_DOWN_CLOSE, None)
            except Exception:
                pass
            await self._channel.close()

        self._channel = None

    async def send(self, worker_id: WorkerId, key: str, data: Any) -> None:
        """Send a message to a specific worker on the server."""
        if not self._running or self._channel is None:
            raise PoolNotStarted("Pool not created")

        if worker_id < 0 or worker_id >= self._num_workers:
            raise ValueError(f"worker_id {worker_id} out of range [0, {self._num_workers})")

        await self._channel.send(RP_DOWN_SEND, {
            "worker_id": worker_id,
            "key": key,
            "data": data,
        })

    async def recv(self, timeout: float | None = None) -> WorkerMessage:
        """Receive a message from any worker.

        Raises:
            WorkerException: If the worker raised an exception
            WorkerCrashed: If the worker died unexpectedly
            PoolError: If the server reported a pool error
            RecvTimeout: If this recv() call times out
        """
        if not self._running:
            raise PoolNotStarted("Pool not created")

        try:
            if timeout is None:
                item = await self._recv_queue.get()
            else:
                item = await asyncio.wait_for(
                    self._recv_queue.get(),
                    timeout=timeout,
                )
        except TimeoutError:
            raise RecvTimeout(f"Receive timed out after {timeout}s")

        msg_type, data = item
        if msg_type == "error":
            # Raise WorkerException or WorkerCrashed based on error type
            worker_id = data.get("worker_id", -1)
            if data.get("type") == "WorkerCrashed":
                raise WorkerCrashed(worker_id, data.get("details", {"reason": data.get("message", "unknown")}))
            else:
                raise WorkerException(worker_id, data)
        elif msg_type == "pool_error":
            raise PoolError(f"Server error: {data}")

        return WorkerMessage(
            worker_id=data["worker_id"],
            key=data["key"],
            data=data["data"],
        )

    async def try_recv(self) -> WorkerMessage | None:
        """Non-blocking receive from any worker.

        Raises:
            WorkerException: If the worker raised an exception
            WorkerCrashed: If the worker died unexpectedly
            PoolError: If the server reported a pool error
        """
        if not self._running:
            raise PoolNotStarted("Pool not created")

        try:
            item = self._recv_queue.get_nowait()
        except asyncio.QueueEmpty:
            return None

        msg_type, data = item
        if msg_type == "error":
            worker_id = data.get("worker_id", -1)
            if data.get("type") == "WorkerCrashed":
                raise WorkerCrashed(worker_id, data.get("details", {"reason": data.get("message", "unknown")}))
            else:
                raise WorkerException(worker_id, data)
        elif msg_type == "pool_error":
            raise PoolError(f"Server error: {data}")

        return WorkerMessage(
            worker_id=data["worker_id"],
            key=data["key"],
            data=data["data"],
        )

    async def broadcast(self, key: str, data: Any) -> None:
        """Send a message to all workers."""
        if not self._running or self._channel is None:
            raise PoolNotStarted("Pool not created")

        await self._channel.send(RP_DOWN_BROADCAST, {
            "key": key,
            "data": data,
        })

    async def flush_stdout(self, process_idx: int, timeout: float = 5.0) -> OutputBuffer:
        """Flush and return the stdout buffer from a specific subprocess.

        Args:
            process_idx: Index of the subprocess (0 to num_processes-1)
            timeout: Timeout in seconds for waiting for the response

        Returns:
            List of (timestamp, is_stdout, text) tuples. is_stdout is True for
            stdout, False for stderr.

        Raises:
            PoolNotStarted: If the pool is not running
            ValueError: If process_idx is out of range
        """
        if not self._running or self._channel is None:
            raise PoolNotStarted("Pool not created")

        if process_idx < 0 or process_idx >= self._num_processes:
            raise ValueError(f"process_idx {process_idx} out of range [0, {self._num_processes})")

        await self._channel.send(RP_DOWN_FLUSH_STDOUT, {"process_idx": process_idx})

        # Wait for response
        import datetime
        try:
            data = await asyncio.wait_for(self._stdout_queue.get(), timeout=timeout)
        except TimeoutError:
            raise RecvTimeout(f"Flush stdout timed out after {timeout}s")

        # Convert ISO format back to datetime
        buffer: OutputBuffer = [
            (datetime.datetime.fromisoformat(ts), is_stdout, text)
            for ts, is_stdout, text in data["buffer"]
        ]
        return buffer

    async def flush_all_stdout(self, timeout: float = 5.0) -> dict[int, OutputBuffer]:
        """Flush and return stdout buffers from all subprocesses.

        Args:
            timeout: Timeout in seconds for waiting for the response

        Returns:
            Dict mapping process index to list of (timestamp, is_stdout, text) tuples.

        Raises:
            PoolNotStarted: If the pool is not running
        """
        if not self._running or self._channel is None:
            raise PoolNotStarted("Pool not created")

        await self._channel.send(RP_DOWN_FLUSH_ALL_STDOUT, {})

        # Wait for response
        import datetime
        try:
            data = await asyncio.wait_for(self._stdout_queue.get(), timeout=timeout)
        except TimeoutError:
            raise RecvTimeout(f"Flush all stdout timed out after {timeout}s")

        # Convert ISO format back to datetime
        result: dict[int, OutputBuffer] = {}
        for idx_str, buffer in data["buffers"].items():
            result[int(idx_str)] = [
                (datetime.datetime.fromisoformat(ts), is_stdout, text)
                for ts, is_stdout, text in buffer
            ]
        return result

    async def __aenter__(self) -> "RemotePoolClient":
        """Context manager entry - connects to server."""
        await self.connect()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Context manager exit - closes connection."""
        await self.close()
